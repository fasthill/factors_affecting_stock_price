{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Testing with real world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "    df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(date, com_name, precision, y_predict, weight):\n",
    "    dict_temp = {}\n",
    "    dict_temp['date'] = date\n",
    "    dict_temp[f'{com_name}_precision'] = f'{precision:.2f}'\n",
    "    dict_temp[f'{com_name}_predict'] = f'{y_predict[0]}'\n",
    "    dict_temp[f'{com_name}_yes'] = f'{weight[0,1]:.2f}'\n",
    "    dict_temp[f'{com_name}_no'] = f'{weight[0,0]:.2f}'\n",
    "    df_t = pd.DataFrame.from_dict(dict_temp, orient='index').T\n",
    "    df_t.set_index('date', inplace=True)\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df_todays(date, com_name, result, y_predict, weight, cr):\n",
    "    precision = result.loc['precision'].iloc[-1]\n",
    "    tn = result.loc['tn'].iloc[-1]\n",
    "    fp = result.loc['fp'].iloc[-1]\n",
    "    fn = result.loc['fn'].iloc[-1]\n",
    "    tp = result.loc['tp'].iloc[-1]\n",
    "    \n",
    "    dict_temp = {}\n",
    "    dict_temp['name'] = com_name\n",
    "    dict_temp[f'precision'] = f'{precision:.2f}'\n",
    "    dict_temp[f'predict'] = f'{y_predict[0]}'\n",
    "    dict_temp[f'yes'] = f'{weight[0,1]:.2f}'\n",
    "    dict_temp[f'no'] = f'{weight[0,0]:.2f}'\n",
    "    dict_temp[f'tn'] = f'{tn:.1f}'\n",
    "    dict_temp[f'fp'] = f'{fp:.1f}'\n",
    "    dict_temp[f'fn'] = f'{fn:.1f}'\n",
    "    dict_temp[f'tp'] = f'{tp:.1f}'\n",
    "    if ((y_predict[0] == 1) & (cr > 0)):\n",
    "        result = 'right'\n",
    "    elif ((y_predict[0] == 1) & (cr <= 0)):\n",
    "        result = 'wrong'\n",
    "    else:\n",
    "        result = 'draw'\n",
    "    dict_temp[f'result'] = result\n",
    "    \n",
    "    df_t = pd.DataFrame.from_dict(dict_temp, orient='index').T\n",
    "    df_t.set_index('name', inplace=True)\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코퓨처엠', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng'], '030200' : ['KT', 'kt']}\n",
    "\n",
    "code_good = {'005930' : ['삼성전자', 'sec'], '035420' : ['NAVER', 'naver'],\n",
    "             '035720' : ['카카오', 'kakao'], '012330' : ['현대모비스', 'mobis'],\n",
    "             '051910' : ['LG화학', 'lgchemical'], '005935' : ['삼성전자우', 'secpre'],\n",
    "             '373220' : ['LG에너지솔루션', 'lgenergy'],\n",
    "            }\n",
    "\n",
    "code_good = {'005930' : ['삼성전자', 'sec'], '035420' : ['NAVER', 'naver'],\n",
    "             '035720' : ['카카오', 'kakao'], '012330' : ['현대모비스', 'mobis'],\n",
    "             '051910' : ['LG화학', 'lgchemical'],'005935' : ['삼성전자우', 'secpre'],\n",
    "             '000270' : ['기아','kia'], '373220' : ['LG에너지솔루션', 'lgenergy'],\n",
    "             '005380' : ['현대차', 'hyunmotor'], '000660' : ['SK하이닉스', 'skhinix'],\n",
    "             '006400' : ['삼성SDI', 'sdi'],\n",
    "            }\n",
    "\n",
    "code_mid = {'105560' : ['KB금융', 'kbbank'],\n",
    "            '003670' : ['포스코퓨처엠', 'poscochemical'],\n",
    "            }\n",
    "\n",
    "code_bad = { '030200' : ['KT', 'kt'],\n",
    "             '033780' : ['KT&G', 'ktng'], '066570' : ['LG전자', 'lgelec'], \n",
    "             '005490' : ['POSCO홀딩스', 'poscoholding'], '055550' : ['신한지주', 'shgroup'],\n",
    "             '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "             '207940' : ['삼성바이오로직스', 'ssbio'], '028260' : ['삼성물산', 'sscnt'],\n",
    "             '068270' : ['셀트리온', 'celltrion'],\n",
    "           }\n",
    "# code_good = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_for_predict = '../data/data_for_ml/predict/'\n",
    "directory_for_data = '../data/company_pkl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory_for_predict+ 'prediction/prediction_list.pkl'):\n",
    "    os.makedirs(directory_for_predict+'prediction')\n",
    "    prediction_list=pd.DataFrame()\n",
    "    fname_p = 'prediction_list.pkl'\n",
    "    path_p = directory_for_predict+'prediction/' + fname_p\n",
    "    prediction_list.to_pickle(path_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = pd.read_pickle(directory_for_predict+ 'prediction/prediction_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_date = datetime.date.today()\n",
    "# prediction_date = datetime.date(2023, 4, 4) # 예측을 필요로 하는 일자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 51)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(scaler_pkl) \u001b[38;5;66;03m# scaler 읽기\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#     scaler = load_from_pickle(scaler_p_pkl) # scaler 읽기\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     real_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# apply the scaled real_data to the model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(model_pkl) \u001b[38;5;66;03m# model 읽기\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    991\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 992\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 51)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "df_base = pd.DataFrame()\n",
    "df_todays = pd.DataFrame()\n",
    "\n",
    "for key, val in code_good.items():\n",
    " \n",
    "    com_name = val[1]\n",
    "    \n",
    "    fname = f'df_{com_name}_sel.pkl'\n",
    "    f_name = directory_for_predict + fname\n",
    "    df_o = pd.read_pickle(f_name) \n",
    "    com_fname = f'{com_name}_historical.pkl'  # 실제와 예측을 비교하기 위하여 실제데이터을 불러 옴\n",
    "    f_com_name = directory_for_data + com_fname\n",
    "    com_data = pd.read_pickle(f_com_name)\n",
    "\n",
    "    current_data = df_o.loc[:, 'retail_1':'weekday'] # select columns except targets columns\n",
    "    \n",
    "    prediction_row = current_data[current_data.index == prediction_date.isoformat()]\n",
    "    com_row = com_data[com_data['date'] == prediction_date.isoformat()]\n",
    "    try:\n",
    "        cr = com_row['close_cr'].values[0] # 실제의 등락을 확인\n",
    "    except:\n",
    "        cr = -1.0 # 예측 당일 아침 실제 결과가 없을시 임시 지정\n",
    "\n",
    "    # locate the model data directory\n",
    "    directory_model_data = f'../machine_learning/{com_name}/'\n",
    "\n",
    "    # get the model data filepath\n",
    "    columns_pkl = directory_model_data + 'best_columns.pkl'\n",
    "    scaler_pkl = directory_model_data + 'best_scaler.pkl'\n",
    "    scaler_p_pkl = directory_model_data + 'best_scaler_p.pkl'\n",
    "    model_pkl = directory_model_data + 'best_model.pkl'\n",
    "    model_p_pkl = directory_model_data + 'best_model_p.pkl'\n",
    "    result_pkl = directory_model_data + 'best_result.pkl'\n",
    "    \n",
    "    # load result data\n",
    "    result = load_from_pickle(result_pkl)[:-5] \n",
    "    precision = result.loc['precision'].iloc[-1]\n",
    "    \n",
    "    # load columns data\n",
    "    real_columns = load_from_pickle(columns_pkl)[:-5] # column 읽기. target columns 5개는 제외\n",
    "    real_data_df = prediction_row[real_columns] # select necessary columns\n",
    "    \n",
    "    # scale the data\n",
    "    scaler = joblib.load(scaler_pkl) # scaler 읽기\n",
    "#     scaler = load_from_pickle(scaler_p_pkl) # scaler 읽기\n",
    "    real_scaled = scaler.transform(real_data_df)\n",
    "    \n",
    "    # apply the scaled real_data to the model\n",
    "    model = joblib.load(model_pkl) # model 읽기\n",
    "#     model = load_from_pickle(model_p_pkl) # model made with pickle 읽기\n",
    "\n",
    "    y_predict = model.predict(real_scaled)\n",
    "    weight = model.predict_proba(real_scaled)\n",
    "\n",
    "    df_temp = to_df(prediction_row.index[-1].date(), com_name, precision, y_predict, weight)\n",
    "    df_base = pd.concat([df_base, df_temp],axis=1)\n",
    "    df_temp_todays = to_df_todays(prediction_row.index[-1].date(), com_name, result, y_predict, weight, cr)\n",
    "    df_todays = pd.concat([df_todays, df_temp_todays],axis=0)\n",
    "    \n",
    "#     print(f'**date: {prediction_row.index[-1].date()}, {precision:.2f}, {com_name}, 예측: {y_predict}, 가능성:{weight}')\n",
    "df_todays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retail_1</th>\n",
       "      <th>foreigner_1</th>\n",
       "      <th>institution_1</th>\n",
       "      <th>financial_1</th>\n",
       "      <th>invtrust_1</th>\n",
       "      <th>pension_1</th>\n",
       "      <th>privequity_1</th>\n",
       "      <th>bank_1</th>\n",
       "      <th>insurance_1</th>\n",
       "      <th>financeetc_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ixtr_cr_2</th>\n",
       "      <th>ixut_cr_2</th>\n",
       "      <th>nbi_cr_2</th>\n",
       "      <th>bkx_cr_2</th>\n",
       "      <th>open_2</th>\n",
       "      <th>high_2</th>\n",
       "      <th>low_2</th>\n",
       "      <th>close_2</th>\n",
       "      <th>vol_2</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>-0.728308</td>\n",
       "      <td>-1.134320</td>\n",
       "      <td>-3.800544</td>\n",
       "      <td>-6.280593</td>\n",
       "      <td>-1.379315</td>\n",
       "      <td>1.202381</td>\n",
       "      <td>8.502452</td>\n",
       "      <td>-3.342857</td>\n",
       "      <td>-0.199498</td>\n",
       "      <td>-3.892308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388204</td>\n",
       "      <td>1.357070</td>\n",
       "      <td>-0.381551</td>\n",
       "      <td>1.397590</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.019206</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.124455</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>-2.922569</td>\n",
       "      <td>-0.961471</td>\n",
       "      <td>-2.248559</td>\n",
       "      <td>-1.318007</td>\n",
       "      <td>0.232121</td>\n",
       "      <td>1.968292</td>\n",
       "      <td>-1.305245</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.878336</td>\n",
       "      <td>-1.271277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171763</td>\n",
       "      <td>-0.681729</td>\n",
       "      <td>-3.743265</td>\n",
       "      <td>0.696059</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.012674</td>\n",
       "      <td>0.047903</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-17</th>\n",
       "      <td>-0.141878</td>\n",
       "      <td>-51.541050</td>\n",
       "      <td>0.494157</td>\n",
       "      <td>1.782079</td>\n",
       "      <td>0.050840</td>\n",
       "      <td>-0.501553</td>\n",
       "      <td>-2.065171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.748316</td>\n",
       "      <td>54.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.541227</td>\n",
       "      <td>-0.778962</td>\n",
       "      <td>-1.356175</td>\n",
       "      <td>-0.122211</td>\n",
       "      <td>-0.022642</td>\n",
       "      <td>-0.018844</td>\n",
       "      <td>-0.019084</td>\n",
       "      <td>-0.020279</td>\n",
       "      <td>-0.100512</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>-8.379546</td>\n",
       "      <td>-1.116349</td>\n",
       "      <td>-0.293620</td>\n",
       "      <td>-0.431429</td>\n",
       "      <td>0.985260</td>\n",
       "      <td>-0.638852</td>\n",
       "      <td>-2.502804</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.671470</td>\n",
       "      <td>-0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.901290</td>\n",
       "      <td>-3.069136</td>\n",
       "      <td>-2.962608</td>\n",
       "      <td>-2.703978</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>-0.003841</td>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.052837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>-0.353206</td>\n",
       "      <td>-0.647862</td>\n",
       "      <td>-0.316408</td>\n",
       "      <td>-12.128503</td>\n",
       "      <td>-0.288602</td>\n",
       "      <td>1.911987</td>\n",
       "      <td>-3.847015</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.384173</td>\n",
       "      <td>-7.476190</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.169371</td>\n",
       "      <td>-3.408924</td>\n",
       "      <td>-4.860017</td>\n",
       "      <td>-5.458870</td>\n",
       "      <td>-0.014175</td>\n",
       "      <td>-0.011568</td>\n",
       "      <td>-0.010403</td>\n",
       "      <td>-0.015484</td>\n",
       "      <td>0.193324</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>5.045599</td>\n",
       "      <td>-6.505242</td>\n",
       "      <td>-1.378964</td>\n",
       "      <td>-1.455990</td>\n",
       "      <td>-0.755787</td>\n",
       "      <td>-161.913669</td>\n",
       "      <td>-2.436101</td>\n",
       "      <td>10.841270</td>\n",
       "      <td>-0.542801</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057836</td>\n",
       "      <td>1.854493</td>\n",
       "      <td>0.600471</td>\n",
       "      <td>0.843254</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.368456</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>0.823596</td>\n",
       "      <td>0.504240</td>\n",
       "      <td>-1.996055</td>\n",
       "      <td>-1.952853</td>\n",
       "      <td>-1.884406</td>\n",
       "      <td>-0.857066</td>\n",
       "      <td>-0.317107</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>-1.742882</td>\n",
       "      <td>-1.046154</td>\n",
       "      <td>...</td>\n",
       "      <td>2.048021</td>\n",
       "      <td>2.039977</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>-0.340135</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>0.020734</td>\n",
       "      <td>0.285894</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>-1.106890</td>\n",
       "      <td>-0.814171</td>\n",
       "      <td>-4.739488</td>\n",
       "      <td>-3.959295</td>\n",
       "      <td>-3.598117</td>\n",
       "      <td>0.343447</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>-1.591121</td>\n",
       "      <td>-6.087108</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670550</td>\n",
       "      <td>1.813086</td>\n",
       "      <td>1.938160</td>\n",
       "      <td>0.332018</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>-0.238065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>-4.669072</td>\n",
       "      <td>1.004010</td>\n",
       "      <td>-1.191640</td>\n",
       "      <td>-1.446173</td>\n",
       "      <td>-1.103679</td>\n",
       "      <td>-4.333411</td>\n",
       "      <td>-0.980275</td>\n",
       "      <td>-2.604743</td>\n",
       "      <td>-2.743607</td>\n",
       "      <td>-0.420804</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.203092</td>\n",
       "      <td>-0.547517</td>\n",
       "      <td>-0.234654</td>\n",
       "      <td>-2.510967</td>\n",
       "      <td>-0.009375</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>-0.014129</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>-0.216077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06</th>\n",
       "      <td>0.064913</td>\n",
       "      <td>0.305738</td>\n",
       "      <td>-1.586522</td>\n",
       "      <td>0.362290</td>\n",
       "      <td>-30.126344</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>136.038462</td>\n",
       "      <td>-0.525862</td>\n",
       "      <td>-1.035616</td>\n",
       "      <td>-2.028571</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.399103</td>\n",
       "      <td>-0.255500</td>\n",
       "      <td>-0.089210</td>\n",
       "      <td>-2.458752</td>\n",
       "      <td>-0.004687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>-0.228796</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            retail_1  foreigner_1  institution_1  financial_1  invtrust_1  \\\n",
       "2022-01-13 -0.728308    -1.134320      -3.800544    -6.280593   -1.379315   \n",
       "2022-01-14 -2.922569    -0.961471      -2.248559    -1.318007    0.232121   \n",
       "2022-01-17 -0.141878   -51.541050       0.494157     1.782079    0.050840   \n",
       "2022-01-19 -8.379546    -1.116349      -0.293620    -0.431429    0.985260   \n",
       "2022-01-20 -0.353206    -0.647862      -0.316408   -12.128503   -0.288602   \n",
       "...              ...          ...            ...          ...         ...   \n",
       "2023-03-31  5.045599    -6.505242      -1.378964    -1.455990   -0.755787   \n",
       "2023-04-03  0.823596     0.504240      -1.996055    -1.952853   -1.884406   \n",
       "2023-04-04 -1.106890    -0.814171      -4.739488    -3.959295   -3.598117   \n",
       "2023-04-05 -4.669072     1.004010      -1.191640    -1.446173   -1.103679   \n",
       "2023-04-06  0.064913     0.305738      -1.586522     0.362290  -30.126344   \n",
       "\n",
       "             pension_1  privequity_1     bank_1  insurance_1  financeetc_1  \\\n",
       "2022-01-13    1.202381      8.502452  -3.342857    -0.199498     -3.892308   \n",
       "2022-01-14    1.968292     -1.305245  -1.000000     0.878336     -1.271277   \n",
       "2022-01-17   -0.501553     -2.065171   1.000000    -0.748316     54.666667   \n",
       "2022-01-19   -0.638852     -2.502804  -1.000000     0.671470     -0.823529   \n",
       "2022-01-20    1.911987     -3.847015  -1.000000    -0.384173     -7.476190   \n",
       "...                ...           ...        ...          ...           ...   \n",
       "2023-03-31 -161.913669     -2.436101  10.841270    -0.542801      3.500000   \n",
       "2023-04-03   -0.857066     -0.317107   0.147453    -1.742882     -1.046154   \n",
       "2023-04-04    0.343447      0.037441  -1.591121    -6.087108     14.666667   \n",
       "2023-04-05   -4.333411     -0.980275  -2.604743    -2.743607     -0.420804   \n",
       "2023-04-06    0.369281    136.038462  -0.525862    -1.035616     -2.028571   \n",
       "\n",
       "            ...  ixtr_cr_2  ixut_cr_2  nbi_cr_2  bkx_cr_2    open_2    high_2  \\\n",
       "2022-01-13  ...   0.388204   1.357070 -0.381551  1.397590  0.017926  0.019206   \n",
       "2022-01-14  ...   0.171763  -0.681729 -3.743265  0.696059  0.011480  0.003797   \n",
       "2022-01-17  ...  -0.541227  -0.778962 -1.356175 -0.122211 -0.022642 -0.018844   \n",
       "2022-01-19  ...  -2.901290  -3.069136 -2.962608 -2.703978 -0.001287 -0.003841   \n",
       "2022-01-20  ...  -3.169371  -3.408924 -4.860017 -5.458870 -0.014175 -0.011568   \n",
       "...         ...        ...        ...       ...       ...       ...       ...   \n",
       "2023-03-31  ...   1.057836   1.854493  0.600471  0.843254  0.020833  0.012719   \n",
       "2023-04-03  ...   2.048021   2.039977  0.770444 -0.340135  0.024000  0.020734   \n",
       "2023-04-04  ...   0.670550   1.813086  1.938160  0.332018  0.004710  0.004710   \n",
       "2023-04-05  ...  -3.203092  -0.547517 -0.234654 -2.510967 -0.009375 -0.003125   \n",
       "2023-04-06  ...  -3.399103  -0.255500 -0.089210 -2.458752 -0.004687  0.000000   \n",
       "\n",
       "               low_2   close_2     vol_2  weekday  \n",
       "2022-01-13  0.019455  0.011538  0.124455        2  \n",
       "2022-01-14 -0.001282 -0.012674  0.047903        3  \n",
       "2022-01-17 -0.019084 -0.020279 -0.100512        4  \n",
       "2022-01-19 -0.006485 -0.003881 -0.052837        1  \n",
       "2022-01-20 -0.010403 -0.015484  0.193324        2  \n",
       "...              ...       ...       ...      ...  \n",
       "2023-03-31  0.016103  0.004769  0.368456        3  \n",
       "2023-04-03  0.024116  0.020734  0.285894        4  \n",
       "2023-04-04 -0.001585 -0.001582 -0.238065        0  \n",
       "2023-04-05 -0.014129 -0.006250 -0.216077        1  \n",
       "2023-04-06  0.006349  0.012678 -0.228796        2  \n",
       "\n",
       "[290 rows x 109 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save current prediction data\n",
    "\n",
    "prediction_list = pd.concat([prediction_list, df_base], axis=0)\n",
    "prediction_list = prediction_list[~prediction_list.index.duplicated(keep='last')]\n",
    "\n",
    "directory_for_predict = '../data/data_for_ml/predict/'\n",
    "fname_p = 'prediction_list.pkl'\n",
    "fname_c = 'prediction_list.csv'\n",
    "path_p = directory_for_predict+'prediction/' + fname_p\n",
    "path_c = directory_for_predict+'prediction/' + fname_c\n",
    "prediction_list.to_pickle(path_p)\n",
    "prediction_list.to_csv(path_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 0 005930 ['삼성전자', 'sec']\n",
      "*** 1 035420 ['NAVER', 'naver']\n",
      "*** 2 035720 ['카카오', 'kakao']\n",
      "*** 3 012330 ['현대모비스', 'mobis']\n",
      "*** 4 051910 ['LG화학', 'lgchemical']\n",
      "*** 5 005935 ['삼성전자우', 'secpre']\n",
      "*** 6 000270 ['기아', 'kia']\n",
      "*** 7 373220 ['LG에너지솔루션', 'lgenergy']\n",
      "*** 8 005380 ['현대차', 'hyunmotor']\n",
      "*** 9 000660 ['SK하이닉스', 'skhinix']\n",
      "*** 10 006400 ['삼성SDI', 'sdi']\n"
     ]
    }
   ],
   "source": [
    "# 결과를 회사별로 확인하기\n",
    "directory_for_predict = '../data/data_for_ml/predict/'\n",
    "fname_p = 'prediction_list.pkl'\n",
    "predict_list = pd.read_pickle(directory_for_predict+'prediction/' + fname_p)\n",
    "\n",
    "for i, (key, val) in enumerate(code_good.items()):\n",
    "    print(\"***\", i, key, val)\n",
    "    k =  i * 4\n",
    "    globals()[f'{val[1]}_df'] = predict_list.iloc[:, k:k+4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgenergy_precision</th>\n",
       "      <th>lgenergy_predict</th>\n",
       "      <th>lgenergy_yes</th>\n",
       "      <th>lgenergy_no</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lgenergy_precision lgenergy_predict lgenergy_yes lgenergy_no\n",
       "date                                                                   \n",
       "2023-04-03               0.89                1         0.49        0.51\n",
       "2023-04-04               0.83                0         0.50        0.50\n",
       "2023-04-05               0.83                0         0.48        0.52\n",
       "2023-04-06               0.83                0         0.48        0.52"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
