{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import datetime, time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3f2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cfscrape # 403 forbidden, cloudflare error을 해결하기 위한 모듈\n",
    "import cloudscraper\n",
    "scraper = cloudscraper.create_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08943027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install cfscrape # 403 forbidden, cloudflare error을 해결하기 위한 모듈\n",
    "# import cfscrape\n",
    "# scraper = cfscrape.create_scraper()\n",
    "# # 이후 403 error이 발생한 곳에는 requests 대신 scraper 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac807255",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('.')) \n",
    "sys.path.append(module_path+\"\\\\data\\\\constant\")\n",
    "\n",
    "from constants import US_SECTOR_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selective-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/6.0 (Macintosh; Intel Mac OS X 10_11_5) \\\n",
    "           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "headers = {'Referer': 'https://kr.investing.com/',\n",
    "           'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbcbb53-e0e0-496d-adb7-a57c3341ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df_o, df, dup_col, sort_col):\n",
    "    df_o = pd.concat([df_o, df], ignore_index=True)\n",
    "    df_o.drop_duplicates(subset=[dup_col], keep='last', inplace=True) # dup_col 중첩제거 기준 컬럼 이름: \"time\", \"date\" 등\n",
    "#     df_o.drop_duplicates(subset=[dup_col], keep='first', inplace=True)\n",
    "    df_o.sort_values(by=[df_o.columns[sort_col]], inplace=True) # sort_col 정렬 기준 컬럼 번호\n",
    "    df_o.index = np.arange(0, len(df_o))  # 일련 번호 오름차순으로 재 설정\n",
    "    return df_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98171c7f-8e92-4ea7-a933-c4855c8bb1a8",
   "metadata": {},
   "source": [
    "## 시간별 시세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c80d5a0-f562-4f37-9363-ee1056d572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정일의 시간별 시세 취득을 위한 페이지별 table 데이터 취득. page는 날짜별로 약 40쪽. 09:00:00부터 1분간격으로 15:58:00 까지.\n",
    "def get_piece_time_price(url_t):\n",
    "    res = scraper.get(url_t, headers=headers)\n",
    "    class_name = 'type2'\n",
    "    df = pd.read_html(io.StringIO(str(res.text)), attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "    \n",
    "    df = df.dropna(axis=0) # delete nan rows\n",
    "\n",
    "    df.columns = ['time', 'price', 'change', 'sell', 'buy', 'volume', 'change_volumn'] # rename column\n",
    "    \n",
    "    df['change'] = df['change'].apply(lambda x: int(x[2:]) if x[:2] == '보합' \n",
    "                                      else (-int(x[4:].replace(',','')) if x[:2] == '하락' \n",
    "                                            else int(x[4:].replace(',',''))))  # convert characters to int\n",
    "    \n",
    "    df = df[['time', 'price', 'change', 'volume']]  # delete unnecessary columns\n",
    "    \n",
    "    df['time'] = df['time'].apply(lambda x : datetime.datetime.strptime(x, \"%H:%M\").time())  # convert characters to datetime objet\n",
    "    df['price'] = df['price'].astype(int)\n",
    "    df['volume'] = df['volume'].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699280b8-7e5c-450f-864a-b27d9329a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정일의 시간대별 가격 40쪽을 한개의 df로 묶는 기능\n",
    "def get_time_price(url_base_t, code_com, collect_date):\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # make first data frame\n",
    "    page = str(page_num)\n",
    "    \n",
    "    collect_date_time = collect_date + '170000' # 장종료후 16시 00분 00초에 시간별 시세 추출\n",
    "    \n",
    "    url = url_base_t + '?code=' + code_com + '&thistime=' + collect_date_time + '&page=' + page\n",
    "    df_base = get_piece_time_price(url)\n",
    "    \n",
    "    page_num = page_num + 1\n",
    "    \n",
    "    while True:\n",
    "        page = str(page_num)\n",
    "        \n",
    "        url = url_base_t + '?code=' + code_com + '&thistime=' + collect_date_time + '&page=' + page\n",
    "        \n",
    "        df_p = get_piece_time_price(url)\n",
    "    \n",
    "        df_base = concat_df(df_base, df_p, 'time', 0)\n",
    "        # print('page_num', page_num)\n",
    "        \n",
    "        if df_p['time'].iloc[-1] == datetime.time(9, 00):\n",
    "            break\n",
    "    \n",
    "        page_num = page_num + 1\n",
    "    \n",
    "    df_base['date'] = datetime.datetime.strptime(collect_date, '%Y%m%d') # insert column with collecting date\n",
    "    df_base = df_base[['date', 'time', 'price', 'change', 'volume']]  \n",
    "\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b751c7-63fc-4f11-ac67-1ee03bee6d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_base = 'https://finance.naver.com/item/sise_time.naver'  # sise_date\n",
    "\n",
    "code_dic = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'], \n",
    "        '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "# code_list = list(code_dic.items())\n",
    "# code_company_name = code_list[0]\n",
    "# code = code_company_name[0] # 취득을 원하는 회사 주식 코드\n",
    "\n",
    "c_date = ['20240620', '20240621', '20240624'] # 취득이 필요한 날짜 리트트\n",
    "# collect_date = c_date[2]\n",
    "\n",
    "for i, (code, company_name) in enumerate(code_dic.items()):\n",
    "    for collect_date in c_date:\n",
    "        df_collect = get_time_price(url_base, code, collect_date)\n",
    "        # add logic to save date for each date for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b8c1a5-7115-476d-a2fa-ecd3257fe5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "      <th>change</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>15:50:00</td>\n",
       "      <td>85900</td>\n",
       "      <td>-400</td>\n",
       "      <td>171774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>15:51:00</td>\n",
       "      <td>85900</td>\n",
       "      <td>-400</td>\n",
       "      <td>171815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>15:52:00</td>\n",
       "      <td>85900</td>\n",
       "      <td>-400</td>\n",
       "      <td>171834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>15:53:00</td>\n",
       "      <td>85900</td>\n",
       "      <td>-400</td>\n",
       "      <td>171844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>15:54:00</td>\n",
       "      <td>85900</td>\n",
       "      <td>-400</td>\n",
       "      <td>171845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      time  price  change  volume\n",
       "386 2024-06-24  15:50:00  85900    -400  171774\n",
       "387 2024-06-24  15:51:00  85900    -400  171815\n",
       "388 2024-06-24  15:52:00  85900    -400  171834\n",
       "389 2024-06-24  15:53:00  85900    -400  171844\n",
       "390 2024-06-24  15:54:00  85900    -400  171845"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collect.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae7fc7-ceb8-4886-af2c-f856d2403168",
   "metadata": {},
   "source": [
    "## 일별시세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebbbd01b-12d7-4956-9bec-301933b1b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자별 주식 데이터를 페이지별로 10개씩 취득\n",
    "def get_piece_date_price(url_d):\n",
    "    res = scraper.get(url_d, headers=headers)\n",
    "    class_name = 'type2'\n",
    "    df = pd.read_html(io.StringIO(str(res.text)), attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "    \n",
    "    df = df.dropna(axis=0) # delete nan rows\n",
    "\n",
    "    df.columns = ['date', 'close', 'close_change', 'open', 'high', 'low', 'volume'] # rename column\n",
    "\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.datetime.strptime(x, '%Y.%m.%d')) # convert character to datetime object\n",
    "\n",
    "    df['close_change'] = df['close_change'].apply(lambda x: int(x[2:]) if x[:2] == '보합' \n",
    "                                  else (-int(x[4:].replace(',','')) if x[:2] == '하락' \n",
    "                                        else int(x[4:].replace(',',''))))  # convert characters to int\n",
    "    \n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'close_change', 'volume']]  # rearrange columns\n",
    "    \n",
    "    df['open'] = df['open'].astype(int)\n",
    "    df['high'] = df['high'].astype(int)\n",
    "    df['low'] = df['low'].astype(int)\n",
    "    df['close'] = df['close'].astype(int)\n",
    "    df['volume'] = df['volume'].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "309638e3-7ee2-4b51-b67c-c12e9f20f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개씩의 일자별 데이터를 원하는 일자부터 현재일자까지 합하어 취득\n",
    "def get_date_price(url_base_d, code_com):\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # make first data frame\n",
    "    page = str(page_num)\n",
    "    \n",
    "    url_date = url_base_d + '?code=' + code_com + '&page=' + page\n",
    "    \n",
    "    df_base = get_piece_date_price(url_date)\n",
    "    \n",
    "    page_num = page_num + 1\n",
    "    \n",
    "    while True:\n",
    "        page = str(page_num)\n",
    "        \n",
    "        url_date = url_base_d + '?code=' + code_com + '&page=' + page\n",
    "        \n",
    "        df_p = get_piece_date_price(url_date)\n",
    "    \n",
    "        df_base = concat_df(df_base, df_p, 'date', 0)\n",
    "        # print('page_num', page_num)\n",
    "\n",
    "        startdate_str = '2021/12/23 00:00:00' # 데이터 수집 시작 일자\n",
    "        # startdate_str = '2024/5/29 00:00:00'\n",
    "        startdate = datetime.datetime.strptime(startdate_str, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "        if (startdate == df_base['date']).any():\n",
    "            break\n",
    "        # print(\"page_num\", page_num)\n",
    "        # print(df_p)\n",
    "        page_num = page_num + 1\n",
    "    \n",
    "    # df_base['date'] = datetime.datetime.strptime(collect_date, '%Y.%m.%d') # insert column with collecting date\n",
    "    # df_base = df_base[['date', 'time', 'price', 'change', 'volume']]  \n",
    "\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8624b98e-d394-4d8d-aeeb-545d7fcdd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://finance.naver.com/item/sise_day.naver'  # sise_day\n",
    "\n",
    "code_dic = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'], \n",
    "        '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "\n",
    "code_dic = {'005930': ['삼성전자', 'sec'],}\n",
    "\n",
    "for i, (code, company_name) in enumerate(code_dic.items()):\n",
    "    df_collect = get_date_price(url_base, code)\n",
    "    # add logic to save date for each date for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6669a8ad-efec-4a67-be11-700c6c08bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_change</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>76800</td>\n",
       "      <td>78000</td>\n",
       "      <td>76800</td>\n",
       "      <td>78000</td>\n",
       "      <td>200</td>\n",
       "      <td>13108479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>77600</td>\n",
       "      <td>77800</td>\n",
       "      <td>76800</td>\n",
       "      <td>77100</td>\n",
       "      <td>-900</td>\n",
       "      <td>11264375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>77900</td>\n",
       "      <td>78300</td>\n",
       "      <td>77500</td>\n",
       "      <td>78100</td>\n",
       "      <td>1000</td>\n",
       "      <td>14245298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>78900</td>\n",
       "      <td>79400</td>\n",
       "      <td>78800</td>\n",
       "      <td>79400</td>\n",
       "      <td>1300</td>\n",
       "      <td>17105892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>79800</td>\n",
       "      <td>80000</td>\n",
       "      <td>79300</td>\n",
       "      <td>79900</td>\n",
       "      <td>500</td>\n",
       "      <td>13577498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close  close_change    volume\n",
       "0 2021-12-17  76800  78000  76800  78000           200  13108479\n",
       "1 2021-12-20  77600  77800  76800  77100          -900  11264375\n",
       "2 2021-12-21  77900  78300  77500  78100          1000  14245298\n",
       "3 2021-12-22  78900  79400  78800  79400          1300  17105892\n",
       "4 2021-12-23  79800  80000  79300  79900           500  13577498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d4419-038b-4f9f-bb67-14562fd58e62",
   "metadata": {},
   "source": [
    "## 여기까지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75c863-3367-4a5f-847c-e8d0c9fba263",
   "metadata": {},
   "source": [
    "### 아래는 지울 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142fef8-6354-4b1b-a207-519b5c30a3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11069a4-0994-41cc-9259-bfde6b523429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73a05c-c2f0-4a06-8aec-3ab52cf2a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488684ec-93f0-4ea0-a92d-898a71afafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0407ea-73f5-41f3-bb6f-0203cdba86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date\topen\thigh\tlow\tclose\tclose_cr\tvol\n",
    "df_get = df[['date', 'open', 'high', 'low', 'close', 'close_cr', 'vol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9434e3-e129-4240-81ea-6136953693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = ['date', 'time', 'price', 'change', 'change(%)', 'amount', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4567c-1b0b-4722-8278-e03532762192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d23980-a986-4ae7-a0cc-a16847ed2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2,2]= char1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca1c8c-07ba-4915-a18d-831db7672c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b8b17-1615-486c-a855-b19acb93716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['change'].str[:2] == '상승']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0689110-8838-45a2-b0f7-f103e67f253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change'] = df['change'].apply(lambda x: int(x[2:]) if x[:2] == '보합' \n",
    "                                  else (-int(x[4:].replace(',','')) if x[:2] == '하락' \n",
    "                                        else int(x[4:].replace(',',''))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1dc9c-2255-464c-aa76-a147eb2f09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb9fac-36b4-42f0-9ee3-48d10d583cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['date', 'time', 'price', 'change', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b096e-580e-440b-9269-bbbf303b1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452fbf50-9f51-42f5-a9e4-83642b427b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = df['time'].apply(lambda x : datetime.datetime.strptime(x, \"%H:%M\").time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a64f44-b8ad-4ee9-8a27-ad773e73f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ed2c5-633b-46db-9037-107222a50924",
   "metadata": {},
   "outputs": [],
   "source": [
    "char1 = df.iloc[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd0e50-68c8-45b4-bd70-1fe2ec7b7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e94ce9-cc70-4d35-92c8-7383329aa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "char[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16afe4e-1561-4760-80bf-3f449cc7f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if char[:2] == '상승':\n",
    "    new_char = int(char[4:])\n",
    "    print(\"1\")\n",
    "elif char[:2] == '하락':\n",
    "    new_char = char[4:]\n",
    "    print(\"2\")\n",
    "elif char[:2] == '보합':\n",
    "    new_char = int(char[2:])\n",
    "    print(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6f555-e17f-44e6-a3d4-879c29935bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5c381-1a6e-450e-8512-bfdea143d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c480d9-de60-4bbe-8c1d-0400b2e19fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_char*df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef148f57-64be-4b4d-ace0-3f46da4fe71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata.reset_index('Date', inplace=True)\n",
    "rdata['Date'] = rdata['Date'].dt.date  # datetime64 to datetime.date()\n",
    "rdata = rdata[(rdata['Date'] <= enddate) & (rdata['Date'] >= startdate)] \n",
    "rdata['temp'] = rdata['Close'].shift(1)\n",
    "val_temp = (rdata['Close'] - rdata['temp'])/rdata['temp']*100\n",
    "rdata[f'{col_name}_cr'] = val_temp.map(\"{:.2f}%\".format)\n",
    "rdata = rdata[['Date', 'Close', 'Open', 'High', 'Low', 'Volume', f'{col_name}_cr']] # 필요한 column만 남김\n",
    "rdata.columns = ['date', f'{col_name}', 'open', 'high', 'low', 'volume', f'{col_name}_cr'] # column이름 통일\n",
    "rdata.reset_index(drop=True, inplace=True) # index번호를 0부터 재정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc05f3-dc56-46f9-8bc0-b333990e2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cfe54-489a-4a2e-a173-5ae21eb2b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1a28-f85f-4cc6-b35a-1a03e0e56e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466bcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pickle(df, pkl_name):\n",
    "    pkl_directory = 'data/common_pkl/'\n",
    "    try:\n",
    "        if not os.path.exists(pkl_directory):\n",
    "            os.makedirs(pkl_directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "    # 데이터 저장: ../data/spx.pkl\n",
    "    df.to_pickle(pkl_directory+pkl_name)\n",
    "    df.to_csv(pkl_directory+pkl_name.replace('pkl','csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904330d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(pkl_name):\n",
    "# 데이터 로드\n",
    "    pkl_directory = 'data/common_pkl/'\n",
    "    df = pd.read_pickle(pkl_directory+pkl_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e62780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, column):\n",
    "           \n",
    "    count = 0\n",
    "    while True:\n",
    "        try :\n",
    "            res = scraper.get(url, headers=headers)\n",
    "            print(\"t1\", res.status_code)\n",
    "#             res = requests.get(url, headers=headers)\n",
    "#             class_name = 'w-full text-xs leading-4 overflow-x-auto freeze-column-w-1'\n",
    "# 위의 class_name 명칭은 수시로 바뀌므로 새롭게 수정해 주어야 함.\n",
    "            class_name = 'freeze-column-w-1 w-full overflow-x-auto text-xs leading-4'\n",
    "            # df = pd.read_html(res.text, attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "            df = pd.read_html(io.StringIO(str(res.text)), attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "#             res = scraper.get(url, headers=headers)  # 변경전\n",
    "#             df = pd.read_html(res.text, attrs={\"id\": \"curr_table\"}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "            break\n",
    "        except:\n",
    "            try:\n",
    "                # res = scraper.get(url, headers=headers)\n",
    "                res = requests.get(url, headers=headers)\n",
    "                print(\"t2\", res.status_code)\n",
    "                # df = pd.read_html(res.text, attrs={\"data-test\": \"historical-data-table\"}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "                df = pd.read_html(io.StringIO(str(res.text)), attrs={\"data-test\": \"historical-data-table\"}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        finally:\n",
    "            time.sleep(1)\n",
    "            print(\"t3\")\n",
    "            count += 1\n",
    "            if count > 5 :\n",
    "                raise ValueError('The url request is delaying')\n",
    "                break           \n",
    "\n",
    "    df.columns = column\n",
    "    correct_date_format(df)\n",
    "    df.sort_values(by=[df.columns[0]], inplace=True)\n",
    "    df.index = np.arange(0, len(df))  # 일련 번호 오름차순으로 재 설정\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a455de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df_o, df):\n",
    "    df_o = pd.concat([df_o, df], ignore_index=True)\n",
    "    df_o.drop_duplicates(subset=['date'], keep='last', inplace=True)\n",
    "#     df_o.drop_duplicates(subset=['date'], keep='first', inplace=True)\n",
    "    df_o.sort_values(by=[df_o.columns[0]], inplace=True)\n",
    "    df_o.index = np.arange(0, len(df_o))  # 일련 번호 오름차순으로 재 설정\n",
    "    return df_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9731a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pickle(df, pkl_name):\n",
    "    df_o = read_pickle(pkl_name)\n",
    "    try:  # convert timestamp to datetime.datetime.date\n",
    "        df_o['date'] = df_o['date'].apply(lambda x: datetime.datetime.date(x))\n",
    "    except:\n",
    "        pass\n",
    "    df_o = concat_df(df_o, df)\n",
    "    \n",
    "    make_pickle(df_o, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat data from yfinance\n",
    "def reformat_df(df, col_name):\n",
    "    df = df.reset_index('Date')\n",
    "    df.drop(labels='Adj Close', axis=1, inplace=True)\n",
    "    df = df[['Date', 'Close', 'Open', 'High', 'Low', 'Volume']]\n",
    "    df.columns = ['date', col_name, 'open', 'high', 'low', 'volume']\n",
    "    df['temp'] = df[col_name].shift(1)\n",
    "    df[col_name+'_cr'] = ((df[col_name] - df['temp'])/df['temp']*100).apply(lambda x: f'{x:.2f}%')\n",
    "    df.drop(labels='temp', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd243e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_data(ticker, startdate, enddate, col_name):\n",
    "    while True:\n",
    "        ydata = yf.Ticker(ticker)\n",
    "        rdata = ydata.history(period=\"5y\") # 오늘부터 3년치\n",
    "        if len(rdata) <= 100: # 인터넷 속도로 인한 데이터 취득이 되지 않았을 때 임의의 수(100)으로 비교\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "    rdata.reset_index('Date', inplace=True)\n",
    "    rdata['Date'] = rdata['Date'].dt.date  # datetime64 to datetime.date()\n",
    "    rdata = rdata[(rdata['Date'] <= enddate) & (rdata['Date'] >= startdate)] \n",
    "    rdata['temp'] = rdata['Close'].shift(1)\n",
    "    val_temp = (rdata['Close'] - rdata['temp'])/rdata['temp']*100\n",
    "    rdata[f'{col_name}_cr'] = val_temp.map(\"{:.2f}%\".format)\n",
    "    rdata = rdata[['Date', 'Close', 'Open', 'High', 'Low', 'Volume', f'{col_name}_cr']] # 필요한 column만 남김\n",
    "    rdata.columns = ['date', f'{col_name}', 'open', 'high', 'low', 'volume', f'{col_name}_cr'] # column이름 통일\n",
    "    rdata.reset_index(drop=True, inplace=True) # index번호를 0부터 재정리\n",
    "    return rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83760063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startdate = datetime.datetime(2021,12,25)\n",
    "startdate = datetime.date(2021,12,25)\n",
    "# enddate = datetime.datetime(2023,3,23)\n",
    "enddate = datetime.date.today() + datetime.timedelta(days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca633db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # spx = pdr.get_data_yahoo('^SPX', start=startdate, end=enddate)\n",
    "# # df = reformat_df(spx, 'spx')\n",
    "# # make_pickle(df, 'spx.pkl')\n",
    "\n",
    "# # spx는 yahoo에서 최근 하루만 제공하기 때문에 investing을 계속 사용함\n",
    "# spx_url = 'https://kr.investing.com/indices/us-spx-500-historical-data'\n",
    "# spx = ['date', 'spx', 'open', 'high', 'low', 'volume', 'spx_cr']\n",
    "# pkl_name = 'spx.pkl'\n",
    "# df = get_data(spx_url,spx)\n",
    "\n",
    "# update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b3b5c-245b-41ee-b634-9f1de7b6315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx = get_ticker_data('^SPX', startdate, enddate, 'spx')\n",
    "make_pickle(spx, 'spx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dji = get_ticker_data('^DJI', startdate, enddate, 'dji')\n",
    "make_pickle(dji, 'dji.pkl')\n",
    "\n",
    "# 시간대별로 막혀 있어서 아래 것은 사용하지 않음 (미국 개장시간대에서만 열림)\n",
    "# dji = pdr.get_data_yahoo('^DJI', start=startdate, end=enddate)\n",
    "# df = reformat_df(dji, 'dji')\n",
    "# make_pickle(df, 'dji.pkl')\n",
    "\n",
    "# 아래 investing은 vol자료에 차이가 있어 사용하지 않음.\n",
    "# dji_url = 'https://www.investing.com/indices/us-30-historical-data'\n",
    "# dji = ['date', 'dji', 'open', 'high', 'low', 'volume', 'dji_cr']\n",
    "# pkl_name = 'dji.pkl'\n",
    "# df = get_data(dji_url,dji)\n",
    "\n",
    "# update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ixic = get_ticker_data('^IXIC', startdate, enddate, 'ixic')\n",
    "make_pickle(ixic, 'nas.pkl')\n",
    "\n",
    "# ixic = pdr.get_data_yahoo('^IXIC', start=startdate, end=enddate)\n",
    "# df = reformat_df(ixic, 'ixic')\n",
    "# make_pickle(df, 'nas.pkl')\n",
    "\n",
    "# nas_url = 'https://kr.investing.com/indices/nasdaq-composite-historical-data'\n",
    "# ixic = ['date', 'ixic', 'open', 'high', 'low', 'volume', 'ixic_cr']\n",
    "# pkl_name = 'nas.pkl'\n",
    "# df = get_data(nas_url,ixic)\n",
    "\n",
    "# update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sox = get_ticker_data('^SOX', startdate, enddate, 'sox')\n",
    "make_pickle(sox, 'sox.pkl')\n",
    "\n",
    "# sox = pdr.get_data_yahoo('^SOX', start=startdate, end=enddate)\n",
    "# df = reformat_df(sox, 'sox')\n",
    "# make_pickle(df, 'sox.pkl')\n",
    "\n",
    "# sox_url = 'https://kr.investing.com/indices/phlx-semiconductor-historical-data'\n",
    "# sox = ['date', 'sox', 'open', 'high', 'low', 'volume', 'sox_cr']\n",
    "# pkl_name = 'sox.pkl'\n",
    "# df = get_data(sox_url,sox)\n",
    "\n",
    "# update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ac32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vix = get_ticker_data('^VIX', startdate, enddate, 'vix')\n",
    "make_pickle(vix, 'vix.pkl')\n",
    "\n",
    "# vix = pdr.get_data_yahoo('^VIX', start=startdate, end=enddate)\n",
    "# df = reformat_df(vix, 'vix')\n",
    "# make_pickle(df, 'vix.pkl')\n",
    "\n",
    "# vix_url = 'https://kr.investing.com/indices/volatility-s-p-500-historical-data'\n",
    "# vix = ['date', 'vix', 'open', 'high', 'low', 'volume', 'vix_cr']\n",
    "# pkl_name = 'vix.pkl'\n",
    "# df = get_data(vix_url,vix)\n",
    "\n",
    "# update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_bond_10yr_url = 'https://kr.investing.com/rates-bonds/south-korea-10-year-bond-yield-historical-data'\n",
    "kor_10yr = ['date', 'bond_kor_10', 'open', 'high', 'low', 'bond_kor_10_cr']\n",
    "pkl_name = 'kor_10yr_bond.pkl'\n",
    "df = get_data(kor_bond_10yr_url,kor_10yr)\n",
    "\n",
    "update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048eb07-357e-433c-9ef3-bd1b8ee74e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://kr.investing.com/rates-bonds/south-korea-10-year-bond-yield-historical-data'\n",
    "res = requests.get(url, headers=headers)\n",
    "print(res.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc71d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_bond_2yr_url = 'https://kr.investing.com/rates-bonds/south-korea-2-year-bond-yield-historical-data'\n",
    "kor_2yr = ['date', 'bond_kor_2', 'open', 'high', 'low','bond_kor_2_cr']\n",
    "pkl_name = 'kor_2yr_bond.pkl'\n",
    "df = get_data(kor_bond_2yr_url,kor_2yr)\n",
    "\n",
    "update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "krw_rate_url = 'https://kr.investing.com/currencies/usd-krw-historical-data'\n",
    "krw_rate = ['date', 'krw', 'open', 'high', 'low', 'vol', 'krw_cr']\n",
    "pkl_name = 'krw_rate.pkl'\n",
    "df = get_data(krw_rate_url,krw_rate)\n",
    "\n",
    "update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-driving",
   "metadata": {},
   "source": [
    "#### get append cpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_url = 'https://www.investing.com/economic-calendar/cpi-733'\n",
    "cpi_column = ['date', 'time', 'cpi', 'cpi_anticipated', 'cpi_previous', 'none']\n",
    "pkl_name = 'cpi.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2f267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = scraper.get(cpi_url, headers=headers)\n",
    "# res = requests.get(cpi_url, headers=headers)\n",
    "# df = pd.read_html(res.text, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "df = pd.read_html(io.StringIO(str(res.text)), flavor=[\"lxml\", \"bs4\"])[0]\n",
    "df.columns = cpi_column\n",
    "df['time'] = df['time'].apply(lambda x : datetime.datetime.strptime(x, \"%H:%M\").time())\n",
    "df['date'] = df['date'].apply(lambda x : datetime.datetime.strptime(x[:12], \"%b %d, %Y\"))\n",
    "\n",
    "df = df[['date', 'cpi', 'cpi_anticipated', 'cpi_previous']]\n",
    "\n",
    "try: # convert timestamp to datetime.datetime.date\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.datetime.date(x))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df.sort_values(by=['date'], inplace=True)\n",
    "\n",
    "update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-allergy",
   "metadata": {},
   "source": [
    "#### get append fear and greed\n",
    "##### 2020년 9월 21일부터  2021년 1월 21일까지 데이터는 이상 데이터 로 나중에 수정해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ca824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp_to_date(x):\n",
    "    dt = datetime.datetime.fromtimestamp(x / 1000, tz=pytz.utc) # UTC에서 변환 불필요.\n",
    "#     tzone = pytz.timezone('US/Eastern')\n",
    "#     tzone = pytz.timezone('Asia/Seoul')\n",
    "#     loc_dt = dt.astimezone(tzone)\n",
    "    loc_dt = dt\n",
    "    return loc_dt.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과거 데이터 (fear_greed_old_to_20200918.pkl) 에 rating column을 추가한 내용\n",
    "# 한번만 사용하고 이후 사용하지 않음\n",
    "\n",
    "def convert_to_rating(x):\n",
    "    if x < 25 :\n",
    "        rating = 'extreme fear'\n",
    "    elif x < 45 :\n",
    "        rating = 'fear'\n",
    "    elif x < 55 :\n",
    "        rating = 'neutral'\n",
    "    elif x < 75 :\n",
    "        rating = 'greed'\n",
    "    elif x <= 100 :\n",
    "        rating = 'extreme greed'\n",
    "\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "today_p = today.strftime('%Y%m%d')\n",
    "diff_days = datetime.timedelta(days=40)\n",
    "today = today - diff_days\n",
    "start_date = today.strftime('%Y-%m-%d')  # 30일전부터 자료 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://production.dataviz.cnn.io/index/fearandgreed/graphdata\"\n",
    "pkl_name = 'fear_greed.pkl'\n",
    "# start_date = '2020-07-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"{}/{}\".format(url, start_date), headers=headers)\n",
    "data = r.json()\n",
    "\n",
    "fg_data = data['fear_and_greed_historical']['data']\n",
    "df = pd.DataFrame(fg_data)\n",
    "\n",
    "df.columns = ['date', 'fg_index', 'rating']\n",
    "df['date'] = df['date'].apply(lambda x: convert_timestamp_to_date(x))\n",
    "df['fg_index'] = df['fg_index'].apply(lambda x: round(x))\n",
    "\n",
    "df.sort_values(by=[df.columns[0]], inplace=True)\n",
    "df.index = np.arange(0, len(df))  # 일련 번호 오름차순으로 재 설정\n",
    "df.drop_duplicates(subset=['date'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o = read_pickle(pkl_name)\n",
    "df_o['date'] = df_o['date'].apply(lambda x : datetime.datetime.strftime(x, \"%Y-%m-%d\"))\n",
    "df_o['date'] = df_o['date'].apply(lambda x : datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "try:  # convert timestamp to datetime.datetime.date\n",
    "    df_o['date'] = df_o['date'].apply(lambda x: datetime.datetime.date(x))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_o = concat_df(df_o, df)\n",
    "\n",
    "# 분석시 제외. 추후 보강 2023년 8월 이후에 추가 할지 결정해야 함.\n",
    "make_pickle(df_o, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7f19a",
   "metadata": {},
   "source": [
    "#### get and append gold price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_url = 'https://www.usagold.com/daily-gold-price-history/'\n",
    "# pkl_name = 'gold.pkl'\n",
    "\n",
    "# res = requests.get(gold_url, headers=headers)\n",
    "## df = pd.read_html(res.text, flavor=[\"lxml\", \"bs4\"])\n",
    "# df = pd.read_html(io.StringIO(str(res.text)), flavor=[\"lxml\", \"bs4\"])\n",
    "# df = df[0].drop(0) # delete empty first row\n",
    "# df.columns = ['date', 'gold']\n",
    "# df['date'] = df['date'].apply(lambda x : datetime.datetime.strptime(x, \"%d %b %Y\"))\n",
    "# df.sort_values(by=['date'], inplace=True)\n",
    "# df.drop_duplicates(subset=['date'], inplace=True) \n",
    "\n",
    "# # 분석시 제외. 추후 보강 현재는 빠짐.\n",
    "# update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = get_ticker_data('GC=F', startdate, enddate, 'gold')\n",
    "make_pickle(gold, 'gold.pkl')\n",
    "\n",
    "# # Gold Apr 23 (GC=F)\n",
    "# df = pdr.get_data_yahoo('GC=F', start=startdate, end=enddate)\n",
    "# df = reformat_df(df, 'gold')\n",
    "# make_pickle(df, 'gold.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6771fd5",
   "metadata": {},
   "source": [
    "### fed 금리 get append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27dd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_url = 'https://www.investing.com/economic-calendar/interest-rate-decision-168/'\n",
    "interest_column = ['date', 'time', 'fed_rate', 'fed_rate_fore', 'fed_rate_prev', 'none']\n",
    "pkl_name = 'fed_rate.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e24196",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scraper.get(interest_url, headers=headers)\n",
    "# res = requests.get(interest_url, headers=headers)\n",
    "# df = pd.read_html(res.text, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "df = pd.read_html(io.StringIO(str(res.text)), flavor=[\"lxml\", \"bs4\"])[0]\n",
    "df.columns = interest_column\n",
    "\n",
    "df.replace(np.nan, '', inplace=True)\n",
    "\n",
    "df['date'] = df['date'].apply(lambda x : datetime.datetime.strptime(x[:12], \"%b %d, %Y\"))\n",
    "df['time'] = df['time'].apply(lambda x : datetime.datetime.strptime(x, \"%H:%M\").time())\n",
    "df.sort_values(by=['date'], inplace=True)\n",
    "df.drop_duplicates(subset=['date'], inplace=True) \n",
    "# convert from timestampe to datetime\n",
    "df['date'] = df['date'].apply(lambda x: datetime.datetime.date(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매일매일의 데이터가 없어서 분석시 제외. 추후 보강 현재는 빠짐.\n",
    "update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddc5b3",
   "metadata": {},
   "source": [
    "### 한국은행 금리 get append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827eed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_url = 'https://www.bok.or.kr/portal/singl/baseRate/list.do?dataSeCd=01&menuNo=200643'\n",
    "pkl_name = 'bok_rate.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dd0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = requests.get(kor_url, headers=headers, verify=certifi.where())\n",
    "res = requests.get(kor_url, headers=headers)\n",
    "df = pd.read_html(io.StringIO(str(res.text)), attrs = {'class': 'fixed'}, flavor=[\"lxml\", \"bs4\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75736723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=  ['release_yr', 'release_date', 'bok_rate']\n",
    "df_date_temp = df['release_yr'].astype('str')+df['release_date']\n",
    "df['date'] = df_date_temp.apply(lambda x : datetime.datetime.strptime(x, \"%Y%m월 %d일\"))\n",
    "df.sort_values(by=['date'], inplace=True)\n",
    "df.drop_duplicates(subset=['date'], inplace=True) \n",
    "\n",
    "df = df[['date', 'bok_rate']] # leave only valid columns\n",
    "\n",
    "# convert from timestampe to datetime\n",
    "df['date'] = df['date'].apply(lambda x: datetime.datetime.date(x)) \n",
    "\n",
    "# 매일매일의 데이터가 없어서 분석시 제외. 추후 보강 현재는 빠짐.\n",
    "update_pickle(df, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0639aa",
   "metadata": {},
   "source": [
    "### US Sector Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# startdate = datetime.datetime(2021,12,25)\n",
    "# enddate = datetime.datetime(2023,3,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ticker, shortname, filename]\n",
    "us_sector_list = US_SECTOR_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in us_sector_list:\n",
    "    make_pickle(get_ticker_data(sector[0], startdate, enddate, sector[1]), sector[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11977f",
   "metadata": {},
   "source": [
    "### 여기까지 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = '^SP500-40'\n",
    "ydata = yf.Ticker(ticker)\n",
    "rdata = ydata.history(period=\"2y\") # 오늘부터 2년치\n",
    "rdata.reset_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ceba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata['Date'] = rdata['Date'].dt.date  # datetime64 to datetime.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571365a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d824cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata['Date'] = rdata['Date'].dt.date  # datetime64 to datetime.date()\n",
    "rdata = rdata[(rdata['Date'] <= enddate) & (rdata['Date'] >= startdate)] \n",
    "rdata['temp'] = rdata['Close'].shift(1)\n",
    "val_temp = (rdata['Close'] - rdata['temp'])/rdata['temp']*100\n",
    "rdata[f'{col_name}_cr'] = val_temp.map(\"{:.2f}%\".format)\n",
    "rdata = rdata[['Date', 'Close', 'Open', 'High', 'Low', 'Volume', f'{col_name}_cr']] # 필요한 column만 남김\n",
    "rdata.columns = ['date', f'{col_name}', 'open', 'high', 'low', 'volume', f'{col_name}_cr'] # column이름 통일\n",
    "rdata.reset_index(drop=True, inplace=True) # index번호를 0부터 재정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab395b",
   "metadata": {},
   "source": [
    "### 아래는 삭제 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ea894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # S&P 500 Financials (SPSY), ^SP500-40\n",
    "# # spsy_url = 'https://www.investing.com/indices/s-p-500-financial-historical-data'\n",
    "# spsy = get_ticker_data('^SP500-40', startdate, enddate, 'spsy')\n",
    "# make_pickle(spsy, 'spsy.pkl')\n",
    "\n",
    "# # df = pdr.get_data_yahoo('^SP500-40', start=startdate, end=enddate)\n",
    "# # df = reformat_df(df, 'spsy')\n",
    "# # make_pickle(df, 'spsy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # S&P 500 Energy (SPNY), ^GSPE\n",
    "# # spny_url = 'https://www.investing.com/indices/s-p-500-energy-historical-data'\n",
    "# spny = get_ticker_data('^GSPE', startdate, enddate, 'spny')\n",
    "# make_pickle(spny, 'spny.pkl')\n",
    "\n",
    "# # df = pdr.get_data_yahoo('^GSPE', start=startdate, end=enddate)\n",
    "# # df = reformat_df(df, 'spny')\n",
    "# # make_pickle(df, 'spny.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spxhc_url = 'https://www.investing.com/indices/s-p-500-health-care-historical-data'\n",
    "# # S&P 500 Health Care (SPXHC), ^SP500-35\n",
    "# spxhc = get_ticker_data('^SP500-35', startdate, enddate, 'spxhc')\n",
    "# make_pickle(spxhc, 'spxhc.pkl')\n",
    "\n",
    "# # spxhc = pdr.get_data_yahoo('^SP500-35', start=startdate, end=enddate)\n",
    "# # df = reformat_df(spxhc, 'spxhc')\n",
    "# # make_pickle(df, 'spxhc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrcd_url = 'https://www.investing.com/indices/s-p-500-consumer-discretionary-historical-data'\n",
    "# # S&P 500 Consumer Discretionary (SPLRCD), ^SP500-25\n",
    "# splrcd = get_ticker_data('^SP500-25', startdate, enddate, 'splrcd')\n",
    "# make_pickle(splrcd, 'splrcd.pkl')\n",
    "\n",
    "# # splrcd = pdr.get_data_yahoo('^SP500-25', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrcd, 'splrcd')\n",
    "# # make_pickle(df, 'splrcd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrci_url = 'https://www.investing.com/indices/s-p-500-industrials-historical-data'\n",
    "# # S&P 500 Industrials (SPLRCI), ^SP500-20\n",
    "# splrci = get_ticker_data('^SP500-20', startdate, enddate, 'splrci')\n",
    "# make_pickle(splrci, 'splrci.pkl')\n",
    "\n",
    "# # splrci = pdr.get_data_yahoo('^SP500-20', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrci, 'splrci')\n",
    "# # make_pickle(df, 'splrci.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896816aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrcu_url = 'https://www.investing.com/indices/s-p-500-utilities-historical-data'\n",
    "# # S&P 500 Utilities (SPLRCU), ^SP500-55\n",
    "# splrcu = get_ticker_data('^SP500-55', startdate, enddate, 'splrcu')\n",
    "# make_pickle(splrcu, 'splrcu.pkl')\n",
    "\n",
    "# # splrcu = pdr.get_data_yahoo('^SP500-55', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrcu, 'splrcu')\n",
    "# # make_pickle(df, 'splrcu.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b057482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrcs_url = 'https://www.investing.com/indices/s-p-500-consumer-staples-historical-data'\n",
    "# # S&P 500 Consumer Staples (SPLRCS), ^SP500-30\n",
    "# splrcs = get_ticker_data('^SP500-30', startdate, enddate, 'splrcs')\n",
    "# make_pickle(splrcs, 'splrcs.pkl')\n",
    "\n",
    "# # splrcs = pdr.get_data_yahoo('^SP500-30', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrcs, 'splrcs')\n",
    "# # make_pickle(df, 'splrcs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee39090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrct_url = 'https://www.investing.com/indices/s-p-500-information-technology-historical-data'\n",
    "# # S&P 500 Information Technology (SPLRCT), ^SP500-45\n",
    "# splrct = get_ticker_data('^SP500-45', startdate, enddate, 'splrct')\n",
    "# make_pickle(splrct, 'splrct.pkl')\n",
    "\n",
    "# # splrct = pdr.get_data_yahoo('^SP500-45', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrct, 'splrct')\n",
    "# # make_pickle(df, 'splrct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43adf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrcl_url = 'https://www.investing.com/indices/s-p-500-telecom-services-historical-data'\n",
    "# # S&P 500 Telecom Services (SPLRCL), ^SP500-50\n",
    "# splrcl = get_ticker_data('^SP500-50', startdate, enddate, 'splrcl')\n",
    "# make_pickle(splrcl, 'splrcl.pkl')\n",
    "\n",
    "# # splrcl = pdr.get_data_yahoo('^SP500-50', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrcl, 'splrcl')\n",
    "# # make_pickle(df, 'splrcl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9347df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # splrcm_url = 'https://www.investing.com/indices/s-p-500-materials-historical-data'\n",
    "# # S&P 500 Materials (SPLRCM), ^SP500-15\n",
    "# splrcm = get_ticker_data('^SP500-15', startdate, enddate, 'splrcm')\n",
    "# make_pickle(splrcm, 'splrcm.pkl')\n",
    "\n",
    "# # splrcm = pdr.get_data_yahoo('^SP500-15', start=startdate, end=enddate)\n",
    "# # df = reformat_df(splrcm, 'splrcm')\n",
    "# # make_pickle(df, 'splrcm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f51910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixbk_url = 'https://www.investing.com/indices/nasdaq-bank-historical-data'\n",
    "# # NASDAQ Bank (IXBK), ^BANK\n",
    "# ixbk = get_ticker_data('^BANK', startdate, enddate, 'ixbk')\n",
    "# make_pickle(ixbk, 'ixbk.pkl')\n",
    "\n",
    "# # ixbk = pdr.get_data_yahoo('^BANK', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixbk, 'ixbk')\n",
    "# # make_pickle(df, 'ixbk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fc0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yahoo에서는 하루만 잡힘. investing.com에서는 자료가 있으나 skip (나중에 보강)\n",
    "# ixf_url = 'https://www.investing.com/indices/nasdaq-financial-100-historical-data'\n",
    "# # NASDAQ Financial 100 (IXF), ^IXF\n",
    "# ixf = pdr.get_data_yahoo('^IXF', start=startdate, end=enddate)\n",
    "# df = reformat_df(ixf, 'ixf')\n",
    "# make_pickle(df, 'ixf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d081094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixfn_url = 'https://www.investing.com/indices/nasdaq-other-finance-historical-data'\n",
    "# # NASDAQ Other Finance (IXFN), ^OFIN\n",
    "# ixfn = get_ticker_data('^OFIN', startdate, enddate, 'ixfn')\n",
    "# make_pickle(ixfn, 'ixfn.pkl')\n",
    "\n",
    "# # ixfn = pdr.get_data_yahoo('^OFIN', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixfn, 'ixfn')\n",
    "# # make_pickle(df, 'ixfn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1556dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixid_url = 'https://www.investing.com/indices/nasdaq-industrial-historical-data'\n",
    "# # NASDAQ Industrial (IXID), ^INDS\n",
    "# ixid = get_ticker_data('^INDS', startdate, enddate, 'ixid')\n",
    "# make_pickle(ixid, 'ixid.pkl')\n",
    "\n",
    "# # ixid = pdr.get_data_yahoo('^INDS', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixid, 'ixid')\n",
    "# # make_pickle(df, 'ixid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ecd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixis_url = 'https://www.investing.com/indices/nasdaq-insurance-historical-data'\n",
    "# # NASDAQ Insurance (IXIS), ^INSR\n",
    "# ixis = get_ticker_data('^INSR', startdate, enddate, 'ixis')\n",
    "# make_pickle(ixis, 'ixis.pkl')\n",
    "\n",
    "# # ixis = pdr.get_data_yahoo('^INSR', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixis, 'ixis')\n",
    "# # make_pickle(df, 'ixis.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8583318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixk_url = 'https://www.investing.com/indices/nnasdaq-computer-historical-data'\n",
    "# # NASDAQ Computer (IXK), ^IXCO\n",
    "# ixk = get_ticker_data('^IXCO', startdate, enddate, 'ixk')\n",
    "# make_pickle(ixk, 'ixk.pkl')\n",
    "\n",
    "# # ixk = pdr.get_data_yahoo('^IXCO', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixk, 'ixk')\n",
    "# # make_pickle(df, 'ixk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixtr_url = 'https://www.investing.com/indices/nasdaq-transportation-historical-data'\n",
    "# # NASDAQ Transportation (IXTR), ^TRAN\n",
    "# ixtr = get_ticker_data('^TRAN', startdate, enddate, 'ixtr')\n",
    "# make_pickle(ixtr, 'ixtr.pkl')\n",
    "\n",
    "# # ixtr = pdr.get_data_yahoo('^TRAN', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixtr, 'ixtr')\n",
    "# # make_pickle(df, 'ixtr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ixut_url = 'https://www.investing.com/indices/nasdaq-telecommunications-historical-data'\n",
    "# # NASDAQ Telecommunications (IXUT), ^IXTC\n",
    "# ixut = get_ticker_data('^IXTC', startdate, enddate, 'ixut')\n",
    "# make_pickle(ixut, 'ixut.pkl')\n",
    "\n",
    "# # ixut = pdr.get_data_yahoo('^IXTC', start=startdate, end=enddate)\n",
    "# # df = reformat_df(ixut, 'ixut')\n",
    "# # make_pickle(df, 'ixut.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29110256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nbi_url = 'https://www.investing.com/indices/nasdaq-biotechnology-historical-data'\n",
    "# # NASDAQ Biotechnology (NBI), ^NBI\n",
    "# nbi = get_ticker_data('^NBI', startdate, enddate, 'nbi')\n",
    "# make_pickle(nbi, 'nbi.pkl')\n",
    "\n",
    "# # nbi = pdr.get_data_yahoo('^NBI', start=startdate, end=enddate)\n",
    "# # df = reformat_df(nbi, 'nbi')\n",
    "# # make_pickle(df, 'nbi.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yahoo에서는 하루만 잡힘. investing.com에서는 자료가 있으나 skip (나중에 보강)\n",
    "# qnet_url = 'https://www.investing.com/indices/nasdaq-internet-historical-data'\n",
    "# # NASDAQ Internet (QNET), ^QNET\n",
    "# qnet = pdr.get_data_yahoo('^QNET', start=startdate, end=enddate)\n",
    "# df = reformat_df(qnet, 'qnet')\n",
    "# make_pickle(df, 'qnet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad080d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bkx_url = 'https://www.investing.com/indices/kbw-bank-historical-data'\n",
    "# # KBW NASDAQ Bank (BKX), ^BKX\n",
    "# bkx = get_ticker_data('^BKX', startdate, enddate, 'bkx')\n",
    "# make_pickle(bkx, 'bkx.pkl')\n",
    "\n",
    "# # bkx = pdr.get_data_yahoo('^BKX', start=startdate, end=enddate)\n",
    "# # df = reformat_df(bkx, 'bkx')\n",
    "# # make_pickle(df, 'bkx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7125da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec7c127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
