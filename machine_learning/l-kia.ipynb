{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    fields=my_dict.keys()\n",
    "    values = my_dict.values()\n",
    "    pd.DataFrame([fields, values], index=['parameter','value']).T.to_csv(path)\n",
    "#     df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "#     df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) \n",
    "    \n",
    "# def load_dict_from_csv(path):\n",
    "#     df = pd.read_csv(path, header=None)\n",
    "#     my_dict = df.to_dict()\n",
    "#     return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'iter_{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(lgbm, model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target,\n",
    "                 test_scaled1, test_scaled2, test_scaled3, test_target1, test_target2, test_target3):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbm.best_score_ \n",
    "    result_dict['best_index'] = lgbm.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled1)\n",
    "    result_dict['acc_test1'] = model.score(test_scaled1, test_target1)\n",
    "    result_dict['precision1'] = precision_score(test_target1, y_predict)\n",
    "    result_dict['recall1'] = recall_score(test_target1, y_predict)\n",
    "    result_dict['f1score1'] = f1_score(test_target1, y_predict)\n",
    "    result_dict['roc1'] = roc_auc_score(test_target1, y_predict)\n",
    "    cm = confusion_matrix(test_target1, y_predict)\n",
    "    result_dict['tn1'] = cm[0,0]\n",
    "    result_dict['fp1'] = cm[0,1]\n",
    "    result_dict['fn1'] = cm[1,0]\n",
    "    result_dict['tp1'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled2)\n",
    "    result_dict['acc_test2'] = model.score(test_scaled2, test_target2)\n",
    "    result_dict['precision2'] = precision_score(test_target2, y_predict)\n",
    "    result_dict['recall2'] = recall_score(test_target2, y_predict)\n",
    "    result_dict['f1score2'] = f1_score(test_target2, y_predict)\n",
    "    result_dict['roc2'] = roc_auc_score(test_target2, y_predict)\n",
    "    cm = confusion_matrix(test_target2, y_predict)\n",
    "    result_dict['tn2'] = cm[0,0]\n",
    "    result_dict['fp2'] = cm[0,1]\n",
    "    result_dict['fn2'] = cm[1,0]\n",
    "    result_dict['tp2'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled3)\n",
    "    result_dict['acc_test3'] = model.score(test_scaled3, test_target3)\n",
    "    result_dict['precision3'] = precision_score(test_target3, y_predict)\n",
    "    result_dict['recall3'] = recall_score(test_target3, y_predict)\n",
    "    result_dict['f1score3'] = f1_score(test_target3, y_predict)\n",
    "    result_dict['roc3'] = roc_auc_score(test_target3, y_predict)\n",
    "    cm = confusion_matrix(test_target3, y_predict)\n",
    "    result_dict['tn3'] = cm[0,0]\n",
    "    result_dict['fp3'] = cm[0,1]\n",
    "    result_dict['fn3'] = cm[1,0]\n",
    "    result_dict['tp3'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_results(com_name, model, scaler, columns, df_base):\n",
    "    joblib.dump(model, f'{directory_for_model}{com_name}/best_model.pkl') # estimaor 저장\n",
    "    joblib.dump(scaler, f'{directory_for_model}{com_name}/best_scaler.pkl') # scaler 저장\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_model_p.pkl', model)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_scaler_p.pkl', scaler)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_columns.pkl', new_col)\n",
    "    save_list_to_csv(f'{directory_for_model}{com_name}/best_columns.csv', new_col)\n",
    "    df_base.to_pickle(f'{directory_for_model}{com_name}/best_result.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(*dicts):\n",
    "    dsum = {}\n",
    "    d_k = []\n",
    "    d_v = []\n",
    "    for dic in dicts:\n",
    "        d_k.extend(list(dic.keys()))  # sum keys list\n",
    "        d_v.extend(list(dic.values()))  # sum values list\n",
    "    for i in range(len(d_k)):\n",
    "        dsum[d_k[i]] = d_v[i]\n",
    "    return dsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_combine_sorted(df_base_l, df_params_l):\n",
    "    o_num = list(df_base_l.index).index('best_score')\n",
    "    df1 = df_base.iloc[:o_num, :]\n",
    "    df2 = df_base.iloc[o_num:, :]\n",
    "    df3 = pd.concat([df1, df_params_l], axis=0)\n",
    "    df3.sort_index(axis=0, inplace=True)\n",
    "    df_sorted = pd.concat([df3, df2], axis=0)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..')) # 현재 폴더로 이동\n",
    "if module_path+\"\\\\data\\\\base_data\\\\common_data\" not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\data\\\\base_data\\\\common_data\") #  공통으로 사용하는 각종 리스트, 코드 등 \n",
    "    \n",
    "import common_data as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = cd.code_all # 전체 회사 코드\n",
    "code = {'000270': ['기아', 'kia']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "#             'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', \n",
    "            'privequity_1',  'insurance_1', 'corporateetc_1', # bank_1, 'financeetc_1 제외\n",
    "            'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "#             'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', \n",
    "            'privequity_2', 'insurance_2', 'corporateetc_2', # bank_2, 'financeetc_2 제외\n",
    "            'foreigneretc_2']\n",
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']\n",
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']\n",
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]\n",
    "col_futures = ['ixic_f_cr', 'ixic_f_cr_2', 'spx_f_cr', 'spx_f_cr_2', 'dji_f_cr', 'dji_f_cr_2',\n",
    "           'wti_cr','wti_cr_2', 'dxy_cr', 'dxy_cr_2', 'bond_usa_10_cr', 'bond_usa_10_cr_2' ]\n",
    "column_o = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr\n",
    "\n",
    "col_except_futures = [item for item in column_o if item not in col_futures]\n",
    "\n",
    "new_col = col_except_futures.copy()\n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   \n",
    "\n",
    "# col_futures : futures는 당일 종료가 되지 않는 data이므로 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "df_params = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 신규 분석 데이터는 아래 것으로 사용\n",
    "\n",
    "com_name = list(code.values())[0][1]\n",
    "\n",
    "directory_for_ml = '../data/data_for_ml/predict/'\n",
    "fname = f'df_{com_name}_combine.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df_o = pd.read_pickle(f_name) \n",
    "df_o = df_o.iloc[:-1] # /predict/를 사용할 경우 마지막 prediction data 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = None\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'boosting_type' : ['gbdt', 'dart', ],# ['gbdt', 'dart', 'goss'],\n",
    "    'learning_rate': (0.0001, 0.004, 'log-uniform'),\n",
    "    'num_leaves': (3, 20),      \n",
    "    'max_depth': (0, 50), #[-1], #(0, 50),\n",
    "    'min_child_samples': (5, 30),\n",
    "#     'min_child_weight': (0.001, 10.0), # 값을 변동시 같은 값이 최적값으로 선정되더라고 precision이 틀림. 반드시 값을 바꾸면서 진행해야 함.\n",
    "#     'min_split_loss': (0, 5), \n",
    "    'max_bin': (100, 1000), # 사용시 0.75%로 올라감 default: 255\n",
    "#     'max_cat_threshold' : (1, 100),\n",
    "    'subsample': (0.005, 1.0, 'uniform'), # == bagging_fraction\n",
    "#     'subsample_freq': (1, 5), # mobis에서 적용시 값이 많이 올라감. default:0\n",
    "    'colsample_bytree': (0.005, 1.0, 'uniform'),\n",
    "    'subsample_for_bin': (100000, 1000000),\n",
    "    'scale_pos_weight' : (0.2, 2.0, 'uniform'),\n",
    "#     'scale_pos_weight': np.arange(0.2, 2, 0.1) ,\n",
    "    'n_estimators': (700, 5000),\n",
    "    'reg_alpha' : (0.0, 2.0, 'uniform'), # =='lambda_l1': [0, 5], # default 0\n",
    "    'reg_lambda' : (0.0, 2.0, 'uniform'), # == lambda_l2': [0, 5], #default 0    \n",
    "#     'reg_alpha' : np.arange(0, 4, 0.1),\n",
    "#     'reg_lambda' : np.arange(0, 4, 0.1),\n",
    "    'force_col_wise': ['true'], \n",
    "    'importance_type': ['split'], # ['gain'], default: split\n",
    "    'boost_from_average' : [True, False],\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "}\n",
    "\n",
    "params_space = search_space.copy() # for Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'cv' : 5,\n",
    "#     'cv' : None,\n",
    "#     'scoring' : None,\n",
    "#     'scoring' : 'f1',\n",
    "#     'scoring' : 'roc_auc',\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'average_precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 50,  # default : 50, number of parameter settings.\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_for_model = '../data/data_for_ml/model/model/0. test/'\n",
    "directory_for_model = '../data/data_for_ml/model/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbm BS ******\n",
      "******* No.14 BS Process is Done! ********\n",
      "**** End of BayesSearchCV Process ****\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(directory_for_model+com_name):\n",
    "    os.makedirs(directory_for_model+com_name)\n",
    "\n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmBS = None\n",
    "gsbs = 'bs'\n",
    "\n",
    "lgbmBS = BayesSearchCV( estimator = lightgbm.LGBMClassifier(verbose=0, random_state=42),\n",
    "                       search_spaces = params_space,\n",
    "                       scoring = param_grid['scoring'],\n",
    "                       cv = StratifiedKFold( n_splits=param_grid['cv'],\n",
    "                                             shuffle=True,\n",
    "                                             random_state=42 ),\n",
    "                       n_jobs = -1, # 자동 검색 적용\n",
    "                       n_iter = param_grid['iterations'],   \n",
    "                       verbose = 0, refit = True, random_state = 42 \n",
    "                      )\n",
    "\n",
    "print(\"*** after lgbm BS ******\")\n",
    "lgbmBS.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "\n",
    "# save model\n",
    "stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "dt = f'{dt[:4]}_{dt[4:]}'\n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmBS.best_estimator_.get_params(), iter)\n",
    "df_estimator.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "\n",
    "# metrics accuracy,,,, 3단계 precision 등까지. dictionary\n",
    "result_dict = calc_results(lgbmBS, lgbmBS.best_estimator_, \n",
    "                           train_scaled, val_scaled, test_scaled,  \n",
    "                           train_target, val_target, test_target,\n",
    "                           test_scaled1, test_scaled2, test_scaled3,  \n",
    "                           test_target1, test_target2, test_target3\n",
    "                          )\n",
    "\n",
    "df_grid = make_df_from_estimator(param_grid, iter) # gridcv parameter\n",
    "df_grid.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "df_result = make_df_from_estimator(result_dict, iter)  # dict 를 df로\n",
    "df_concat = pd.concat([df_grid, df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "precision = df_concat.loc['precision'].iloc[0]\n",
    "f1score = df_concat.loc['f1score'].iloc[0]\n",
    "\n",
    "params_search = add_dict(param_grid, search_space)\n",
    "df_params_search = make_df_from_estimator(params_search, iter)\n",
    "df_params = pd.merge(df_params,df_params_search, how='outer', left_index=True, right_index=True)\n",
    "  \n",
    "print(\"******* No.{} BS Process is Done! ********\".format(iter))\n",
    "    \n",
    "print(\"**** End of BayesSearchCV Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_7</th>\n",
       "      <th>iter_8</th>\n",
       "      <th>iter_12</th>\n",
       "      <th>iter_13</th>\n",
       "      <th>iter_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.001, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.678785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.347135</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>727</td>\n",
       "      <td>563</td>\n",
       "      <td>799</td>\n",
       "      <td>158</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>(5, 30)</td>\n",
       "      <td>(5, 30)</td>\n",
       "      <td>(5, 30)</td>\n",
       "      <td>(5, 30)</td>\n",
       "      <td>(5, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 7000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>4054</td>\n",
       "      <td>2337</td>\n",
       "      <td>3409</td>\n",
       "      <td>2937</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299583</td>\n",
       "      <td>1.362278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.475134</td>\n",
       "      <td>0.954686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>0.845205</td>\n",
       "      <td>0.86856</td>\n",
       "      <td>0.771934</td>\n",
       "      <td>0.596121</td>\n",
       "      <td>0.845205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.365919</td>\n",
       "      <td>0.610377</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.579124</td>\n",
       "      <td>0.365919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1120196</td>\n",
       "      <td>1000000</td>\n",
       "      <td>698490</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>(100000, 1000000)</td>\n",
       "      <td>(100000, 1200000)</td>\n",
       "      <td>(100000, 1000000)</td>\n",
       "      <td>(100000, 1000000)</td>\n",
       "      <td>(100000, 1000000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.682619</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.670909</td>\n",
       "      <td>0.721905</td>\n",
       "      <td>0.682619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.914141</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.914141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          iter_7   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                         False   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               dart   \n",
       "class_weight                                None   \n",
       "colsample_bytree           (0.005, 1.0, uniform)   \n",
       "colsample_bytree                           0.005   \n",
       "cv                                             5   \n",
       "cv                                             5   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                              0.004   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      727   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     37   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 30)   \n",
       "min_child_samples                             11   \n",
       "min_child_weight                             NaN   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                4054   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                     4   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                                    0.0   \n",
       "reg_alpha                    (0.0, 2.0, uniform)   \n",
       "reg_lambda                   (0.0, 2.0, uniform)   \n",
       "reg_lambda                                   0.0   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.845205   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                               0.365919   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                        1000000   \n",
       "subsample_for_bin              (100000, 1000000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.682619   \n",
       "best_index                                  33.0   \n",
       "acc_train                               0.914141   \n",
       "acc_val                                     0.56   \n",
       "acc_test                                0.555556   \n",
       "precision                               0.705882   \n",
       "recall                                  0.342857   \n",
       "\n",
       "                                          iter_8   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree           (0.005, 1.0, uniform)   \n",
       "colsample_bytree                        0.678785   \n",
       "cv                                             5   \n",
       "cv                                             5   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.000123   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      563   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     25   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 30)   \n",
       "min_child_samples                             24   \n",
       "min_child_weight                             NaN   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 7000)   \n",
       "n_estimators                                2337   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                    12   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                               0.299583   \n",
       "reg_alpha                    (0.0, 2.0, uniform)   \n",
       "reg_lambda                   (0.0, 2.0, uniform)   \n",
       "reg_lambda                              1.475134   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                         0.86856   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                               0.610377   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                        1120196   \n",
       "subsample_for_bin              (100000, 1200000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                                   0.7   \n",
       "best_index                                  29.0   \n",
       "acc_train                               0.676768   \n",
       "acc_val                                     0.52   \n",
       "acc_test                                0.460317   \n",
       "precision                                    0.6   \n",
       "recall                                  0.085714   \n",
       "\n",
       "                                         iter_12   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree           (0.001, 1.0, uniform)   \n",
       "colsample_bytree                             1.0   \n",
       "cv                                             5   \n",
       "cv                                             5   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.002571   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      799   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                      1   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 30)   \n",
       "min_child_samples                             17   \n",
       "min_child_weight                             NaN   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                3409   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                    10   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                               1.362278   \n",
       "reg_alpha                    (0.0, 2.0, uniform)   \n",
       "reg_lambda                   (0.0, 2.0, uniform)   \n",
       "reg_lambda                              0.954686   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.771934   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                                  0.005   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                        1000000   \n",
       "subsample_for_bin              (100000, 1000000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.670909   \n",
       "best_index                                  48.0   \n",
       "acc_train                               0.737374   \n",
       "acc_val                                     0.64   \n",
       "acc_test                                0.492063   \n",
       "precision                               0.578947   \n",
       "recall                                  0.314286   \n",
       "\n",
       "                                         iter_13                       iter_14  \n",
       "parameter                                                                       \n",
       "boost_from_average                 [True, False]                 [True, False]  \n",
       "boost_from_average                         False                         False  \n",
       "boosting_type                       [gbdt, dart]                  [gbdt, dart]  \n",
       "boosting_type                               dart                          dart  \n",
       "class_weight                                None                          None  \n",
       "colsample_bytree           (0.005, 1.0, uniform)         (0.005, 1.0, uniform)  \n",
       "colsample_bytree                        0.347135                         0.005  \n",
       "cv                                             5                             5  \n",
       "cv                                             5                             5  \n",
       "force_col_wise                            [true]                        [true]  \n",
       "force_col_wise                              true                          true  \n",
       "importance_type                          [split]                       [split]  \n",
       "importance_type                            split                         split  \n",
       "iterations                                    50                            50  \n",
       "iterations                                    50                            50  \n",
       "learning_rate                           0.000131                         0.004  \n",
       "learning_rate       (0.0001, 0.004, log-uniform)  (0.0001, 0.004, log-uniform)  \n",
       "max_bin                                      158                           727  \n",
       "max_bin                              (100, 1000)                   (100, 1000)  \n",
       "max_depth                                     35                            37  \n",
       "max_depth                                (0, 50)                       (0, 50)  \n",
       "metric                            binary_logloss                binary_logloss  \n",
       "metric                          [binary_logloss]              [binary_logloss]  \n",
       "min_child_samples                        (5, 30)                       (5, 30)  \n",
       "min_child_samples                              8                            11  \n",
       "min_child_weight                             NaN                           NaN  \n",
       "min_child_weight                           0.001                         0.001  \n",
       "min_split_gain                               0.0                           0.0  \n",
       "n_estimators                         (700, 5000)                   (700, 5000)  \n",
       "n_estimators                                2937                          4054  \n",
       "n_jobs                                        -1                            -1  \n",
       "num_col                                       98                            98  \n",
       "num_col                                       98                            98  \n",
       "num_leaves                                     6                             4  \n",
       "num_leaves                               (3, 20)                       (3, 20)  \n",
       "objective                               [binary]                      [binary]  \n",
       "objective                                 binary                        binary  \n",
       "random_state                                  42                            42  \n",
       "reg_alpha                                    0.0                           0.0  \n",
       "reg_alpha                                    NaN           (0.0, 2.0, uniform)  \n",
       "reg_lambda                                   NaN           (0.0, 2.0, uniform)  \n",
       "reg_lambda                                   0.0                           0.0  \n",
       "scale_pos_weight             (0.2, 2.0, uniform)           (0.2, 2.0, uniform)  \n",
       "scale_pos_weight                        0.596121                      0.845205  \n",
       "scoring                                precision                     precision  \n",
       "scoring                                precision                     precision  \n",
       "silent                                      warn                          warn  \n",
       "subsample                               0.579124                      0.365919  \n",
       "subsample                  (0.005, 1.0, uniform)         (0.005, 1.0, uniform)  \n",
       "subsample_for_bin                         698490                       1000000  \n",
       "subsample_for_bin              (100000, 1000000)             (100000, 1000000)  \n",
       "subsample_freq                                 0                             0  \n",
       "verbose                                        0                             0  \n",
       "best_score                              0.721905                      0.682619  \n",
       "best_index                                  42.0                          33.0  \n",
       "acc_train                               0.767677                      0.914141  \n",
       "acc_val                                     0.56                          0.56  \n",
       "acc_test                                 0.47619                      0.555556  \n",
       "precision                               0.666667                      0.705882  \n",
       "recall                                  0.114286                      0.342857  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one = df_combine_sorted(df_base, df_params)\n",
    "df_one.iloc[:, 6:].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_1</th>\n",
       "      <th>iter_2</th>\n",
       "      <th>iter_3</th>\n",
       "      <th>iter_4</th>\n",
       "      <th>iter_5</th>\n",
       "      <th>iter_6</th>\n",
       "      <th>iter_7</th>\n",
       "      <th>iter_8</th>\n",
       "      <th>iter_12</th>\n",
       "      <th>iter_13</th>\n",
       "      <th>iter_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>verbose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.557494</td>\n",
       "      <td>0.580766</td>\n",
       "      <td>0.578704</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.682619</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.670909</td>\n",
       "      <td>0.721905</td>\n",
       "      <td>0.682619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.823232</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.914141</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.914141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.460714</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.453571</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.582143</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.582143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.52381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall1</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score1</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              iter_1    iter_2    iter_3    iter_4    iter_5    iter_6   \n",
       "parameter                                                                \n",
       "verbose            0         0         0         0         0         0  \\\n",
       "best_score  0.565657  0.557494  0.580766  0.578704    0.5889       0.8   \n",
       "best_index       2.0      13.0      44.0      37.0      20.0      19.0   \n",
       "acc_train   0.762626  0.712121  0.823232  0.671717  0.828283  0.767677   \n",
       "acc_val         0.58      0.62      0.58      0.52      0.56      0.58   \n",
       "acc_test    0.492063  0.428571  0.492063  0.412698   0.52381   0.47619   \n",
       "precision   0.615385  0.461538       0.6     0.375  0.647059  0.666667   \n",
       "recall      0.228571  0.171429  0.257143  0.085714  0.314286  0.114286   \n",
       "f1score     0.333333      0.25      0.36  0.139535  0.423077  0.195122   \n",
       "roc            0.525  0.460714  0.521429  0.453571      0.55  0.521429   \n",
       "tn              23.0      21.0      22.0      23.0      22.0      26.0   \n",
       "fp               5.0       7.0       6.0       5.0       6.0       2.0   \n",
       "fn              27.0      29.0      26.0      32.0      24.0      31.0   \n",
       "tp               8.0       6.0       9.0       3.0      11.0       4.0   \n",
       "acc_test1   0.333333  0.380952  0.285714  0.380952  0.380952  0.380952   \n",
       "precision1       0.5  0.666667  0.333333  0.666667       0.6       1.0   \n",
       "recall1     0.142857  0.142857  0.071429  0.142857  0.214286  0.071429   \n",
       "f1score1    0.222222  0.235294  0.117647  0.235294  0.315789  0.133333   \n",
       "\n",
       "              iter_7    iter_8   iter_12   iter_13   iter_14  \n",
       "parameter                                                     \n",
       "verbose            0         0         0         0         0  \n",
       "best_score  0.682619       0.7  0.670909  0.721905  0.682619  \n",
       "best_index      33.0      29.0      48.0      42.0      33.0  \n",
       "acc_train   0.914141  0.676768  0.737374  0.767677  0.914141  \n",
       "acc_val         0.56      0.52      0.64      0.56      0.56  \n",
       "acc_test    0.555556  0.460317  0.492063   0.47619  0.555556  \n",
       "precision   0.705882       0.6  0.578947  0.666667  0.705882  \n",
       "recall      0.342857  0.085714  0.314286  0.114286  0.342857  \n",
       "f1score     0.461538      0.15  0.407407  0.195122  0.461538  \n",
       "roc         0.582143  0.507143  0.514286  0.521429  0.582143  \n",
       "tn              23.0      26.0      20.0      26.0      23.0  \n",
       "fp               5.0       2.0       8.0       2.0       5.0  \n",
       "fn              23.0      32.0      24.0      31.0      23.0  \n",
       "tp              12.0       3.0      11.0       4.0      12.0  \n",
       "acc_test1    0.52381  0.333333  0.619048  0.380952   0.52381  \n",
       "precision1       1.0       0.5       0.8       1.0       1.0  \n",
       "recall1     0.285714  0.071429  0.571429  0.071429  0.285714  \n",
       "f1score1    0.444444     0.125  0.666667  0.133333  0.444444  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.iloc[52:70, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space, parameters and results save\n",
    "df_one.to_csv(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.csv')\n",
    "df_one.to_pickle(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 아래 내용은 위의 df_one을 대체함.\n",
    "# parameter and results save\n",
    "df_base.to_csv(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.csv')\n",
    "df_base.to_pickle(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.pkl')\n",
    "\n",
    "# search_space, parameters save\n",
    "df_params.to_csv(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.csv')\n",
    "df_params.to_pickle(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# save model\\n# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\\njoblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\\nsave_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\\njoblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\\nsave_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\\nsave_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# save model\n",
    "# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\n",
    "joblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\n",
    "joblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\n",
    "save_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 가장 좋은 결과 저장\n",
    "save_best_results(com_name, lgbmBS.best_estimator_, scaler, new_col, df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lgbmBS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmBS.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spny_cr_2</th>\n",
       "      <td>402.680579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr</th>\n",
       "      <td>398.743630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixut_cr</th>\n",
       "      <td>385.739984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail_1</th>\n",
       "      <td>384.922704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_cr</th>\n",
       "      <td>384.683385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance_1</th>\n",
       "      <td>151.132395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_10_cr_2</th>\n",
       "      <td>142.877404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixbk_cr_2</th>\n",
       "      <td>130.880282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigneretc_2</th>\n",
       "      <td>116.201861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>41.043695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "spny_cr_2         402.680579\n",
       "kosdaq_cr         398.743630\n",
       "ixut_cr           385.739984\n",
       "retail_1          384.922704\n",
       "ixic_cr           384.683385\n",
       "...                      ...\n",
       "insurance_1       151.132395\n",
       "bond_kor_10_cr_2  142.877404\n",
       "ixbk_cr_2         130.880282\n",
       "foreigneretc_2    116.201861\n",
       "weekday            41.043695\n",
       "\n",
       "[70 rows x 1 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.tail(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:35]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
