parameter,value1,value2,value3
cv,3,3,3
iterations,50,20,20
num_col,98,98,98
scoring,precision,precision,accuracy
boost_from_average,True,True,False
boosting_type,gbdt,gbdt,gbdt
class_weight,,,
colsample_bytree,0.49898437007873314,0.49898437007873314,0.10933486275994007
force_col_wise,true,true,true
importance_type,split,split,split
learning_rate,0.0003304939642148201,0.0003304939642148201,0.00020003937281998327
max_bin,146,146,508
max_depth,29,29,8
metric,binary_logloss,binary_logloss,binary_logloss
min_child_samples,19,19,25
min_child_weight,0.001,0.001,0.001
min_split_gain,0.0,0.0,0.0
n_estimators,2600,2600,2938
n_jobs,-1,-1,-1
num_leaves,7,7,11
objective,binary,binary,binary
random_state,42,42,42
reg_alpha,2.7,2.7,0.8
reg_lambda,0.30000000000000004,0.30000000000000004,2.0
scale_pos_weight,0.7000000000000002,0.7000000000000002,1.0000000000000002
silent,warn,warn,warn
subsample,0.5597576125719046,0.5597576125719046,0.36433471742398227
subsample_for_bin,439614,439614,498762
subsample_freq,0,0,0
verbose,1,0,0
best_score,0.7777777777777777,0.7777777777777777,0.623477564102564
best_index,7.0,7.0,2.0
acc_train,0.7216494845360825,0.7216494845360825,0.7783505154639175
acc_val,0.6122448979591837,0.6122448979591837,0.7755102040816326
acc_test,0.6229508196721312,0.6229508196721312,0.6721311475409836
precision,1.0,1.0,0.7
recall,0.041666666666666664,0.041666666666666664,0.2916666666666667
f1score,0.07999999999999999,0.07999999999999999,0.4117647058823529
roc,0.5208333333333334,0.5208333333333334,0.6052927927927928
tn,37.0,37.0,34.0
fp,0.0,0.0,3.0
fn,23.0,23.0,17.0
tp,1.0,1.0,7.0
acc_test1,0.5,0.5,0.6
precision1,0.0,0.0,0.75
recall1,0.0,0.0,0.3
f1score1,0.0,0.0,0.4285714285714285
roc1,0.5,0.5,0.6000000000000001
tn1,10.0,10.0,9.0
fp1,0.0,0.0,1.0
fn1,10.0,10.0,7.0
tp1,0.0,0.0,3.0
acc_test2,0.65,0.65,0.7
precision2,1.0,1.0,0.75
recall2,0.125,0.125,0.375
f1score2,0.2222222222222222,0.2222222222222222,0.5
roc2,0.5625,0.5625,0.6458333333333333
tn2,12.0,12.0,11.0
fp2,0.0,0.0,1.0
fn2,7.0,7.0,5.0
tp2,1.0,1.0,3.0
acc_test3,0.7142857142857143,0.7142857142857143,0.7142857142857143
precision3,0.0,0.0,0.5
recall3,0.0,0.0,0.16666666666666666
f1score3,0.0,0.0,0.25
roc3,0.5,0.5,0.55
tn3,15.0,15.0,14.0
fp3,0.0,0.0,1.0
fn3,6.0,6.0,5.0
tp3,0.0,0.0,1.0
