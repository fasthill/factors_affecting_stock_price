{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix to list 변환\n",
    "def matrix_to_list(confu_matrix):\n",
    "    m_list = []\n",
    "    tn = confu_matrix[0,0]\n",
    "    fp = confu_matrix[0,1]\n",
    "    fn = confu_matrix[1,0]\n",
    "    tp = confu_matrix[1,1]\n",
    "    m_list.extend([tn, fp, fn, tp])\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "#     cm = matrix_to_list(confusion_matrix(test_target, y_predict_list))\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "#     collect_list.extend(cm)\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'df_naver_sel.pkl'\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "val_scaled = ss.transform(val_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "train accuracy: 1.0000, val accuracy 0.8205, test accuracy 0.7083\n",
      "precision : 0.6111, recall : 0.6111, f1score : 0.6111, roc : 0.6889\n",
      "[[23  7]\n",
      " [ 7 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "lgbm = None\n",
    "lgbm = lightgbm.LGBMClassifier(random_state=42,\n",
    "                               learning_rate =0.22, # default = 0.1\n",
    "                               num_iterations=500, # default=100\n",
    "                               max_depth=5, # <= 0 means no limit, default=-1\n",
    "                               bagging_fraction=0.9, # 0.0 < bagging_fraction <= 1.0, default=1\n",
    "                               feature_fraction=0.8, # 0.0 < feature_fraction <= 1.0, default=1\n",
    "                               objective= 'binary', \n",
    "#                                num_threads = 0, # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "                               max_delta_step = 0.5, # best value found, default = 0\n",
    "#                             scale_pos_weight=40, # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "                              ) \n",
    "lgbm.fit(train_scaled, train_target, eval_metric = 'logloss')\n",
    "y_pred = lgbm.predict(val_scaled)\n",
    "# val_error = mean_squared_error(val_target, y_pred) # 책에 없음\n",
    "# print(\"Validation MSE:\", val_error)           # 책에 없음\n",
    "\n",
    "train_score_lgbm = lgbm.score(train_scaled, train_target)\n",
    "val_score_lgbm = lgbm.score(val_scaled, val_target)\n",
    "test_score_lgbm = lgbm.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, lgbm.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, lgbm.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score_lgbm, val_score_lgbm, test_score_lgbm))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4608 candidates, totalling 23040 fits\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
      "               learning_rate=0.005, max_delta_step=0.5, max_depth=None,\n",
      "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
      "               objective='binary', random_state=42, subsample=0.003)\n",
      "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.005, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
      "Best Score: 0.8311827956989248, Best Index: 864\n",
      "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7708\n",
      "precision : 0.8182, recall : 0.5000, f1score : 0.6207, roc : 0.7167\n",
      "[[28  2]\n",
      " [ 9  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"boosting_type\" : ['gbdt'],\n",
    "    \"max_depth\": [None, 2, 3, 4],\n",
    "    \"num_leaves\": [3, 4, 5],\n",
    "    \"learning_rate\": [0.002, 0.003, 0.004, 0.005],\n",
    "    \"objective\": ['binary'],\n",
    "    \"metric\": ['loss'],\n",
    "    \"colsample_bytree\": [0.38, 0.39, 0.41, 0.42],\n",
    "    \"subsample\": [0.003, 0.004, 0.005, 0.01],\n",
    "    \"n_estimators\": [3, 4, 5, 6, 7, 8],\n",
    "#     \"num_iterations\": [100, 200, 300, 400, 500],\n",
    "#     \"num_class\": [1]\n",
    "#     \"metric\" : \"rmse\",\n",
    "#     \"bagging_frequency\" : 5,\n",
    "#     \"bagging_seed\" : 2018,\n",
    "#     \"verbosity\" : -1,\n",
    "\n",
    "#     # Selected rounded-off params\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'feature_fraction': 0.1,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 0,\n",
    "#     'max_depth': 9,\n",
    "#     'min_child_weight': 5,\n",
    "#     'min_split_gain': 0,\n",
    "#     'num_leaves': 24\n",
    "}\n",
    "lgbm = None\n",
    "lgbmgs = None\n",
    "\n",
    "lgbm = lightgbm.LGBMClassifier( random_state=42, \n",
    "                               learning_rate =0.22, # default = 0.1\n",
    "                               num_iterations=500, # default=100\n",
    "                               max_depth=5, # <= 0 means no limit, default=-1\n",
    "#                                bagging_fraction=0.9, # 0.0 < bagging_fraction <= 1.0, default=1\n",
    "#                                feature_fraction=0.8, # 0.0 < feature_fraction <= 1.0, default=1\n",
    "                               objective= 'binary', \n",
    "#                                num_threads = 0, # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "                               max_delta_step = 0.5, # best value found, default = 0\n",
    "#                                scale_pos_weight=40, # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "                               eval_metric = 'logloss'\n",
    "                                )\n",
    "\n",
    "lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                      param_grid = params,\n",
    "                      cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "#                       scoring = 'precision', \n",
    "                      scoring = 'accuracy', \n",
    "                      verbose = 1,\n",
    "                      n_jobs=-1, # 자동 검색 적용\n",
    "                      )\n",
    "\n",
    "lgbmgs.fit(train_scaled, train_target)\n",
    "    \n",
    "print(\"Best Estimator: {}\".format(lgbmgs.best_estimator_)) \n",
    "print(\"Best Parameters: {}\".format(lgbmgs.best_params_))  # 최적 파라미터.\n",
    "print('Best Score: {}, Best Index: {}'.format(lgbmgs.best_score_ , lgbmgs.best_index_))  # 교차검증된 점수를 보여줌.\n",
    "\n",
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_pred = model.predict(test_scaled)\n",
    "\n",
    "train_score = model.score(train_scaled, train_target)\n",
    "val_score = model.score(val_scaled, val_target)\n",
    "test_score = model.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, model.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, model.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score, val_score, test_score))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36,   5,   5,   4,  11,   5,   2,   0,   0,   6,   0,   7,   0,\n",
       "         2,  31,  18,  11,   8,  32,  29,   7,   4,   3,   0, 162, 179,\n",
       "        32,  13,   0,   1,  21, 175, 187,   0,   0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krw_cr</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_10_cr</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_cr</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_2_cr</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_f_cr</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox_cr</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invtrust</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_cr</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_f_cr</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigneretc</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxy_cr</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financeetc</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigner</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pension</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_10_cr</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financial</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_2_cr</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_f_cr</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wti_cr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix_cr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporateetc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance\n",
       "low                    187\n",
       "kospi_cr               179\n",
       "high                   175\n",
       "kosdaq_cr              162\n",
       "retail                  36\n",
       "krw_cr                  32\n",
       "bond_kor_10_cr          32\n",
       "ixic_cr                 31\n",
       "bond_kor_2_cr           29\n",
       "open                    21\n",
       "ixic_f_cr               18\n",
       "sox_cr                  13\n",
       "invtrust                11\n",
       "spx_cr                  11\n",
       "spx_f_cr                 8\n",
       "foreigneretc             7\n",
       "dxy_cr                   7\n",
       "financeetc               6\n",
       "foreigner                5\n",
       "institution              5\n",
       "pension                  5\n",
       "bond_usa_10_cr           4\n",
       "financial                4\n",
       "bond_usa_2_cr            3\n",
       "dji_f_cr                 2\n",
       "privequity               2\n",
       "wti_cr                   1\n",
       "vol                      0\n",
       "insurance                0\n",
       "vix_cr                   0\n",
       "bank                     0\n",
       "dji_cr                   0\n",
       "bond_usa_3m_cr           0\n",
       "corporateetc             0\n",
       "weekday                  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel = pd.DataFrame(model.feature_importances_, index=data.columns, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.01853705e+02, 2.09116001e+01, 2.24134402e+01, 1.99464099e+01,\n",
       "       4.68392494e+01, 1.82933300e+01, 7.76625991e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.44078705e+01, 0.00000000e+00, 3.46162000e+01,\n",
       "       0.00000000e+00, 8.73318966e-03, 1.55219209e+01, 3.39758409e+01,\n",
       "       8.69237512e+00, 8.67263984e+00, 1.03369987e+02, 6.71910275e+01,\n",
       "       3.29085801e+01, 1.01570300e+01, 1.17823501e+01, 0.00000000e+00,\n",
       "       1.65933056e+03, 3.50580067e+03, 3.56548126e+01, 5.08107218e+00,\n",
       "       0.00000000e+00, 6.88262987e+00, 7.59577905e+01, 2.18379700e+03,\n",
       "       5.84932801e+03, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>5849.328011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr</th>\n",
       "      <td>3505.800665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>2183.797003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr</th>\n",
       "      <td>1659.330565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail</th>\n",
       "      <td>201.853705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_10_cr</th>\n",
       "      <td>103.369987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>75.957790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_2_cr</th>\n",
       "      <td>67.191028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invtrust</th>\n",
       "      <td>46.839249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krw_cr</th>\n",
       "      <td>35.654813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigneretc</th>\n",
       "      <td>34.616200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_f_cr</th>\n",
       "      <td>33.975841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxy_cr</th>\n",
       "      <td>32.908580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financeetc</th>\n",
       "      <td>24.407871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution</th>\n",
       "      <td>22.413440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigner</th>\n",
       "      <td>20.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financial</th>\n",
       "      <td>19.946410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pension</th>\n",
       "      <td>18.293330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_cr</th>\n",
       "      <td>15.521921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_2_cr</th>\n",
       "      <td>11.782350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_10_cr</th>\n",
       "      <td>10.157030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_cr</th>\n",
       "      <td>8.692375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_f_cr</th>\n",
       "      <td>8.672640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity</th>\n",
       "      <td>7.766260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wti_cr</th>\n",
       "      <td>6.882630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox_cr</th>\n",
       "      <td>5.081072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_f_cr</th>\n",
       "      <td>0.008733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporateetc</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance\n",
       "low             5849.328011\n",
       "kospi_cr        3505.800665\n",
       "high            2183.797003\n",
       "kosdaq_cr       1659.330565\n",
       "retail           201.853705\n",
       "bond_kor_10_cr   103.369987\n",
       "open              75.957790\n",
       "bond_kor_2_cr     67.191028\n",
       "invtrust          46.839249\n",
       "krw_cr            35.654813\n",
       "foreigneretc      34.616200\n",
       "ixic_f_cr         33.975841\n",
       "dxy_cr            32.908580\n",
       "financeetc        24.407871\n",
       "institution       22.413440\n",
       "foreigner         20.911600\n",
       "financial         19.946410\n",
       "pension           18.293330\n",
       "ixic_cr           15.521921\n",
       "bond_usa_2_cr     11.782350\n",
       "bond_usa_10_cr    10.157030\n",
       "spx_cr             8.692375\n",
       "spx_f_cr           8.672640\n",
       "privequity         7.766260\n",
       "wti_cr             6.882630\n",
       "sox_cr             5.081072\n",
       "dji_f_cr           0.008733\n",
       "bond_usa_3m_cr     0.000000\n",
       "dji_cr             0.000000\n",
       "corporateetc       0.000000\n",
       "vix_cr             0.000000\n",
       "insurance          0.000000\n",
       "bank               0.000000\n",
       "vol                0.000000\n",
       "weekday            0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>4807.865055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr</th>\n",
       "      <td>3317.561685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>1831.948064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr</th>\n",
       "      <td>1494.045491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail</th>\n",
       "      <td>182.058875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_2_cr</th>\n",
       "      <td>118.091723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_10_cr</th>\n",
       "      <td>89.554625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>45.789817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financeetc</th>\n",
       "      <td>42.706240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigneretc</th>\n",
       "      <td>41.495180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_f_cr</th>\n",
       "      <td>39.439572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krw_cr</th>\n",
       "      <td>35.100498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invtrust</th>\n",
       "      <td>34.779950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_cr</th>\n",
       "      <td>32.081290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxy_cr</th>\n",
       "      <td>28.714810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution</th>\n",
       "      <td>26.070720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pension</th>\n",
       "      <td>24.623440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financial</th>\n",
       "      <td>20.365260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr</th>\n",
       "      <td>14.885010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigner</th>\n",
       "      <td>13.461420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_cr</th>\n",
       "      <td>12.455132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_10_cr</th>\n",
       "      <td>9.851990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_f_cr</th>\n",
       "      <td>8.383915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wti_cr</th>\n",
       "      <td>6.780290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox_cr</th>\n",
       "      <td>5.873813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_2_cr</th>\n",
       "      <td>3.848290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_f_cr</th>\n",
       "      <td>0.096254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr</th>\n",
       "      <td>0.012481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporateetc</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance\n",
       "low             4807.865055\n",
       "kospi_cr        3317.561685\n",
       "high            1831.948064\n",
       "kosdaq_cr       1494.045491\n",
       "retail           182.058875\n",
       "bond_kor_2_cr    118.091723\n",
       "bond_kor_10_cr    89.554625\n",
       "open              45.789817\n",
       "financeetc        42.706240\n",
       "foreigneretc      41.495180\n",
       "ixic_f_cr         39.439572\n",
       "krw_cr            35.100498\n",
       "invtrust          34.779950\n",
       "ixic_cr           32.081290\n",
       "dxy_cr            28.714810\n",
       "institution       26.070720\n",
       "pension           24.623440\n",
       "financial         20.365260\n",
       "bond_usa_3m_cr    14.885010\n",
       "foreigner         13.461420\n",
       "spx_cr            12.455132\n",
       "bond_usa_10_cr     9.851990\n",
       "spx_f_cr           8.383915\n",
       "wti_cr             6.780290\n",
       "sox_cr             5.873813\n",
       "bond_usa_2_cr      3.848290\n",
       "dji_f_cr           0.096254\n",
       "dji_cr             0.012481\n",
       "corporateetc       0.000000\n",
       "vix_cr             0.000000\n",
       "insurance          0.000000\n",
       "bank               0.000000\n",
       "privequity         0.000000\n",
       "vol                0.000000\n",
       "weekday            0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36,   5,   5,   4,  11,   5,   2,   0,   0,   6,   0,   7,   0,\n",
       "         2,  31,  18,  11,   8,  32,  29,   7,   4,   3,   0, 162, 179,\n",
       "        32,  13,   0,   1,  21, 175, 187,   0,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score  :  [0.5        0.91806667        nan 0.5        0.90966667        nan\n",
      " 0.5        0.91546667        nan 0.5        0.91293333        nan\n",
      " 0.5        0.90963333        nan 0.5        0.9145            nan\n",
      " 0.5        0.90633333        nan 0.5        0.9128            nan\n",
      " 0.5        0.9112            nan 0.5        0.91456667        nan\n",
      " 0.5        0.9088            nan 0.5        0.91283333        nan\n",
      " 0.5        0.90803333        nan 0.5        0.91466667        nan\n",
      " 0.5        0.90866667        nan 0.5        0.90796667        nan\n",
      " 0.5        0.91706667        nan 0.5        0.92043333        nan\n",
      " 0.5        0.90883333        nan 0.5        0.90966667        nan\n",
      " 0.5        0.91113333        nan 0.5        0.89726667        nan\n",
      " 0.5        0.89386667        nan 0.5        0.9096            nan\n",
      " 0.5        0.90566667        nan 0.5        0.90386667        nan\n",
      " 0.5        0.90383333        nan 0.5        0.91293333        nan\n",
      " 0.5        0.90873333        nan 0.5        0.9136            nan\n",
      " 0.5        0.91213333        nan 0.5        0.90473333        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9113            nan\n",
      " 0.5        0.91946667        nan 0.5        0.92043333        nan\n",
      " 0.5        0.91806667        nan 0.5        0.91126667        nan\n",
      " 0.5        0.91123333        nan 0.5        0.9063            nan\n",
      " 0.5        0.9079            nan 0.5        0.91213333        nan\n",
      " 0.5        0.90473333        nan 0.5        0.91056667        nan\n",
      " 0.5        0.91453333        nan 0.5        0.9121            nan\n",
      " 0.5        0.91123333        nan 0.5        0.90786667        nan\n",
      " 0.5        0.91213333        nan 0.5        0.90473333        nan\n",
      " 0.5        0.9071            nan 0.5        0.91213333        nan\n",
      " 0.5        0.9178            nan 0.5        0.92123333        nan\n",
      " 0.5        0.91806667        nan 0.5        0.91126667        nan\n",
      " 0.5        0.91123333        nan 0.5        0.9063            nan\n",
      " 0.5        0.9054            nan 0.5        0.91213333        nan\n",
      " 0.5        0.90473333        nan 0.5        0.91056667        nan\n",
      " 0.5        0.91133333        nan 0.5        0.9121            nan\n",
      " 0.5        0.91123333        nan 0.5        0.90786667        nan\n",
      " 0.5        0.91213333        nan 0.5        0.90473333        nan\n",
      " 0.5        0.9071            nan 0.5        0.91213333        nan\n",
      " 0.5        0.9178            nan 0.5        0.92123333        nan\n",
      " 0.5        0.91383333        nan 0.5        0.92016667        nan\n",
      " 0.5        0.90876667        nan 0.5        0.91373333        nan\n",
      " 0.5        0.91866667        nan 0.5        0.91713333        nan\n",
      " 0.5        0.91706667        nan 0.5        0.91056667        nan\n",
      " 0.5        0.918             nan 0.5        0.9172            nan\n",
      " 0.5        0.9172            nan 0.5        0.91886667        nan\n",
      " 0.5        0.90806667        nan 0.5        0.91626667        nan\n",
      " 0.5        0.9089            nan 0.5        0.91143333        nan\n",
      " 0.5        0.9114            nan 0.5        0.91553333        nan\n",
      " 0.5        0.9057            nan 0.5        0.90633333        nan\n",
      " 0.5        0.9146            nan 0.5        0.9145            nan\n",
      " 0.5        0.9161            nan 0.5        0.91293333        nan\n",
      " 0.5        0.9172            nan 0.5        0.9072            nan\n",
      " 0.5        0.92206667        nan 0.5        0.91543333        nan\n",
      " 0.5        0.91956667        nan 0.5        0.91726667        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9056            nan\n",
      " 0.5        0.91296667        nan 0.5        0.91566667        nan\n",
      " 0.5        0.9014            nan 0.5        0.90813333        nan\n",
      " 0.5        0.90896667        nan 0.5        0.91553333        nan\n",
      " 0.5        0.9162            nan 0.5        0.91193333        nan\n",
      " 0.5        0.91466667        nan 0.5        0.91696667        nan\n",
      " 0.5        0.918             nan 0.5        0.90886667        nan\n",
      " 0.5        0.92706667        nan 0.5        0.91713333        nan\n",
      " 0.5        0.91956667        nan 0.5        0.91886667        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9056            nan\n",
      " 0.5        0.91296667        nan 0.5        0.91406667        nan\n",
      " 0.5        0.9014            nan 0.5        0.90643333        nan\n",
      " 0.5        0.90896667        nan 0.5        0.91553333        nan\n",
      " 0.5        0.9162            nan 0.5        0.91193333        nan\n",
      " 0.5        0.91466667        nan 0.5        0.91696667        nan\n",
      " 0.5        0.918             nan 0.5        0.90886667        nan\n",
      " 0.5        0.92706667        nan 0.5        0.91713333        nan\n",
      " 0.5        0.91956667        nan 0.5        0.91886667        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9056            nan\n",
      " 0.5        0.91296667        nan 0.5        0.91406667        nan\n",
      " 0.5        0.9014            nan 0.5        0.90643333        nan]\n",
      "std_test_score  :  [0.         0.05141494        nan 0.         0.05938677        nan\n",
      " 0.         0.06358454        nan 0.         0.06214952        nan\n",
      " 0.         0.07168088        nan 0.         0.06333386        nan\n",
      " 0.         0.06287898        nan 0.         0.07082705        nan\n",
      " 0.         0.06620955        nan 0.         0.06517511        nan\n",
      " 0.         0.06366914        nan 0.         0.07063521        nan\n",
      " 0.         0.06915107        nan 0.         0.06263465        nan\n",
      " 0.         0.07132523        nan 0.         0.06577524        nan\n",
      " 0.         0.05580846        nan 0.         0.06146838        nan\n",
      " 0.         0.06809887        nan 0.         0.0697576         nan\n",
      " 0.         0.07091728        nan 0.         0.06829264        nan\n",
      " 0.         0.06742645        nan 0.         0.0641076         nan\n",
      " 0.         0.06805398        nan 0.         0.06688659        nan\n",
      " 0.         0.06477988        nan 0.         0.06573352        nan\n",
      " 0.         0.06991523        nan 0.         0.06904794        nan\n",
      " 0.         0.06664461        nan 0.         0.06457335        nan\n",
      " 0.         0.06274911        nan 0.         0.06244201        nan\n",
      " 0.         0.06074742        nan 0.         0.0605792         nan\n",
      " 0.         0.06177725        nan 0.         0.06354286        nan\n",
      " 0.         0.06911003        nan 0.         0.06823981        nan\n",
      " 0.         0.07404508        nan 0.         0.06706012        nan\n",
      " 0.         0.06715145        nan 0.         0.06258271        nan\n",
      " 0.         0.06771635        nan 0.         0.06360124        nan\n",
      " 0.         0.06727701        nan 0.         0.06536686        nan\n",
      " 0.         0.06664461        nan 0.         0.06457335        nan\n",
      " 0.         0.06265652        nan 0.         0.06281281        nan\n",
      " 0.         0.06293404        nan 0.         0.06153785        nan\n",
      " 0.         0.06177725        nan 0.         0.06354286        nan\n",
      " 0.         0.06911003        nan 0.         0.06823981        nan\n",
      " 0.         0.07292466        nan 0.         0.06706012        nan\n",
      " 0.         0.06715145        nan 0.         0.06258271        nan\n",
      " 0.         0.06564966        nan 0.         0.06360124        nan\n",
      " 0.         0.06727701        nan 0.         0.06536686        nan\n",
      " 0.         0.06664461        nan 0.         0.06457335        nan\n",
      " 0.         0.06265652        nan 0.         0.06281281        nan\n",
      " 0.         0.06293404        nan 0.         0.06153785        nan\n",
      " 0.         0.05609159        nan 0.         0.06456349        nan\n",
      " 0.         0.07349079        nan 0.         0.06899973        nan\n",
      " 0.         0.06325706        nan 0.         0.06208269        nan\n",
      " 0.         0.06772597        nan 0.         0.06578928        nan\n",
      " 0.         0.06994355        nan 0.         0.06919613        nan\n",
      " 0.         0.0686925         nan 0.         0.06061751        nan\n",
      " 0.         0.06326616        nan 0.         0.06375148        nan\n",
      " 0.         0.06151654        nan 0.         0.05651328        nan\n",
      " 0.         0.05883599        nan 0.         0.05991266        nan\n",
      " 0.         0.06259716        nan 0.         0.06670591        nan\n",
      " 0.         0.0609504         nan 0.         0.07393496        nan\n",
      " 0.         0.07198986        nan 0.         0.06355335        nan\n",
      " 0.         0.06249928        nan 0.         0.06340552        nan\n",
      " 0.         0.05970209        nan 0.         0.07008817        nan\n",
      " 0.         0.0677641         nan 0.         0.06317653        nan\n",
      " 0.         0.06513837        nan 0.         0.06277461        nan\n",
      " 0.         0.06449198        nan 0.         0.05671527        nan\n",
      " 0.         0.06481346        nan 0.         0.05723775        nan\n",
      " 0.         0.06050798        nan 0.         0.05784869        nan\n",
      " 0.         0.06110786        nan 0.         0.07479903        nan\n",
      " 0.         0.06092764        nan 0.         0.06588141        nan\n",
      " 0.         0.06336876        nan 0.         0.061184          nan\n",
      " 0.         0.06312955        nan 0.         0.07134684        nan\n",
      " 0.         0.0677641         nan 0.         0.06482484        nan\n",
      " 0.         0.06513837        nan 0.         0.06277461        nan\n",
      " 0.         0.06449198        nan 0.         0.05484702        nan\n",
      " 0.         0.06481346        nan 0.         0.06098994        nan\n",
      " 0.         0.06050798        nan 0.         0.05784869        nan\n",
      " 0.         0.06110786        nan 0.         0.07479903        nan\n",
      " 0.         0.06092764        nan 0.         0.06588141        nan\n",
      " 0.         0.06336876        nan 0.         0.061184          nan\n",
      " 0.         0.06312955        nan 0.         0.07134684        nan\n",
      " 0.         0.0677641         nan 0.         0.06482484        nan\n",
      " 0.         0.06513837        nan 0.         0.06277461        nan\n",
      " 0.         0.06449198        nan 0.         0.05484702        nan\n",
      " 0.         0.06481346        nan 0.         0.06098994        nan]\n"
     ]
    }
   ],
   "source": [
    "for i in ['mean_test_score', 'std_test_score']:\n",
    "        print(i,\" : \", gsearch1.cv_results_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_min_child_weight', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9884, val accuracy 0.8140, test accuracy 0.8148\n",
      "precision : 0.6667, recall : 0.8235, f1score : 0.7368, roc : 0.8172\n",
      "[[30  7]\n",
      " [ 3 14]]\n"
     ]
    }
   ],
   "source": [
    "# use best fit model using .best_estimator\n",
    "\n",
    "best_xgb = gsearch1.best_estimator_\n",
    "y_pred = best_xgb.predict(val_scaled)\n",
    "# val_error = mean_squared_error(val_target, y_pred) # 책에 없음\n",
    "# print(\"Validation MSE:\", val_error)           # 책에 없음\n",
    "\n",
    "train_score_xgb = best_xgb.score(train_scaled, train_target)\n",
    "val_score_xgb = best_xgb.score(val_scaled, val_target)\n",
    "test_score_xgb = best_xgb.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, best_xgb.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, best_xgb.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score_xgb, val_score_xgb, test_score_xgb))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naver\n",
    "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.41, eval_metric='logloss',\n",
    "               learning_rate=0.004, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=5, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.005)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.41, 'learning_rate': 0.004, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.005}\n",
    "Best Score: 0.9444444444444444, Best Index: 0\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7917\n",
    "precision : 0.9000, recall : 0.5000, f1score : 0.6429, roc : 0.7333\n",
    "[[29  1]\n",
    " [ 9  9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.003, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.003, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.9777777777777779, Best Index: 216\n",
    "train accuracy: 0.8170, val accuracy 0.8462, test accuracy 0.7292\n",
    "precision : 0.8571, recall : 0.3333, f1score : 0.4800, roc : 0.6500\n",
    "[[29  1]\n",
    " [12  6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scoring을 precision에서 default(accuracy)로 변경한 결과\n",
    "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.005, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.8311827956989248, Best Index: 648\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7708\n",
    "precision : 0.8182, recall : 0.5000, f1score : 0.6207, roc : 0.7167\n",
    "[[28  2]\n",
    " [ 9  9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = None 삽입결과\n",
    "\n",
    "Fitting 5 folds for each of 4608 candidates, totalling 23040 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=None,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.005, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.8311827956989248, Best Index: 864\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7708\n",
    "precision : 0.8182, recall : 0.5000, f1score : 0.6207, roc : 0.7167\n",
    "[[28  2]\n",
    " [ 9  9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
