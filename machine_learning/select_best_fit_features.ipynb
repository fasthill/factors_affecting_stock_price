{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlS4gyYqJVpn"
   },
   "source": [
    "# 가장 좋은 결과를 낼 수 있는 feature항목 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQBDVUjBbIsL"
   },
   "source": [
    "## 모든 feature를 사용한 결과와, 선택 추출된 feature만 사용한 결과 정확도에 차이가 남\n",
    "#### ligistic 회귀 이용하여 coef_ 항목에서 영향력이 높은 feature를 선택. 최적의 갯수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILi_LPl9JVpw"
   },
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EwImyTS9S3QQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀후에 .coef_ 항목에서 기준(criteria, 계수)보다 높은 영향력을 미치는 feature column 선택\n",
    "def select_features(df, coef, criteria):\n",
    "    sel_num = np.where(np.abs(coef) > criteria )[1]\n",
    "    sel_col = df.columns[sel_num]\n",
    "    return sel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data, target):\n",
    "    train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "\n",
    "    lr = LogisticRegression(C=20, max_iter=4000) # max_iter default 100, \n",
    "#     lr = LogisticRegression(C=1, solver='newton_cg', max_iter=1000) # max_iter default 100, \n",
    "    lr.fit(train_scaled, train_target)\n",
    "\n",
    "    train_score = lr.score(train_scaled, train_target)\n",
    "    test_score = lr.score(test_scaled, test_target)\n",
    "#     print(f'train score: {train_score:.4f} \\n test score; {test_score:.4f}')\n",
    "    return train_score, test_score, lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_result(data, target):\n",
    "# min을 하나씩 제거하면서 최고의 결과를 가져오는 feature갯수(항목) 선택\n",
    "\n",
    "    train_score_list= []\n",
    "    test_score_list = []\n",
    "#     data_columns = []\n",
    "#     data_coef = []\n",
    "    test_s = 0\n",
    "    train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "    for _ in range(len(data.columns)-1):\n",
    "        criteria = np.abs(coef).min()\n",
    "        sel_col = select_features(data, coef, criteria)\n",
    "        data = df[sel_col]\n",
    "        train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "\n",
    "        if test_score > test_s:\n",
    "            test_s = test_score\n",
    "            data_columns = sel_col\n",
    "            data_coef = coef\n",
    "\n",
    "        train_score_list.append(train_score)\n",
    "        test_score_list.append(test_score)\n",
    "    \n",
    "    return train_score_list, test_score_list, data_columns, data_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석용 데이터 입력\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "fname = 'df_sec_sel.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:, :-3]\n",
    "target = df.iloc[:, -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "train_score_list, test_score_list, data_columns, data_coef = find_best_result(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_score_list, label = 'train')\n",
    "plt.plot(test_score_list, label = 'test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_columns, data_coef)\n",
    "print(\"train_max: {:.4f}, test_max: {:.4f}\".format(max(train_score_list), max(test_score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data[data_columns]\n",
    "target = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_target, test_target = train_test_split(data_new, target, random_state=42, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input.shape, train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = []\n",
    "for iter in range(5, 50, 1):\n",
    "    sc = SGDClassifier(loss='log', max_iter=iter, random_state=42)\n",
    "#     sc = SGDClassifier(max_iter=iter, random_state=42)\n",
    "    scores = cross_validate(sc,\n",
    "                            X=train_scaled, y=train_target,\n",
    "                            n_jobs=-1)\n",
    "#     print(scores['test_score'].mean())\n",
    "    value.append(scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max\", max(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(value, label = 'test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(num_node, inp_num, num_out, a_layer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_node, activation='sigmoid', input_shape=(inp_num,)))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(Dense(num_out, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_fn(10, len(data_new.columns), 2, Dropout(0.3))\n",
    "model = model_fn(10, len(data_new.columns), 2)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_target), np.unique(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_scaled, train_target, epochs=2000, verbose=0,\n",
    "                    callbacks=[checkpoint_cb, earlystopping_cb],\n",
    "                    validation_data=(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_cb.stopped_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_scaled, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-1 로지스틱 회귀.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
