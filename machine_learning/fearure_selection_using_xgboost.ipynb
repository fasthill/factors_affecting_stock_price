{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix to list 변환\n",
    "def matrix_to_list(confu_matrix):\n",
    "    m_list = []\n",
    "    tn = confu_matrix[0,0]\n",
    "    fp = confu_matrix[0,1]\n",
    "    fn = confu_matrix[1,0]\n",
    "    tp = confu_matrix[1,1]\n",
    "    m_list.extend([tn, fp, fn, tp])\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "#     cm = matrix_to_list(confusion_matrix(test_target, y_predict_list))\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "#     collect_list.extend(cm)\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "#     #Print model report:\n",
    "#     print(\"\\nModel Report\")\n",
    "#     print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions))\n",
    "#     print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Choose all predictors except target & IDcols\n",
    "# predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "# xgb1 = XGBClassifier(\n",
    "#  learning_rate =0.1,\n",
    "#  n_estimators=1000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)\n",
    "# modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'df_sec_sel.pkl'\n",
    "stock_name = 'sec'\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "val_scaled = ss.transform(val_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9826, val accuracy 0.8140, test accuracy 0.8519\n",
      "precision : 0.7143, recall : 0.8824, f1score : 0.7895, roc : 0.8601\n",
      "[[31  6]\n",
      " [ 2 15]]\n"
     ]
    }
   ],
   "source": [
    "xgb = None\n",
    "# xgb = xgboost.XGBRegressor(random_state=42, n_estimator=100, learning_rate=0.01)\n",
    "xgb = xgboost.XGBClassifier(random_state=42, use_label_encoder=False,\n",
    "                            learning_rate =0.22, n_estimators=500, \n",
    "#                             max_depth=5, \n",
    "                            min_child_weight=6, # imbalance 경감\n",
    "                            gamma=0, subsample=0.9, \n",
    "                            colsample_bytree=0.8,\n",
    "                            objective= 'binary:logistic', \n",
    "#                             nthread=4, # Gpu 수\n",
    "                            max_delta_step = 0.5, # best value found\n",
    "                            scale_pos_weight=40,) # class imbalance 경감\n",
    "xgb.fit(train_scaled, train_target, eval_metric = 'logloss')\n",
    "y_pred = xgb.predict(val_scaled)\n",
    "# val_error = mean_squared_error(val_target, y_pred) # 책에 없음\n",
    "# print(\"Validation MSE:\", val_error)           # 책에 없음\n",
    "\n",
    "train_score_xgb = xgb.score(train_scaled, train_target)\n",
    "val_score_xgb = xgb.score(val_scaled, val_target)\n",
    "test_score_xgb = xgb.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, xgb.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, xgb.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score_xgb, val_score_xgb, test_score_xgb))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m param_test1 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale_pos_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_delta_step\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m      9\u001b[0m gsearch1 \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     10\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m XGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                             learning_rate \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.22\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m                             scale_pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,), \u001b[38;5;66;03m# class imbalance 경감, \u001b[39;00m\n\u001b[0;32m     20\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m param_test1, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     param_grid = param_test1, scoring='roc_auc',n_jobs=4, iid=False, cv=5),\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(3,8,2),\n",
    "    'subsample':[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'subsample':[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'scale_pos_weight': range(20, 50, 5),\n",
    "    'max_delta_step': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9]\n",
    "}\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = XGBClassifier(random_state=42, use_label_encoder=False,\n",
    "                            learning_rate =0.22, n_estimators=500, \n",
    "#                             max_depth=5, \n",
    "                            min_child_weight=6, # imbalance 경감\n",
    "                            gamma=0, subsample=0.9, \n",
    "                            colsample_bytree=0.8,\n",
    "                            objective= 'binary:logistic', \n",
    "#                             nthread=4, # Gpu 수\n",
    "                            max_delta_step = 0.5, # best value found\n",
    "                            scale_pos_weight=40,), # class imbalance 경감, \n",
    "    param_grid = param_test1, scoring='roc_auc', cv=5)\n",
    "#     param_grid = param_test1, scoring='roc_auc',n_jobs=4, iid=False, cv=5),\n",
    "    \n",
    "gsearch1.fit(train_scaled, train_target, eval_metric = 'logloss')\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score  :  [0.5        0.91806667        nan 0.5        0.90966667        nan\n",
      " 0.5        0.91546667        nan 0.5        0.91293333        nan\n",
      " 0.5        0.90963333        nan 0.5        0.9145            nan\n",
      " 0.5        0.90633333        nan 0.5        0.9128            nan\n",
      " 0.5        0.9112            nan 0.5        0.91456667        nan\n",
      " 0.5        0.9088            nan 0.5        0.91283333        nan\n",
      " 0.5        0.90803333        nan 0.5        0.91466667        nan\n",
      " 0.5        0.90866667        nan 0.5        0.90796667        nan\n",
      " 0.5        0.91706667        nan 0.5        0.92043333        nan\n",
      " 0.5        0.90883333        nan 0.5        0.90966667        nan\n",
      " 0.5        0.91113333        nan 0.5        0.89726667        nan\n",
      " 0.5        0.89386667        nan 0.5        0.9096            nan\n",
      " 0.5        0.90566667        nan 0.5        0.90386667        nan\n",
      " 0.5        0.90383333        nan 0.5        0.91293333        nan\n",
      " 0.5        0.90873333        nan 0.5        0.9136            nan\n",
      " 0.5        0.91213333        nan 0.5        0.90473333        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9113            nan\n",
      " 0.5        0.91946667        nan 0.5        0.92043333        nan\n",
      " 0.5        0.91806667        nan 0.5        0.91126667        nan\n",
      " 0.5        0.91123333        nan 0.5        0.9063            nan\n",
      " 0.5        0.9079            nan 0.5        0.91213333        nan\n",
      " 0.5        0.90473333        nan 0.5        0.91056667        nan\n",
      " 0.5        0.91453333        nan 0.5        0.9121            nan\n",
      " 0.5        0.91123333        nan 0.5        0.90786667        nan\n",
      " 0.5        0.91213333        nan 0.5        0.90473333        nan\n",
      " 0.5        0.9071            nan 0.5        0.91213333        nan\n",
      " 0.5        0.9178            nan 0.5        0.92123333        nan\n",
      " 0.5        0.91806667        nan 0.5        0.91126667        nan\n",
      " 0.5        0.91123333        nan 0.5        0.9063            nan\n",
      " 0.5        0.9054            nan 0.5        0.91213333        nan\n",
      " 0.5        0.90473333        nan 0.5        0.91056667        nan\n",
      " 0.5        0.91133333        nan 0.5        0.9121            nan\n",
      " 0.5        0.91123333        nan 0.5        0.90786667        nan\n",
      " 0.5        0.91213333        nan 0.5        0.90473333        nan\n",
      " 0.5        0.9071            nan 0.5        0.91213333        nan\n",
      " 0.5        0.9178            nan 0.5        0.92123333        nan\n",
      " 0.5        0.91383333        nan 0.5        0.92016667        nan\n",
      " 0.5        0.90876667        nan 0.5        0.91373333        nan\n",
      " 0.5        0.91866667        nan 0.5        0.91713333        nan\n",
      " 0.5        0.91706667        nan 0.5        0.91056667        nan\n",
      " 0.5        0.918             nan 0.5        0.9172            nan\n",
      " 0.5        0.9172            nan 0.5        0.91886667        nan\n",
      " 0.5        0.90806667        nan 0.5        0.91626667        nan\n",
      " 0.5        0.9089            nan 0.5        0.91143333        nan\n",
      " 0.5        0.9114            nan 0.5        0.91553333        nan\n",
      " 0.5        0.9057            nan 0.5        0.90633333        nan\n",
      " 0.5        0.9146            nan 0.5        0.9145            nan\n",
      " 0.5        0.9161            nan 0.5        0.91293333        nan\n",
      " 0.5        0.9172            nan 0.5        0.9072            nan\n",
      " 0.5        0.92206667        nan 0.5        0.91543333        nan\n",
      " 0.5        0.91956667        nan 0.5        0.91726667        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9056            nan\n",
      " 0.5        0.91296667        nan 0.5        0.91566667        nan\n",
      " 0.5        0.9014            nan 0.5        0.90813333        nan\n",
      " 0.5        0.90896667        nan 0.5        0.91553333        nan\n",
      " 0.5        0.9162            nan 0.5        0.91193333        nan\n",
      " 0.5        0.91466667        nan 0.5        0.91696667        nan\n",
      " 0.5        0.918             nan 0.5        0.90886667        nan\n",
      " 0.5        0.92706667        nan 0.5        0.91713333        nan\n",
      " 0.5        0.91956667        nan 0.5        0.91886667        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9056            nan\n",
      " 0.5        0.91296667        nan 0.5        0.91406667        nan\n",
      " 0.5        0.9014            nan 0.5        0.90643333        nan\n",
      " 0.5        0.90896667        nan 0.5        0.91553333        nan\n",
      " 0.5        0.9162            nan 0.5        0.91193333        nan\n",
      " 0.5        0.91466667        nan 0.5        0.91696667        nan\n",
      " 0.5        0.918             nan 0.5        0.90886667        nan\n",
      " 0.5        0.92706667        nan 0.5        0.91713333        nan\n",
      " 0.5        0.91956667        nan 0.5        0.91886667        nan\n",
      " 0.5        0.91293333        nan 0.5        0.9056            nan\n",
      " 0.5        0.91296667        nan 0.5        0.91406667        nan\n",
      " 0.5        0.9014            nan 0.5        0.90643333        nan]\n",
      "std_test_score  :  [0.         0.05141494        nan 0.         0.05938677        nan\n",
      " 0.         0.06358454        nan 0.         0.06214952        nan\n",
      " 0.         0.07168088        nan 0.         0.06333386        nan\n",
      " 0.         0.06287898        nan 0.         0.07082705        nan\n",
      " 0.         0.06620955        nan 0.         0.06517511        nan\n",
      " 0.         0.06366914        nan 0.         0.07063521        nan\n",
      " 0.         0.06915107        nan 0.         0.06263465        nan\n",
      " 0.         0.07132523        nan 0.         0.06577524        nan\n",
      " 0.         0.05580846        nan 0.         0.06146838        nan\n",
      " 0.         0.06809887        nan 0.         0.0697576         nan\n",
      " 0.         0.07091728        nan 0.         0.06829264        nan\n",
      " 0.         0.06742645        nan 0.         0.0641076         nan\n",
      " 0.         0.06805398        nan 0.         0.06688659        nan\n",
      " 0.         0.06477988        nan 0.         0.06573352        nan\n",
      " 0.         0.06991523        nan 0.         0.06904794        nan\n",
      " 0.         0.06664461        nan 0.         0.06457335        nan\n",
      " 0.         0.06274911        nan 0.         0.06244201        nan\n",
      " 0.         0.06074742        nan 0.         0.0605792         nan\n",
      " 0.         0.06177725        nan 0.         0.06354286        nan\n",
      " 0.         0.06911003        nan 0.         0.06823981        nan\n",
      " 0.         0.07404508        nan 0.         0.06706012        nan\n",
      " 0.         0.06715145        nan 0.         0.06258271        nan\n",
      " 0.         0.06771635        nan 0.         0.06360124        nan\n",
      " 0.         0.06727701        nan 0.         0.06536686        nan\n",
      " 0.         0.06664461        nan 0.         0.06457335        nan\n",
      " 0.         0.06265652        nan 0.         0.06281281        nan\n",
      " 0.         0.06293404        nan 0.         0.06153785        nan\n",
      " 0.         0.06177725        nan 0.         0.06354286        nan\n",
      " 0.         0.06911003        nan 0.         0.06823981        nan\n",
      " 0.         0.07292466        nan 0.         0.06706012        nan\n",
      " 0.         0.06715145        nan 0.         0.06258271        nan\n",
      " 0.         0.06564966        nan 0.         0.06360124        nan\n",
      " 0.         0.06727701        nan 0.         0.06536686        nan\n",
      " 0.         0.06664461        nan 0.         0.06457335        nan\n",
      " 0.         0.06265652        nan 0.         0.06281281        nan\n",
      " 0.         0.06293404        nan 0.         0.06153785        nan\n",
      " 0.         0.05609159        nan 0.         0.06456349        nan\n",
      " 0.         0.07349079        nan 0.         0.06899973        nan\n",
      " 0.         0.06325706        nan 0.         0.06208269        nan\n",
      " 0.         0.06772597        nan 0.         0.06578928        nan\n",
      " 0.         0.06994355        nan 0.         0.06919613        nan\n",
      " 0.         0.0686925         nan 0.         0.06061751        nan\n",
      " 0.         0.06326616        nan 0.         0.06375148        nan\n",
      " 0.         0.06151654        nan 0.         0.05651328        nan\n",
      " 0.         0.05883599        nan 0.         0.05991266        nan\n",
      " 0.         0.06259716        nan 0.         0.06670591        nan\n",
      " 0.         0.0609504         nan 0.         0.07393496        nan\n",
      " 0.         0.07198986        nan 0.         0.06355335        nan\n",
      " 0.         0.06249928        nan 0.         0.06340552        nan\n",
      " 0.         0.05970209        nan 0.         0.07008817        nan\n",
      " 0.         0.0677641         nan 0.         0.06317653        nan\n",
      " 0.         0.06513837        nan 0.         0.06277461        nan\n",
      " 0.         0.06449198        nan 0.         0.05671527        nan\n",
      " 0.         0.06481346        nan 0.         0.05723775        nan\n",
      " 0.         0.06050798        nan 0.         0.05784869        nan\n",
      " 0.         0.06110786        nan 0.         0.07479903        nan\n",
      " 0.         0.06092764        nan 0.         0.06588141        nan\n",
      " 0.         0.06336876        nan 0.         0.061184          nan\n",
      " 0.         0.06312955        nan 0.         0.07134684        nan\n",
      " 0.         0.0677641         nan 0.         0.06482484        nan\n",
      " 0.         0.06513837        nan 0.         0.06277461        nan\n",
      " 0.         0.06449198        nan 0.         0.05484702        nan\n",
      " 0.         0.06481346        nan 0.         0.06098994        nan\n",
      " 0.         0.06050798        nan 0.         0.05784869        nan\n",
      " 0.         0.06110786        nan 0.         0.07479903        nan\n",
      " 0.         0.06092764        nan 0.         0.06588141        nan\n",
      " 0.         0.06336876        nan 0.         0.061184          nan\n",
      " 0.         0.06312955        nan 0.         0.07134684        nan\n",
      " 0.         0.0677641         nan 0.         0.06482484        nan\n",
      " 0.         0.06513837        nan 0.         0.06277461        nan\n",
      " 0.         0.06449198        nan 0.         0.05484702        nan\n",
      " 0.         0.06481346        nan 0.         0.06098994        nan]\n"
     ]
    }
   ],
   "source": [
    "for i in ['mean_test_score', 'std_test_score']:\n",
    "        print(i,\" : \", gsearch1.cv_results_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_min_child_weight', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9884, val accuracy 0.8140, test accuracy 0.8148\n",
      "precision : 0.6667, recall : 0.8235, f1score : 0.7368, roc : 0.8172\n",
      "[[30  7]\n",
      " [ 3 14]]\n"
     ]
    }
   ],
   "source": [
    "# use best fit model using .best_estimator\n",
    "\n",
    "best_xgb = gsearch1.best_estimator_\n",
    "y_pred = best_xgb.predict(val_scaled)\n",
    "# val_error = mean_squared_error(val_target, y_pred) # 책에 없음\n",
    "# print(\"Validation MSE:\", val_error)           # 책에 없음\n",
    "\n",
    "train_score_xgb = best_xgb.score(train_scaled, train_target)\n",
    "val_score_xgb = best_xgb.score(val_scaled, val_target)\n",
    "test_score_xgb = best_xgb.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, best_xgb.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, best_xgb.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score_xgb, val_score_xgb, test_score_xgb))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
