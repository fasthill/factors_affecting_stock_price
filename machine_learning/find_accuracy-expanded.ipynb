{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlS4gyYqJVpn"
   },
   "source": [
    "# 예측이 가능한 종목 추리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQBDVUjBbIsL"
   },
   "source": [
    "## 가장 좋은 결과를 낼 수 있는 feature항목 추출\n",
    "## 모든 feature를 사용한 결과와, 선택 추출된 feature만 사용한 결과 정확도에 차이가 남\n",
    "#### logistic 회귀 이용하여 coef_ 항목에서 영향력이 높은 feature를 선택. 최적의 갯수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILi_LPl9JVpw"
   },
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EwImyTS9S3QQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀후에 .coef_ 항목에서 기준(criteria, 계수)보다 높은 영향력을 미치는 feature column 선택\n",
    "def select_features(df, coef, criteria):\n",
    "    sel_num = np.where(np.abs(coef) > criteria )[1]\n",
    "    sel_col = df.columns[sel_num]\n",
    "    return sel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data, target):\n",
    "    train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "\n",
    "    lr = LogisticRegression(C=20, max_iter=4000) # max_iter default 100, \n",
    "#     lr = LogisticRegression(C=1, solver='newton_cg', max_iter=1000) # max_iter default 100, \n",
    "    lr.fit(train_scaled, train_target)\n",
    "\n",
    "    train_score = lr.score(train_scaled, train_target)\n",
    "    test_score = lr.score(test_scaled, test_target)\n",
    "#     print(f'train score: {train_score:.4f} \\n test score; {test_score:.4f}')\n",
    "    return train_score, test_score, lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_result(data, target):\n",
    "# min을 하나씩 제거하면서 최고의 결과를 가져오는 feature갯수(항목) 선택\n",
    "\n",
    "    train_score_list= []\n",
    "    test_score_list = []\n",
    "#     data_columns = []\n",
    "#     data_coef = []\n",
    "    test_s = 0\n",
    "    train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "    for _ in range(len(data.columns)-1):\n",
    "        criteria = np.abs(coef).min()\n",
    "        sel_col = select_features(data, coef, criteria)\n",
    "        data = df[sel_col]\n",
    "        train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "\n",
    "        if test_score > test_s:\n",
    "            test_s = test_score\n",
    "            data_columns = sel_col\n",
    "            data_coef = coef\n",
    "\n",
    "        train_score_list.append(train_score)\n",
    "        test_score_list.append(test_score)\n",
    "    \n",
    "    return train_score_list, test_score_list, data_columns, data_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(inp_num, a_layer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='sigmoid', input_shape=(inp_num,)))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.1))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix to list 변환\n",
    "def matrix_to_list(matrix):\n",
    "    m_list = []\n",
    "    for cm in confu_matrix:\n",
    "        name = cm[0]\n",
    "        tn = cm[1][0,0]\n",
    "        fp = cm[1][0,1]\n",
    "        fn = cm[1][1,0]\n",
    "        tp = cm[1][1,1]\n",
    "        m_list.append([name, tn, fp, fn, tp])\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "# code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023A7DA7D630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023A7B6FDF30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# 분석용 데이터 입력\n",
    "directory_for_ml = '../data/data_for_ml/expand_date/'\n",
    "logi_accuracy = []\n",
    "sgd_accuracy = []\n",
    "deep_accuracy = []\n",
    "confu_matrix = []\n",
    "for key, val in code.items():\n",
    "    f_name= 'df_{}_{}.pkl'.format(val[1], 'sel')\n",
    "    fname = directory_for_ml + f_name\n",
    "    df = pd.read_pickle(fname)\n",
    "    \n",
    "    data = df.iloc[:, :-5]\n",
    "    target = df.iloc[:, -4]\n",
    "    \n",
    "    # logisticregression 결과 모으기\n",
    "    train_score_list, test_score_list, data_columns, data_coef = find_best_result(data, target)\n",
    "    logi_accuracy.append([val[1], max(train_score_list), max(test_score_list)])\n",
    "    \n",
    "    # SGDregressor 결과 모으기\n",
    "    data_new = data[data_columns] # 선택된 주요 column (feature) 만으로 정확도 계산하기\n",
    "    train_input, test_input, train_target, test_target \\\n",
    "        = train_test_split(data_new, target, random_state=42, test_size=0.2, stratify=target)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    sgd_value = []\n",
    "    for iter in range(5, 50, 1):\n",
    "        sc = SGDClassifier(loss='log', max_iter=iter, random_state=42)\n",
    "        scores = cross_validate(sc, X=train_scaled, y=train_target, n_jobs=-1)\n",
    "        sgd_value.append(scores['test_score'].mean())\n",
    "        \n",
    "    sgd_accuracy.append([val[1], max(sgd_value)])\n",
    "    \n",
    "    # 인공신경망\n",
    "    try :\n",
    "        model = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model = model_fn(len(data_new.columns))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    # checkpoint_cb = ModelCheckpoint(filepath='best_model_{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5', \\\n",
    "#                                                 monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "    checkpoint_cb = ModelCheckpoint(filepath='best_model.h5', save_best_only=True)\n",
    "# earlystopping_cb = EarlyStopping(patience=100, monitor='val_accuracy', mode='max', restore_best_weights=True)\n",
    "    earlystopping_cb = EarlyStopping(patience=100, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(train_scaled, train_target, epochs=2000, verbose=0,\n",
    "                        callbacks=[checkpoint_cb, earlystopping_cb],\n",
    "                        validation_data=(test_scaled, test_target))\n",
    "    \n",
    "    y_predict = model.predict(np.array(test_scaled), verbose=0)\n",
    "    y_predict_list = [1 if i > 0.5 else 0 for i in y_predict[:, 0]]\n",
    "    \n",
    "# 정밀도 : 양성으로 예측된 것(TP+FP) 중 얼마나 많은 샘플이 진짜 양성(TP)인지 측정\n",
    "#     precision_score(test_target, y_predict_list)  # 정밀도, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     recall_score(test_target, y_predict_list)  # 재현율, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     f1_score(test_target, y_predict_list)\n",
    "#     roc_auc_score(test_target, y_predict_list)  \n",
    "    score = model.evaluate(test_scaled, test_target, verbose=0)\n",
    "    deep_accuracy.append([val[1], \n",
    "                          score[0], score[1],\n",
    "                          precision_score(test_target, y_predict_list),\n",
    "                          recall_score(test_target, y_predict_list),\n",
    "                          f1_score(test_target, y_predict_list),\n",
    "                          roc_auc_score(test_target, y_predict_list)  \n",
    "                         ]) \n",
    "    \n",
    "    confu_matrix.append([val[1], confusion_matrix(test_target, y_predict_list)])\n",
    "    \n",
    "    df_logi = pd.DataFrame(logi_accuracy, columns=['name', 'train_max', 'test_max']).set_index('name')\n",
    "    df_sgd = pd.DataFrame(sgd_accuracy, columns=['name', 'sgd_accuracy']).set_index('name')\n",
    "    df_deep = pd.DataFrame(deep_accuracy, \n",
    "                       columns=['name', 'val_loss', 'val_accuracy', 'precision', 'recall', 'f1_score', ' roc_auc_score']).set_index('name')\n",
    "    df_confu_matrix = pd.DataFrame(matrix_to_list(confu_matrix), columns = ['name', 'tn', 'fp', 'fn', 'tp']).set_index('name')\n",
    "\n",
    "    dfs = [df_logi, df_sgd, df_deep, df_confu_matrix ]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right, how='left', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981395</td>\n",
       "      <td>0.076432</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgenergy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skhinix</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssbio</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984308</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sdi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.978805</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgchemical</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secpre</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyunmotor</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naver</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kia</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.085428</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kakao</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994118</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscoholding</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbbank</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sscnt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.107563</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celltrion</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobis</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.007878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shgroup</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgelec</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscochemical</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958095</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skinnovation</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ktng</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968615</td>\n",
       "      <td>0.054907</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_max  test_max  sgd_accuracy  val_loss  val_accuracy  \\\n",
       "name                                                                       \n",
       "sec                  1.0  1.000000      0.981395  0.076432      0.981818   \n",
       "lgenergy             1.0  1.000000      1.000000  0.001890      1.000000   \n",
       "skhinix              1.0  1.000000      1.000000  0.000848      1.000000   \n",
       "ssbio                1.0  1.000000      0.984308  0.003861      1.000000   \n",
       "sdi                  1.0  0.979167      0.978805  0.022799      0.979167   \n",
       "lgchemical           1.0  1.000000      0.994444  0.002111      1.000000   \n",
       "secpre               1.0  1.000000      0.980000  0.009509      1.000000   \n",
       "hyunmotor            1.0  1.000000      0.983333  0.026419      1.000000   \n",
       "naver                1.0  1.000000      0.988889  0.001641      1.000000   \n",
       "kia                  1.0  0.976744      0.988235  0.085428      0.953488   \n",
       "kakao                1.0  1.000000      0.994118  0.034328      1.000000   \n",
       "poscoholding         1.0  1.000000      0.983784  0.001693      1.000000   \n",
       "kbbank               1.0  0.972222      1.000000  0.023173      1.000000   \n",
       "sscnt                1.0  1.000000      0.980000  0.107563      0.961538   \n",
       "celltrion            1.0  1.000000      0.970000  0.013300      1.000000   \n",
       "mobis                1.0  1.000000      0.976000  0.007878      1.000000   \n",
       "shgroup              1.0  1.000000      0.992000  0.054131      1.000000   \n",
       "lgelec               1.0  1.000000      1.000000  0.002256      1.000000   \n",
       "poscochemical        1.0  1.000000      0.958095  0.049444      0.947368   \n",
       "skinnovation         1.0  1.000000      0.982353  0.003017      1.000000   \n",
       "ktng                 1.0  1.000000      0.968615  0.054907      0.969697   \n",
       "\n",
       "               precision    recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                                          \n",
       "sec             0.941176  1.000000  0.969697        0.987179  38   1   0  16  \n",
       "lgenergy        1.000000  1.000000  1.000000        1.000000  25   0   0  19  \n",
       "skhinix         1.000000  1.000000  1.000000        1.000000  33   0   0  18  \n",
       "ssbio           1.000000  1.000000  1.000000        1.000000  20   0   0  13  \n",
       "sdi             1.000000  0.952381  0.975610        0.976190  27   0   1  20  \n",
       "lgchemical      1.000000  1.000000  1.000000        1.000000  28   0   0  18  \n",
       "secpre          1.000000  1.000000  1.000000        1.000000  10   0   0   3  \n",
       "hyunmotor       1.000000  1.000000  1.000000        1.000000  30   0   0  16  \n",
       "naver           1.000000  1.000000  1.000000        1.000000  30   0   0  16  \n",
       "kia             0.875000  1.000000  0.933333        0.965517  27   2   0  14  \n",
       "kakao           1.000000  1.000000  1.000000        1.000000  28   0   0  16  \n",
       "poscoholding    1.000000  1.000000  1.000000        1.000000  30   0   0  17  \n",
       "kbbank          1.000000  1.000000  1.000000        1.000000  22   0   0  14  \n",
       "sscnt           0.888889  1.000000  0.941176        0.972222  17   1   0   8  \n",
       "celltrion       1.000000  1.000000  1.000000        1.000000  14   0   0  12  \n",
       "mobis           1.000000  1.000000  1.000000        1.000000  21   0   0  11  \n",
       "shgroup         1.000000  1.000000  1.000000        1.000000  20   0   0  13  \n",
       "lgelec          1.000000  1.000000  1.000000        1.000000  23   0   0  14  \n",
       "poscochemical   1.000000  0.888889  0.941176        0.944444  10   0   1   8  \n",
       "skinnovation    1.000000  1.000000  1.000000        1.000000  26   0   0  16  \n",
       "ktng            0.900000  1.000000  0.947368        0.979167  23   1   0   9  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 0.7\n",
    "sgd_accuracy = 0.7\n",
    "val_accuracy = 0.7\n",
    "precision = 0.7\n",
    "fi_score = 0.7\n",
    "ratio_min = 0.4\n",
    "ratio_max = 0.6\n",
    "\n",
    "ratio = ((df_merged['fn'] + df_merged['tp']) / (df_merged['tn'] + df_merged['fp'] + df_merged['fn'] + df_merged['tp']))\n",
    "df_sel = (df_merged['test_max'] >= test_max) & \\\n",
    "        (df_merged['sgd_accuracy'] >= sgd_accuracy) & \\\n",
    "        (df_merged['val_accuracy'] >= val_accuracy) & \\\n",
    "        (df_merged['precision'] >= precision) & \\\n",
    "        (df_merged['f1_score'] >= fi_score) & \\\n",
    "        (ratio_min < ratio ) & (ratio < ratio_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgenergy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sdi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.978805</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celltrion</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscochemical</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958095</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_max  test_max  sgd_accuracy  val_loss  val_accuracy  \\\n",
       "name                                                                       \n",
       "lgenergy             1.0  1.000000      1.000000  0.001890      1.000000   \n",
       "sdi                  1.0  0.979167      0.978805  0.022799      0.979167   \n",
       "celltrion            1.0  1.000000      0.970000  0.013300      1.000000   \n",
       "poscochemical        1.0  1.000000      0.958095  0.049444      0.947368   \n",
       "\n",
       "               precision    recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                                          \n",
       "lgenergy             1.0  1.000000  1.000000        1.000000  25   0   0  19  \n",
       "sdi                  1.0  0.952381  0.975610        0.976190  27   0   1  20  \n",
       "celltrion            1.0  1.000000  1.000000        1.000000  14   0   0  12  \n",
       "poscochemical        1.0  0.888889  0.941176        0.944444  10   0   1   8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 정밀도, f1-score, \n",
    "2. confusion matrix ((1,1), (2,2), 두개가 큰 비중이면 good, (1,2)은 틀린것을 맞다라고 구분, (2,1)은 맞는 것을 틀린 것이다 라고 결정하는 항목) 따라서\n",
    "    (2,2) -> (1,2) -> (1,1)로 확인하고. <br>\n",
    "    (1,2)가 크면 모델 제외 (정밀도(precision = TP / (TP + FP) )가 높아야 함. 낮으면 손해를 보게 됨.), <br>\n",
    "    재현율(Recall = TP / (TP + FN) ) 은 손해를 끼치지는 않음.\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/fasthill/My-gist/main/data/picture/confusion_matrix.png\" width=\"800\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수수료: 주식거래수수료 0.015%. 유관기관수수료 0.0036%, 증권거래세 0.08, 농어촌 특별세 0.15%\n",
    "수수료 : (0.015+0.0036 ) * 2 (사고팔때), 증권거래세 : 0.08 + 0.15 (팔때)\n",
    "전체 지출 금액율: 0.2672%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-1 로지스틱 회귀.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
