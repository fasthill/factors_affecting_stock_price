{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlS4gyYqJVpn"
   },
   "source": [
    "# 예측이 가능한 종목 추리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQBDVUjBbIsL"
   },
   "source": [
    "## 가장 좋은 결과를 낼 수 있는 feature항목 추출\n",
    "## 모든 feature를 사용한 결과와, 선택 추출된 feature만 사용한 결과 정확도에 차이가 남\n",
    "#### logistic 회귀 이용하여 coef_ 항목에서 영향력이 높은 feature를 선택. 최적의 갯수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILi_LPl9JVpw"
   },
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EwImyTS9S3QQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀후에 .coef_ 항목에서 기준(criteria, 계수)보다 높은 영향력을 미치는 feature column 선택\n",
    "def select_features(df, coef, criteria):\n",
    "    sel_num = np.where(np.abs(coef) > criteria )[1]\n",
    "    sel_col = df.columns[sel_num]\n",
    "    return sel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data, target):\n",
    "    train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "\n",
    "    lr = LogisticRegression(C=20, max_iter=4000) # max_iter default 100, \n",
    "#     lr = LogisticRegression(C=1, solver='newton_cg', max_iter=1000) # max_iter default 100, \n",
    "    lr.fit(train_scaled, train_target)\n",
    "\n",
    "    train_score = lr.score(train_scaled, train_target)\n",
    "    test_score = lr.score(test_scaled, test_target)\n",
    "#     print(f'train score: {train_score:.4f} \\n test score; {test_score:.4f}')\n",
    "    return train_score, test_score, lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_result(data, target):\n",
    "# min을 하나씩 제거하면서 최고의 결과를 가져오는 feature갯수(항목) 선택\n",
    "\n",
    "    train_score_list= []\n",
    "    test_score_list = []\n",
    "#     data_columns = []\n",
    "#     data_coef = []\n",
    "    test_s = 0\n",
    "    train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "    for _ in range(len(data.columns)-1):\n",
    "        criteria = np.abs(coef).min()\n",
    "        sel_col = select_features(data, coef, criteria)\n",
    "        data = df[sel_col]\n",
    "        train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "\n",
    "        if test_score > test_s:\n",
    "            test_s = test_score\n",
    "            data_columns = sel_col\n",
    "            data_coef = coef\n",
    "\n",
    "        train_score_list.append(train_score)\n",
    "        test_score_list.append(test_score)\n",
    "    \n",
    "    return train_score_list, test_score_list, data_columns, data_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(inp_num, a_layer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='sigmoid', input_shape=(inp_num,)))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.1))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix to list 변환\n",
    "def matrix_to_list(matrix):\n",
    "    m_list = []\n",
    "    for cm in confu_matrix:\n",
    "        name = cm[0]\n",
    "        tn = cm[1][0,0]\n",
    "        fp = cm[1][0,1]\n",
    "        fn = cm[1][1,0]\n",
    "        tp = cm[1][1,1]\n",
    "        m_list.append([name, tn, fp, fn, tp])\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "# code = {'005380' : ['현대차', 'hyunmotor'], '005930' : ['삼성전자', 'sec']}\n",
    "# code = {'373220' : ['LG에너지솔루션', 'lgenergy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vom--- sec\n",
      "vom--- lgenergy\n",
      "vom--- skhinix\n",
      "vom--- ssbio\n",
      "vom--- sdi\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002225D2BC0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "vom--- lgchemical\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002225E4063A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "vom--- secpre\n",
      "vom--- hyunmotor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vom--- naver\n",
      "vom--- kia\n",
      "vom--- kakao\n",
      "vom--- poscoholding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vom--- kbbank\n",
      "vom--- sscnt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vom--- celltrion\n",
      "vom--- mobis\n",
      "vom--- shgroup\n",
      "vom--- lgelec\n",
      "vom--- poscochemical\n",
      "vom--- skinnovation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vom--- ktng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 분석용 데이터 입력\n",
    "directory_for_ml = '../data/data_for_ml/expand_date/'\n",
    "logi_accuracy = []\n",
    "sgd_accuracy = []\n",
    "deep_accuracy = []\n",
    "confu_matrix = []\n",
    "for key, val in code.items():\n",
    "    f_name= 'df_{}_{}.pkl'.format(val[1], 'sel')\n",
    "    fname = directory_for_ml + f_name\n",
    "    df = pd.read_pickle(fname)\n",
    "    \n",
    "    # bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "    df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   \n",
    "    \n",
    "    data = df.iloc[:, :-5]\n",
    "    target = df.iloc[:, -4]\n",
    "    \n",
    "    col_name = data.columns  # df로 되돌리기 위하여 진행. impute하면  np.array로 변환됨.\n",
    "    data = data.replace([np.inf, -np.inf], np.nan) # replace 메서드로 np.inf를 None(np.nan)\n",
    "    # imputer = SimpleImputer(missing_values=np.inf, strategy = 'mean')\n",
    "    imputer = SimpleImputer(strategy = 'mean')\n",
    "    data = imputer.fit_transform(data)\n",
    "    \n",
    "    data = pd.DataFrame(data, columns=col_name)\n",
    "        \n",
    "    if data.isnull().values.any():\n",
    "        print(\"com_name\", val[1])\n",
    "\n",
    "    print(\"vom---\", val[1])\n",
    "    # logisticregression 결과 모으기\n",
    "    train_score_list, test_score_list, data_columns, data_coef = find_best_result(data, target)\n",
    "    logi_accuracy.append([val[1], max(train_score_list), max(test_score_list)])\n",
    "    \n",
    "    # SGDregressor 결과 모으기\n",
    "    data_new = data[data_columns] # 선택된 주요 column (feature) 만으로 정확도 계산하기\n",
    "    train_input, test_input, train_target, test_target \\\n",
    "        = train_test_split(data_new, target, random_state=42, test_size=0.2, stratify=target)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    sgd_value = []\n",
    "    for iter in range(5, 50, 1):\n",
    "        sc = SGDClassifier(loss='log', max_iter=iter, random_state=42)\n",
    "        scores = cross_validate(sc, X=train_scaled, y=train_target, n_jobs=-1)\n",
    "        sgd_value.append(scores['test_score'].mean())\n",
    "        \n",
    "    sgd_accuracy.append([val[1], max(sgd_value)])\n",
    "    \n",
    "    # 인공신경망\n",
    "    try :\n",
    "        model = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model = model_fn(len(data_new.columns))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    # checkpoint_cb = ModelCheckpoint(filepath='best_model_{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5', \\\n",
    "#                                                 monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "    checkpoint_cb = ModelCheckpoint(filepath='best_model.h5', save_best_only=True)\n",
    "# earlystopping_cb = EarlyStopping(patience=100, monitor='val_accuracy', mode='max', restore_best_weights=True)\n",
    "    earlystopping_cb = EarlyStopping(patience=100, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(train_scaled, train_target, epochs=2000, verbose=0,\n",
    "                        callbacks=[checkpoint_cb, earlystopping_cb],\n",
    "                        validation_data=(test_scaled, test_target))\n",
    "    \n",
    "    y_predict = model.predict(np.array(test_scaled), verbose=0)\n",
    "    y_predict_list = [1 if i > 0.5 else 0 for i in y_predict[:, 0]]\n",
    "    \n",
    "# 정밀도 : 양성으로 예측된 것(TP+FP) 중 얼마나 많은 샘플이 진짜 양성(TP)인지 측정\n",
    "#     precision_score(test_target, y_predict_list)  # 정밀도, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     recall_score(test_target, y_predict_list)  # 재현율, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     f1_score(test_target, y_predict_list)\n",
    "#     roc_auc_score(test_target, y_predict_list)  \n",
    "    score = model.evaluate(test_scaled, test_target, verbose=0)\n",
    "    deep_accuracy.append([val[1], \n",
    "                          score[0], score[1],\n",
    "                          precision_score(test_target, y_predict_list),\n",
    "                          recall_score(test_target, y_predict_list),\n",
    "                          f1_score(test_target, y_predict_list),\n",
    "                          roc_auc_score(test_target, y_predict_list)  \n",
    "                         ]) \n",
    "    \n",
    "    confu_matrix.append([val[1], confusion_matrix(test_target, y_predict_list)])\n",
    "    \n",
    "    df_logi = pd.DataFrame(logi_accuracy, columns=['name', 'train_max', 'test_max']).set_index('name')\n",
    "    df_sgd = pd.DataFrame(sgd_accuracy, columns=['name', 'sgd_accuracy']).set_index('name')\n",
    "    df_deep = pd.DataFrame(deep_accuracy, \n",
    "                       columns=['name', 'val_loss', 'val_accuracy', 'precision', 'recall', 'f1_score', ' roc_auc_score']).set_index('name')\n",
    "    df_confu_matrix = pd.DataFrame(matrix_to_list(confu_matrix), columns = ['name', 'tn', 'fp', 'fn', 'tp']).set_index('name')\n",
    "\n",
    "    dfs = [df_logi, df_sgd, df_deep, df_confu_matrix ]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right, how='left', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>0.865116</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.711628</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577107</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgenergy</th>\n",
       "      <td>0.885057</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.632605</td>\n",
       "      <td>0.631958</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.630526</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skhinix</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.596475</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.593434</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssbio</th>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.656308</td>\n",
       "      <td>0.671446</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.550607</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sdi</th>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.675391</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.732601</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgchemical</th>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.607923</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secpre</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.775556</td>\n",
       "      <td>0.472034</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyunmotor</th>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.681270</td>\n",
       "      <td>0.645382</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naver</th>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.605990</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.605042</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kia</th>\n",
       "      <td>0.868263</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.670766</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kakao</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.672941</td>\n",
       "      <td>0.574510</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscoholding</th>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.679429</td>\n",
       "      <td>0.652543</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbbank</th>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.601401</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sscnt</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.649473</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celltrion</th>\n",
       "      <td>0.959596</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.605789</td>\n",
       "      <td>0.691199</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.402597</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobis</th>\n",
       "      <td>0.911290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.654667</td>\n",
       "      <td>0.605083</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shgroup</th>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.588677</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgelec</th>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.673153</td>\n",
       "      <td>0.578608</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650641</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscochemical</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.717123</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skinnovation</th>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.668806</td>\n",
       "      <td>0.639078</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ktng</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.603409</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_max  test_max  sgd_accuracy  val_loss  val_accuracy  \\\n",
       "name                                                                       \n",
       "sec             0.865116  0.703704      0.711628  0.572289      0.703704   \n",
       "lgenergy        0.885057  0.659091      0.632605  0.631958      0.659091   \n",
       "skhinix         0.825000  0.745098      0.715000  0.596475      0.686275   \n",
       "ssbio           0.976562  0.625000      0.656308  0.671446      0.625000   \n",
       "sdi             0.803191  0.723404      0.675391  0.620137      0.744681   \n",
       "lgchemical      0.794444  0.666667      0.644444  0.607923      0.622222   \n",
       "secpre          1.000000  0.692308      0.775556  0.472034      0.923077   \n",
       "hyunmotor       0.877095  0.666667      0.681270  0.645382      0.644444   \n",
       "naver           0.832402  0.666667      0.692857  0.605990      0.666667   \n",
       "kia             0.868263  0.785714      0.670766  0.529637      0.714286   \n",
       "kakao           0.888889  0.674419      0.672941  0.574510      0.674419   \n",
       "poscoholding    0.853261  0.630435      0.679429  0.652543      0.652174   \n",
       "kbbank          0.901408  0.722222      0.675862  0.601401      0.666667   \n",
       "sscnt           0.960000  0.769231      0.690000  0.649473      0.653846   \n",
       "celltrion       0.959596  0.760000      0.605789  0.691199      0.440000   \n",
       "mobis           0.911290  0.709677      0.654667  0.605083      0.709677   \n",
       "shgroup         0.945312  0.787879      0.688923  0.588677      0.696970   \n",
       "lgelec          0.902778  0.756757      0.673153  0.578608      0.729730   \n",
       "poscochemical   1.000000  0.611111      0.604762  0.717123      0.555556   \n",
       "skinnovation    0.855422  0.690476      0.668806  0.639078      0.642857   \n",
       "ktng            0.953125  0.687500      0.774154  0.603409      0.718750   \n",
       "\n",
       "               precision    recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                                          \n",
       "sec             0.571429  0.235294  0.333333        0.577107  34   3  13   4  \n",
       "lgenergy        0.666667  0.421053  0.516129        0.630526  21   4  11   8  \n",
       "skhinix         0.625000  0.277778  0.384615        0.593434  30   3  13   5  \n",
       "ssbio           0.666667  0.153846  0.250000        0.550607  18   1  11   2  \n",
       "sdi             0.764706  0.619048  0.684211        0.732601  22   4   8  13  \n",
       "lgchemical      0.533333  0.444444  0.484848        0.592593  20   7  10   8  \n",
       "secpre          1.000000  0.750000  0.857143        0.875000   9   0   1   3  \n",
       "hyunmotor       0.000000  0.000000  0.000000        0.500000  29   0  16   0  \n",
       "naver           0.600000  0.352941  0.444444        0.605042  24   4  11   6  \n",
       "kia             0.666667  0.285714  0.400000        0.607143  26   2  10   4  \n",
       "kakao           0.533333  0.533333  0.533333        0.641667  21   7   7   8  \n",
       "poscoholding    0.000000  0.000000  0.000000        0.500000  30   0  16   0  \n",
       "kbbank          0.571429  0.307692  0.400000        0.588629  20   3   9   4  \n",
       "sscnt           0.000000  0.000000  0.000000        0.500000  17   0   9   0  \n",
       "celltrion       0.200000  0.090909  0.125000        0.402597  10   4  10   1  \n",
       "mobis           1.000000  0.181818  0.307692        0.590909  20   0   9   2  \n",
       "shgroup         0.600000  0.272727  0.375000        0.590909  20   2   8   3  \n",
       "lgelec          0.714286  0.384615  0.500000        0.650641  22   2   8   5  \n",
       "poscochemical   0.538462  0.777778  0.636364        0.555556   3   6   2   7  \n",
       "skinnovation    0.000000  0.000000  0.000000        0.500000  27   0  15   0  \n",
       "ktng            0.000000  0.000000  0.000000        0.500000  23   0   9   0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 0.7\n",
    "sgd_accuracy = 0.7\n",
    "val_accuracy = 0.7\n",
    "precision = 0.7\n",
    "fi_score = 0.7\n",
    "ratio_min = 0.4\n",
    "ratio_max = 0.6\n",
    "\n",
    "ratio = ((df_merged['fn'] + df_merged['tp']) / (df_merged['tn'] + df_merged['fp'] + df_merged['fn'] + df_merged['tp']))\n",
    "df_sel = (df_merged['test_max'] >= test_max) & \\\n",
    "        (df_merged['sgd_accuracy'] >= sgd_accuracy) & \\\n",
    "        (df_merged['val_accuracy'] >= val_accuracy) & \\\n",
    "        (df_merged['precision'] >= precision) & \\\n",
    "        (df_merged['f1_score'] >= fi_score) & \\\n",
    "        (ratio_min < ratio ) & (ratio < ratio_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 정밀도, f1-score, \n",
    "2. confusion matrix ((1,1), (2,2), 두개가 큰 비중이면 good, (1,2)은 틀린것을 맞다라고 구분, (2,1)은 맞는 것을 틀린 것이다 라고 결정하는 항목) 따라서\n",
    "    (2,2) -> (1,2) -> (1,1)로 확인하고. <br>\n",
    "    (1,2)가 크면 모델 제외 (정밀도(precision = TP / (TP + FP) )가 높아야 함. 낮으면 손해를 보게 됨.), <br>\n",
    "    재현율(Recall = TP / (TP + FN) ) 은 손해를 끼치지는 않음.\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/fasthill/My-gist/main/data/picture/confusion_matrix.png\" width=\"800\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수수료: 주식거래수수료 0.015%. 유관기관수수료 0.0036%, 증권거래세 0.08, 농어촌 특별세 0.15%\n",
    "수수료 : (0.015+0.0036 ) * 2 (사고팔때), 증권거래세 : 0.08 + 0.15 (팔때)\n",
    "전체 지출 금액율: 0.2672%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-1 로지스틱 회귀.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
