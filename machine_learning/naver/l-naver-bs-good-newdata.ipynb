{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "    df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) \n",
    "    \n",
    "# def load_dict_from_csv(path):\n",
    "#     df = pd.read_csv(path, header=None)\n",
    "#     my_dict = df.to_dict()\n",
    "#     return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(lgbm, model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target,\n",
    "                 test_scaled1, test_scaled2, test_scaled3, test_target1, test_target2, test_target3):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbm.best_score_ \n",
    "    result_dict['best_index'] = lgbm.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled1)\n",
    "    result_dict['acc_test1'] = model.score(test_scaled1, test_target1)\n",
    "    result_dict['precision1'] = precision_score(test_target1, y_predict)\n",
    "    result_dict['recall1'] = recall_score(test_target1, y_predict)\n",
    "    result_dict['f1score1'] = f1_score(test_target1, y_predict)\n",
    "    result_dict['roc1'] = roc_auc_score(test_target1, y_predict)\n",
    "    cm = confusion_matrix(test_target1, y_predict)\n",
    "    result_dict['tn1'] = cm[0,0]\n",
    "    result_dict['fp1'] = cm[0,1]\n",
    "    result_dict['fn1'] = cm[1,0]\n",
    "    result_dict['tp1'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled2)\n",
    "    result_dict['acc_test2'] = model.score(test_scaled2, test_target2)\n",
    "    result_dict['precision2'] = precision_score(test_target2, y_predict)\n",
    "    result_dict['recall2'] = recall_score(test_target2, y_predict)\n",
    "    result_dict['f1score2'] = f1_score(test_target2, y_predict)\n",
    "    result_dict['roc2'] = roc_auc_score(test_target2, y_predict)\n",
    "    cm = confusion_matrix(test_target2, y_predict)\n",
    "    result_dict['tn2'] = cm[0,0]\n",
    "    result_dict['fp2'] = cm[0,1]\n",
    "    result_dict['fn2'] = cm[1,0]\n",
    "    result_dict['tp2'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled3)\n",
    "    result_dict['acc_test3'] = model.score(test_scaled3, test_target3)\n",
    "    result_dict['precision3'] = precision_score(test_target3, y_predict)\n",
    "    result_dict['recall3'] = recall_score(test_target3, y_predict)\n",
    "    result_dict['f1score3'] = f1_score(test_target3, y_predict)\n",
    "    result_dict['roc3'] = roc_auc_score(test_target3, y_predict)\n",
    "    cm = confusion_matrix(test_target3, y_predict)\n",
    "    result_dict['tn3'] = cm[0,0]\n",
    "    result_dict['fp3'] = cm[0,1]\n",
    "    result_dict['fn3'] = cm[1,0]\n",
    "    result_dict['tp3'] = cm[1,1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters and columns used for the analysis\n",
    "def save_parameters(iter, com_name, dt, precision, gsbs, params, new_col):\n",
    "    save_to_pickle(f'./{com_name}/params_{gsbs}_{dt}_{round(precision*100):2d}%_ver{iter}.pkl', params)\n",
    "    save_dict_to_csv(f'./{com_name}/params_{gsbs}_{dt}_{round(precision*100):2d}%_ver{iter}.csv', params)\n",
    "    save_to_pickle(f'./{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_ver{iter}.pkl', new_col)\n",
    "    save_list_to_csv(f'./{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_ver{iter}.csv', new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_results(com_name, model, scaler, columns, df_base):\n",
    "    joblib.dump(model, f'./{com_name}/best_model.pkl') # estimaor 저장\n",
    "    joblib.dump(scaler, f'./{com_name}/best_scaler.pkl') # scaler 저장\n",
    "    save_to_pickle(f'./{com_name}/best_model_p.pkl', model)\n",
    "    save_to_pickle(f'./{com_name}/best_scaler_p.pkl', scaler)\n",
    "    save_to_pickle(f'./{com_name}/best_columns.pkl', new_col)\n",
    "    save_list_to_csv(f'./{com_name}/best_columns.csv', new_col)\n",
    "    df_base.to_pickle(f'./{com_name}/best_result.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng'], '030200' : ['KT', 'kt']}\n",
    "\n",
    "code = {'035420' : ['NAVER', 'naver']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "#             'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', \n",
    "            'privequity_1',  'insurance_1', 'corporateetc_1', # bank_1, 'financeetc_1 제외\n",
    "            'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "#             'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', \n",
    "            'privequity_2', 'insurance_2', 'corporateetc_2', # bank_2, 'financeetc_2 제외\n",
    "            'foreigneretc_2']\n",
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']\n",
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']\n",
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]\n",
    "col_futures = ['ixic_f_cr', 'ixic_f_cr_2', 'spx_f_cr', 'spx_f_cr_2', 'dji_f_cr', 'dji_f_cr_2',\n",
    "           'wti_cr','wti_cr_2', 'dxy_cr', 'dxy_cr_2', 'bond_usa_10_cr', 'bond_usa_10_cr_2' ]\n",
    "column_o = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr\n",
    "\n",
    "col_except_futures = [item for item in column_o if item not in col_futures]\n",
    "\n",
    "new_col = col_except_futures.copy()\n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 신규 분석 데이터는 아래 것으로 사용\n",
    "\n",
    "com_name = list(code.values())[0][1]\n",
    "\n",
    "directory_for_ml = '../data/data_for_ml/predict/'\n",
    "fname = f'df_{com_name}_combine.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df_o = pd.read_pickle(f_name) \n",
    "df_o = df_o.iloc[:-1] # /predict/를 사용할 경우 마지막 prediction data 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = None\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'boosting_type' : ['gbdt', 'dart', ],# ['gbdt', 'dart', 'goss'],\n",
    "    'learning_rate': (0.0001, 0.004, 'log-uniform'),\n",
    "    'num_leaves': (3, 15),      \n",
    "    'max_depth': (0, 50), #[-1], #(0, 50),\n",
    "    'min_child_samples': (5, 40),\n",
    "    'min_child_weight': (0, 15), # 가장 마지막으로 조정함.  precison이 마지막으로 true positive가 올라감.\n",
    "    'max_bin': (100, 1000), # 사용시 0.75%로 올라감 default: 255\n",
    "#     'max_cat_threshold' : (1, 100),\n",
    "    'subsample': (0.005, 1.0, 'uniform'), # == bagging_fraction\n",
    "#     'subsample_freq': (1, 10),\n",
    "    'colsample_bytree': (0.005, 1.0, 'uniform'),\n",
    "    'subsample_for_bin': (100000, 1000000),\n",
    "    'scale_pos_weight': np.arange(0.1, 2, 0.05) ,\n",
    "    'n_estimators': (700, 4000),\n",
    "#     'reg_alpha' : (0, 4.0, 'uniform'), # =='lambda_l1': [0, 5], # default 0\n",
    "#     'reg_lambda' : (0, 4.0, 'uniform'), # == lambda_l2': [0, 5], #default 0    \n",
    "    'reg_alpha' : np.arange(0, 2, 0.1), # 2로 바꾸니 precision이 많이 올라감.\n",
    "    'reg_lambda' : np.arange(0, 2, 0.1),\n",
    "    'force_col_wise': ['true'], \n",
    "    'boost_from_average' : [True, False],\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'cv' : 3,\n",
    "#     'cv' : None,\n",
    "#     'scoring' : None,\n",
    "#     'scoring' : 'f1',\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 30,\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.min child weight 삭제 -> 올라감\n",
    "2.accuracy로 수정 -> 많이 내려감 따라서 precision으로 하고,\n",
    "3.n-estimator 4000에서 5000으로\n",
    "4.'reg_alpha' :(0, 2, 0.1)-=> (0, 3, 0.1), 'reg_lambda' : (0, 2, 0.1),-> (0, 1, 0.1),\n",
    "5. 2번으로 조정하고, iteration 60으로 -> 변함없음. -> 40으로 조정 변경 변함없음. -> 30으로 같음.\n",
    "6. subsample_for_bin': (100000, 500000) -> (100000, 1000000) 약간 내려감.\n",
    "7. 'min_child_weight': (0, 15) 살리고 15로 수정\n",
    "8. subsample_for_bin': (100000, 1000000) -> (100000, 1100000) , 'reg_alpha' :(0, 2, 0.1)-=> (0, 3, 0.1), 'reg_lambda' : (0, 2, 0.1),-> (0, 3, 0.1) 으로\n",
    "9. 8을 원상태로 하고, iteration을 30 -> 20으로, cv를 3->5로.\n",
    "10. 7로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = search_space.copy() # for Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbm BS ******\n",
      "**** End of BayesSearchCV Process ****\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(com_name):\n",
    "    os.makedirs(com_name)\n",
    "    \n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmBS = None\n",
    "    gsbs = 'bs'\n",
    "    \n",
    "    lgbmBS = BayesSearchCV( estimator = lightgbm.LGBMClassifier(objective='binary',\n",
    "#                                                                 metric='precision',\n",
    "                                                                n_jobs=-1,\n",
    "                                                                verbose=0),\n",
    "                           search_spaces = params_space,\n",
    "                           scoring = param_grid['scoring'],\n",
    "                           cv = StratifiedKFold( n_splits=param_grid['cv'],\n",
    "                                                 shuffle=True,\n",
    "                                                 random_state=42 ),\n",
    "                           n_jobs = -1, # 자동 검색 적용\n",
    "                           n_iter = param_grid['iterations'],   \n",
    "                           verbose = 0, refit = True, random_state = 42 \n",
    "                          )\n",
    "                          \n",
    "    print(\"*** after lgbm BS ******\")\n",
    "    lgbmBS.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "\n",
    "# save model\n",
    "    stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "    dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "    dt = f'{dt[:4]}_{dt[4:]}'\n",
    "#     joblib.dump(lgbmBS, f'./{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\n",
    "    save_to_pickle(f'./{com_name}/model_{gsbs}_{dt}_v{iter}.pkl', lgbmBS.best_estimator_)\n",
    "#     joblib.dump(scaler, f'./{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\n",
    "    save_to_pickle(f'./{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl', scaler)\n",
    "    \n",
    "    df_estimator = make_df_from_estimator(lgbmBS.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmBS, lgbmBS.best_estimator_, \n",
    "                               train_scaled, val_scaled, test_scaled,  \n",
    "                               train_target, val_target, test_target,\n",
    "                               test_scaled1, test_scaled2, test_scaled3,  \n",
    "                               test_target1, test_target2, test_target3\n",
    "                              )\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_grid = make_df_from_estimator(param_grid, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_grid, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1score = df_concat.loc['f1score'].iloc[0]\n",
    "    \n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1score >= 0.6) :\n",
    "        df_base.to_csv(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.pkl')\n",
    "#         params_o = make_new_parameter(params_o, df_concat)\n",
    "        save_parameters(iter, com_name, dt, precision, gsbs, params_space, new_col)\n",
    "        break\n",
    "    if iter >= 1 : \n",
    "        df_base.to_csv(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.pkl')\n",
    "#         params_o = make_new_parameter(params_o, df_concat)\n",
    "        save_parameters(iter, com_name, dt, precision, gsbs, params_space, new_col)\n",
    "        break\n",
    "    print(\"******* No.{} BS Process is Done! ********\".format(iter))\n",
    "#     params_o = make_new_parameter(params_o, df_concat)\n",
    "    save_parameters(iter, com_name, dt, precision, gsbs, params_space, new_col)\n",
    "    \n",
    "print(\"**** End of BayesSearchCV Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value11</th>\n",
       "      <th>value12</th>\n",
       "      <th>value13</th>\n",
       "      <th>value14</th>\n",
       "      <th>value15</th>\n",
       "      <th>value16</th>\n",
       "      <th>value17</th>\n",
       "      <th>value18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.421697</td>\n",
       "      <td>0.306893</td>\n",
       "      <td>0.167789</td>\n",
       "      <td>0.784319</td>\n",
       "      <td>0.369986</td>\n",
       "      <td>0.784319</td>\n",
       "      <td>0.167789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>3302</td>\n",
       "      <td>2779</td>\n",
       "      <td>2643</td>\n",
       "      <td>2006</td>\n",
       "      <td>1587</td>\n",
       "      <td>2006</td>\n",
       "      <td>2643</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.538241</td>\n",
       "      <td>0.052579</td>\n",
       "      <td>0.648771</td>\n",
       "      <td>0.779208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.779208</td>\n",
       "      <td>0.648771</td>\n",
       "      <td>0.020883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>866459</td>\n",
       "      <td>708990</td>\n",
       "      <td>949309</td>\n",
       "      <td>968318</td>\n",
       "      <td>1100000</td>\n",
       "      <td>968318</td>\n",
       "      <td>949309</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>179</td>\n",
       "      <td>156</td>\n",
       "      <td>435</td>\n",
       "      <td>244</td>\n",
       "      <td>790</td>\n",
       "      <td>244</td>\n",
       "      <td>435</td>\n",
       "      <td>861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.790385</td>\n",
       "      <td>0.831349</td>\n",
       "      <td>0.798077</td>\n",
       "      <td>0.831349</td>\n",
       "      <td>0.790385</td>\n",
       "      <td>0.895833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.807292</td>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.848958</td>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.807292</td>\n",
       "      <td>0.739583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.562217</td>\n",
       "      <td>0.562217</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.605204</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.562217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test1</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score1</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc1</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test2</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score2</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc2</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value11         value12         value13  \\\n",
       "parameter                                                            \n",
       "boosting_type                 gbdt            gbdt            gbdt   \n",
       "class_weight                  None            None            None   \n",
       "colsample_bytree          0.421697        0.306893        0.167789   \n",
       "importance_type              split           split           split   \n",
       "learning_rate              0.00031        0.002423        0.001916   \n",
       "max_depth                       28               7              23   \n",
       "min_child_samples               18              27              32   \n",
       "min_child_weight             0.001               5               8   \n",
       "min_split_gain                 0.0             0.0             0.0   \n",
       "n_estimators                  3302            2779            2643   \n",
       "n_jobs                          -1              -1              -1   \n",
       "num_leaves                       8              15              10   \n",
       "objective                   binary          binary          binary   \n",
       "random_state                  None            None            None   \n",
       "reg_alpha                      1.2             0.7             0.9   \n",
       "reg_lambda                     0.1             1.2             1.8   \n",
       "silent                        warn            warn            warn   \n",
       "subsample                 0.538241        0.052579        0.648771   \n",
       "subsample_for_bin           866459          708990          949309   \n",
       "subsample_freq                   0               0               0   \n",
       "verbose                          0               0               0   \n",
       "boost_from_average            True            True            True   \n",
       "force_col_wise                true            true            true   \n",
       "max_bin                        179             156             435   \n",
       "metric              binary_logloss  binary_logloss  binary_logloss   \n",
       "scale_pos_weight               0.5            0.35             0.6   \n",
       "cv                               3               3               3   \n",
       "scoring                  precision       precision       precision   \n",
       "num_col                         98              98              98   \n",
       "iterations                      30              30              30   \n",
       "best_score                0.771429        0.916667        0.790385   \n",
       "best_index                    25.0             1.0             5.0   \n",
       "acc_train                 0.776042        0.786458        0.807292   \n",
       "acc_val                   0.583333        0.520833        0.520833   \n",
       "acc_test                  0.616667        0.616667        0.666667   \n",
       "precision                      0.8             0.8             0.8   \n",
       "recall                    0.153846        0.153846        0.307692   \n",
       "f1score                   0.258065        0.258065        0.444444   \n",
       "roc                       0.562217        0.562217        0.624434   \n",
       "tn                            33.0            33.0            32.0   \n",
       "fp                             1.0             1.0             2.0   \n",
       "fn                            22.0            22.0            18.0   \n",
       "tp                             4.0             4.0             8.0   \n",
       "acc_test1                     0.55            0.65             0.7   \n",
       "precision1                     1.0             1.0             1.0   \n",
       "recall1                        0.1             0.3             0.4   \n",
       "f1score1                  0.181818        0.461538        0.571429   \n",
       "roc1                          0.55            0.65             0.7   \n",
       "tn1                           10.0            10.0            10.0   \n",
       "fp1                            0.0             0.0             0.0   \n",
       "fn1                            9.0             7.0             6.0   \n",
       "tp1                            1.0             3.0             4.0   \n",
       "acc_test2                     0.65            0.55            0.65   \n",
       "precision2                     1.0             0.0             1.0   \n",
       "recall2                   0.222222             0.0        0.222222   \n",
       "f1score2                  0.363636             0.0        0.363636   \n",
       "roc2                      0.611111             0.5        0.611111   \n",
       "tn2                           11.0            11.0            11.0   \n",
       "fp2                            0.0             0.0             0.0   \n",
       "fn2                            7.0             9.0             7.0   \n",
       "\n",
       "                           value14         value15         value16  \\\n",
       "parameter                                                            \n",
       "boosting_type                 dart            gbdt            dart   \n",
       "class_weight                  None            None            None   \n",
       "colsample_bytree          0.784319        0.369986        0.784319   \n",
       "importance_type              split           split           split   \n",
       "learning_rate             0.003807           0.004        0.003807   \n",
       "max_depth                       47              50              47   \n",
       "min_child_samples               28              40              28   \n",
       "min_child_weight                10               0              10   \n",
       "min_split_gain                 0.0             0.0             0.0   \n",
       "n_estimators                  2006            1587            2006   \n",
       "n_jobs                          -1              -1              -1   \n",
       "num_leaves                       8               4               8   \n",
       "objective                   binary          binary          binary   \n",
       "random_state                  None            None            None   \n",
       "reg_alpha                      0.4             2.3             0.4   \n",
       "reg_lambda                     1.8             2.9             1.8   \n",
       "silent                        warn            warn            warn   \n",
       "subsample                 0.779208             1.0        0.779208   \n",
       "subsample_for_bin           968318         1100000          968318   \n",
       "subsample_freq                   0               0               0   \n",
       "verbose                          0               0               0   \n",
       "boost_from_average            True            True            True   \n",
       "force_col_wise                true            true            true   \n",
       "max_bin                        244             790             244   \n",
       "metric              binary_logloss  binary_logloss  binary_logloss   \n",
       "scale_pos_weight               0.6            0.65             0.6   \n",
       "cv                               3               5               3   \n",
       "scoring                  precision       precision       precision   \n",
       "num_col                         98              98              98   \n",
       "iterations                      30              20              30   \n",
       "best_score                0.831349        0.798077        0.831349   \n",
       "best_index                    12.0            15.0            12.0   \n",
       "acc_train                 0.776042        0.848958        0.776042   \n",
       "acc_val                   0.541667        0.479167        0.541667   \n",
       "acc_test                  0.633333            0.65        0.633333   \n",
       "precision                     0.75        0.777778            0.75   \n",
       "recall                    0.230769        0.269231        0.230769   \n",
       "f1score                   0.352941             0.4        0.352941   \n",
       "roc                       0.585973        0.605204        0.585973   \n",
       "tn                            32.0            32.0            32.0   \n",
       "fp                             2.0             2.0             2.0   \n",
       "fn                            20.0            19.0            20.0   \n",
       "tp                             6.0             7.0             6.0   \n",
       "acc_test1                      0.6             0.7             0.6   \n",
       "precision1                     1.0             1.0             1.0   \n",
       "recall1                        0.2             0.4             0.2   \n",
       "f1score1                  0.333333        0.571429        0.333333   \n",
       "roc1                           0.6             0.7             0.6   \n",
       "tn1                           10.0            10.0            10.0   \n",
       "fp1                            0.0             0.0             0.0   \n",
       "fn1                            8.0             6.0             8.0   \n",
       "tp1                            2.0             4.0             2.0   \n",
       "acc_test2                     0.65            0.65            0.65   \n",
       "precision2                     1.0             1.0             1.0   \n",
       "recall2                   0.222222        0.222222        0.222222   \n",
       "f1score2                  0.363636        0.363636        0.363636   \n",
       "roc2                      0.611111        0.611111        0.611111   \n",
       "tn2                           11.0            11.0            11.0   \n",
       "fp2                            0.0             0.0             0.0   \n",
       "fn2                            7.0             7.0             7.0   \n",
       "\n",
       "                           value17         value18  \n",
       "parameter                                           \n",
       "boosting_type                 gbdt            gbdt  \n",
       "class_weight                  None            None  \n",
       "colsample_bytree          0.167789             1.0  \n",
       "importance_type              split           split  \n",
       "learning_rate             0.001916        0.003306  \n",
       "max_depth                       23               1  \n",
       "min_child_samples               32              27  \n",
       "min_child_weight                 8               5  \n",
       "min_split_gain                 0.0             0.0  \n",
       "n_estimators                  2643            2150  \n",
       "n_jobs                          -1              -1  \n",
       "num_leaves                      10              10  \n",
       "objective                   binary          binary  \n",
       "random_state                  None            None  \n",
       "reg_alpha                      0.9             1.9  \n",
       "reg_lambda                     1.8             1.9  \n",
       "silent                        warn            warn  \n",
       "subsample                 0.648771        0.020883  \n",
       "subsample_for_bin           949309         1000000  \n",
       "subsample_freq                   0               0  \n",
       "verbose                          0               0  \n",
       "boost_from_average            True            True  \n",
       "force_col_wise                true            true  \n",
       "max_bin                        435             861  \n",
       "metric              binary_logloss  binary_logloss  \n",
       "scale_pos_weight               0.6            0.45  \n",
       "cv                               3               3  \n",
       "scoring                  precision       precision  \n",
       "num_col                         98              89  \n",
       "iterations                      30              30  \n",
       "best_score                0.790385        0.895833  \n",
       "best_index                     5.0            19.0  \n",
       "acc_train                 0.807292        0.739583  \n",
       "acc_val                   0.520833          0.5625  \n",
       "acc_test                  0.666667        0.616667  \n",
       "precision                      0.8             0.8  \n",
       "recall                    0.307692        0.153846  \n",
       "f1score                   0.444444        0.258065  \n",
       "roc                       0.624434        0.562217  \n",
       "tn                            32.0            33.0  \n",
       "fp                             2.0             1.0  \n",
       "fn                            18.0            22.0  \n",
       "tp                             8.0             4.0  \n",
       "acc_test1                      0.7            0.55  \n",
       "precision1                     1.0             1.0  \n",
       "recall1                        0.4             0.1  \n",
       "f1score1                  0.571429        0.181818  \n",
       "roc1                           0.7            0.55  \n",
       "tn1                           10.0            10.0  \n",
       "fp1                            0.0             0.0  \n",
       "fn1                            6.0             9.0  \n",
       "tp1                            4.0             1.0  \n",
       "acc_test2                     0.65            0.65  \n",
       "precision2                     1.0             1.0  \n",
       "recall2                   0.222222        0.222222  \n",
       "f1score2                  0.363636        0.363636  \n",
       "roc2                      0.611111        0.611111  \n",
       "tn2                           11.0            11.0  \n",
       "fp2                            0.0             0.0  \n",
       "fn2                            7.0             7.0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.iloc[:-6, 10:].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 가장 좋은 결과 저장\n",
    "save_best_results(com_name, lgbmBS.best_estimator_, scaler, new_col, df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lgbmBS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmBS.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spsy_cr</th>\n",
       "      <td>10.022542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigner_1</th>\n",
       "      <td>9.781338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_2</th>\n",
       "      <td>9.357003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixtr_cr</th>\n",
       "      <td>9.007152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkx_cr_2</th>\n",
       "      <td>8.102719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr</th>\n",
       "      <td>7.463862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr_2</th>\n",
       "      <td>7.370149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporateetc_1</th>\n",
       "      <td>6.975944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail_1</th>\n",
       "      <td>5.555070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox_cr_2</th>\n",
       "      <td>5.163250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>krw_cr</th>\n",
       "      <td>4.987054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixut_cr_2</th>\n",
       "      <td>4.932270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_1</th>\n",
       "      <td>4.469649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spny_cr_2</th>\n",
       "      <td>3.712691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close_1</th>\n",
       "      <td>3.108679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr_2</th>\n",
       "      <td>2.843178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcd_cr</th>\n",
       "      <td>2.738917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_2</th>\n",
       "      <td>2.648484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_2</th>\n",
       "      <td>2.487644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spsy_cr_2</th>\n",
       "      <td>2.404461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_1</th>\n",
       "      <td>2.091509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_2_cr_2</th>\n",
       "      <td>1.751169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_2_cr_2</th>\n",
       "      <td>1.684897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bkx_cr</th>\n",
       "      <td>1.441398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcu_cr</th>\n",
       "      <td>1.399152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcm_cr_2</th>\n",
       "      <td>1.112740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr_2</th>\n",
       "      <td>1.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr</th>\n",
       "      <td>0.698563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr</th>\n",
       "      <td>0.540824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcs_cr_2</th>\n",
       "      <td>0.360032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_1</th>\n",
       "      <td>0.095266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcs_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spny_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrci_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "spsy_cr            10.022542\n",
       "foreigner_1         9.781338\n",
       "open_2              9.357003\n",
       "ixtr_cr             9.007152\n",
       "bkx_cr_2            8.102719\n",
       "kosdaq_cr           7.463862\n",
       "kosdaq_cr_2         7.370149\n",
       "corporateetc_1      6.975944\n",
       "retail_1            5.555070\n",
       "sox_cr_2            5.163250\n",
       "krw_cr              4.987054\n",
       "ixut_cr_2           4.932270\n",
       "open_1              4.469649\n",
       "spny_cr_2           3.712691\n",
       "close_1             3.108679\n",
       "bond_usa_3m_cr_2    2.843178\n",
       "splrcd_cr           2.738917\n",
       "low_2               2.648484\n",
       "high_2              2.487644\n",
       "spsy_cr_2           2.404461\n",
       "low_1               2.091509\n",
       "bond_kor_2_cr_2     1.751169\n",
       "bond_usa_2_cr_2     1.684897\n",
       "bkx_cr              1.441398\n",
       "splrcu_cr           1.399152\n",
       "splrcm_cr_2         1.112740\n",
       "dji_cr_2            1.099020\n",
       "dji_cr              0.698563\n",
       "bond_usa_3m_cr      0.540824\n",
       "splrcs_cr_2         0.360032\n",
       "high_1              0.095266\n",
       "splrcs_cr           0.000000\n",
       "spny_cr             0.000000\n",
       "splrci_cr_2         0.000000\n",
       "vol_1               0.000000\n",
       "kospi_cr            0.000000\n",
       "vix_cr_2            0.000000\n",
       "privequity_1        0.000000\n",
       "institution_1       0.000000\n",
       "weekday             0.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:84]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = column_o.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'cv' : 5,\n",
    "#     'cv' : None,\n",
    "#     'scoring' : None,\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 10,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_base = {'boosting_type' : ['gbdt'], # ['gbdt', dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "              'num_leaves' :  [3, 4, 5,], # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "              'learning_rate' :  [0.0003, 0.0005, 0.001, 0.0015,],\n",
    "#               'max_delta_step' :  [0.4, 0.5, 0.6],\n",
    "              'n_estimators' :  [ 1100, 1200, 1300, 1400, ],\n",
    "              'colsample_bytree' :  [0.3, 0.4, 0.5,], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "              'subsample' : [0.3, 0.4, ], #  [0.1, 0.2, 0.3, 0.4], # 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "              'max_depth' :  [-1], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "              'objective': ['binary'],\n",
    "              'metric': ['binary_logloss'],\n",
    "              'scale_pos_weight': [1.0, 1.5,], # posiive  증가, class imbalance 경감, scale_pos_weight > 0.0, default=1.0. \n",
    "#               'min_child_samples' : [30],\n",
    "#               'lambda_l1': [0, 5], # default 0\n",
    "#               'lambda_l2': [0, 5], #default 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = param_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(com_name):\n",
    "    os.makedirs(com_name)\n",
    "    \n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmgs = None\n",
    "    gsbs = 'gs'\n",
    "\n",
    "    lgbm = lightgbm.LGBMClassifier(random_state=42)\n",
    "\n",
    "    lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                          param_grid = params_o,\n",
    "#                           cv = 10, # StratifiedKFold us default for binary or multiclass\n",
    "#                           scoring = 'precision', \n",
    "#                           scoring = 'accuracy', \n",
    "#                           scoring = ['accuracy', 'precision'], # refit 사용해야 함. 고로 사용하지 않음.\n",
    "                          cv = param_grid['cv'],\n",
    "                          scoring = param_grid['scoring'],\n",
    "                          error_score='raise',\n",
    "                          verbose = 1,\n",
    "                          n_jobs=-1, # 자동 검색 적용\n",
    "                         )\n",
    "                          \n",
    "    print(\"*** after lgbmgs ******\")\n",
    "    lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "#     lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss', eval_set = (val_scaled, val_target)) \n",
    "    # eval_set가 있어야 \"early_stopping_rounds\"를 사용할 수 있음.\n",
    "\n",
    "# save model\n",
    "    stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "    dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "    dt = f'{dt[:4]}_{dt[4:]}'\n",
    "#     joblib.dump(lgbmBS, f'./{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\n",
    "    save_to_pickle(f'./{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl', lgbmBS)\n",
    "#     joblib.dump(scaler, f'./{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\n",
    "    save_to_pickle(f'./{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl', scaler)\n",
    "    \n",
    "    df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmgs, lgbmgs.best_estimator_, \n",
    "                               train_scaled, val_scaled, test_scaled,  \n",
    "                               train_target, val_target, test_target,\n",
    "                               test_scaled1, test_scaled2, test_scaled3,  \n",
    "                               test_target1, test_target2, test_target3\n",
    "                              )\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_grid = make_df_from_estimator(param_grid, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_grid, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1score = df_concat.loc['f1score'].iloc[0]\n",
    "    \n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1score >= 0.6) :\n",
    "        df_base.to_csv(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.pkl')\n",
    "#         params_o = make_new_parameter(params_o, df_concat)\n",
    "        save_parameters(iter, com_name, dt, precision, gsbs, params_space, new_col)\n",
    "        break\n",
    "    if iter >= 1 : \n",
    "        df_base.to_csv(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_{gsbs}_df_{dt}_{round(precision*100):2d}%_ver{iter}.pkl')\n",
    "#         params_o = make_new_parameter(params_o, df_concat)\n",
    "        save_parameters(iter, com_name, dt, precision, gsbs, params_space, new_col)\n",
    "        break\n",
    "    print(\"******* No.{}  Process is Done! ********\".format(iter))\n",
    "#     params_o = make_new_parameter(params_o, df_concat)\n",
    "    save_parameters(iter, com_name, dt, precision, gsbs, params_space, new_col)\n",
    "    \n",
    "print(\"**** End of GridSearCV Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lgbmgs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmgs.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.tail(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:35]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
