{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "    df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) \n",
    "    \n",
    "# def load_dict_from_csv(path):\n",
    "#     df = pd.read_csv(path, header=None)\n",
    "#     my_dict = df.to_dict()\n",
    "#     return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target,\n",
    "                 test_scaled1, test_scaled2, test_scaled3, test_target1, test_target2, test_target3):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "#     result_dict['best_score'] = lgbmgs.best_score_ \n",
    "#     result_dict['best_index'] = lgbmgs.best_index_\n",
    "    result_dict['best_score'] = lgbmBS.best_score_ \n",
    "    result_dict['best_index'] = lgbmBS.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled1)\n",
    "    result_dict['acc_test1'] = model.score(test_scaled1, test_target1)\n",
    "    result_dict['precision1'] = precision_score(test_target1, y_predict)\n",
    "    result_dict['recall1'] = recall_score(test_target1, y_predict)\n",
    "    result_dict['f1score1'] = f1_score(test_target1, y_predict)\n",
    "    result_dict['roc1'] = roc_auc_score(test_target1, y_predict)\n",
    "    cm = confusion_matrix(test_target1, y_predict)\n",
    "    result_dict['tn1'] = cm[0,0]\n",
    "    result_dict['fp1'] = cm[0,1]\n",
    "    result_dict['fn1'] = cm[1,0]\n",
    "    result_dict['tp1'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled2)\n",
    "    result_dict['acc_test2'] = model.score(test_scaled2, test_target2)\n",
    "    result_dict['precision2'] = precision_score(test_target2, y_predict)\n",
    "    result_dict['recall2'] = recall_score(test_target2, y_predict)\n",
    "    result_dict['f1score2'] = f1_score(test_target2, y_predict)\n",
    "    result_dict['roc2'] = roc_auc_score(test_target2, y_predict)\n",
    "    cm = confusion_matrix(test_target2, y_predict)\n",
    "    result_dict['tn2'] = cm[0,0]\n",
    "    result_dict['fp2'] = cm[0,1]\n",
    "    result_dict['fn2'] = cm[1,0]\n",
    "    result_dict['tp2'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled3)\n",
    "    result_dict['acc_test3'] = model.score(test_scaled3, test_target3)\n",
    "    result_dict['precision3'] = precision_score(test_target3, y_predict)\n",
    "    result_dict['recall3'] = recall_score(test_target3, y_predict)\n",
    "    result_dict['f1score3'] = f1_score(test_target3, y_predict)\n",
    "    result_dict['roc3'] = roc_auc_score(test_target3, y_predict)\n",
    "    cm = confusion_matrix(test_target3, y_predict)\n",
    "    result_dict['tn3'] = cm[0,0]\n",
    "    result_dict['fp3'] = cm[0,1]\n",
    "    result_dict['fn3'] = cm[1,0]\n",
    "    result_dict['tp3'] = cm[1,1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters and columns used for the analysis\n",
    "def save_parameters(iter, com_name, dt, precision, params_o, new_col):\n",
    "    save_to_pickle(f'./{com_name}/params_{dt}_{round(precision*100):2d}%_ver{iter}.pkl', params_o)\n",
    "    save_dict_to_csv(f'./{com_name}/params_{dt}_{round(precision*100):2d}%_ver{iter}.csv', params_o)\n",
    "    save_to_pickle(f'./{com_name}/columns_{dt}_{len(new_col)}_{round(precision*100):2d}%_ver{iter}.pkl', new_col)\n",
    "    save_list_to_csv(f'./{com_name}/columns_{dt}_{len(new_col)}_{round(precision*100):2d}%_ver{iter}.csv', new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng'], '030200' : ['KT', 'kt']}\n",
    "\n",
    "code = {'005490' : ['POSCO홀딩스', 'poscoholding']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "#             'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', \n",
    "            'privequity_1',  'insurance_1', 'corporateetc_1', # bank_1, 'financeetc_1 제외\n",
    "            'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "#             'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', \n",
    "            'privequity_2', 'insurance_2', 'corporateetc_2', # bank_2, 'financeetc_2 제외\n",
    "            'foreigneretc_2']\n",
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']\n",
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']\n",
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]\n",
    "new_col = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr\n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = list(code.values())[0][1]\n",
    "\n",
    "directory_for_ml = '../data/data_for_ml/expand_date/'\n",
    "fname = f'df_{com_name}_sel.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df_o = pd.read_pickle(f_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_base = {'boosting_type' : ['gbdt'], # ['gbdt', dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "              'num_leaves' :  [3, 4, 5, 6,], # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "              'learning_rate' :  [0.001, 0.0015, 0.0017, 0.002,],\n",
    "#               'max_delta_step' :  [0.4, 0.5, 0.6],\n",
    "              'n_estimators' :  [ 1000, 1100, 1200, 1300, 1400],\n",
    "              'colsample_bytree' :  [0.5, 0.6, 0.7, 0.8], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "              'subsample' : [0.1, 0.2, 0.3,], #  [0.1, 0.2, 0.3, 0.4], # 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "              'max_depth' :  [-1], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "              'objective': ['binary'],\n",
    "              'metric': ['binary_logloss'],\n",
    "              'scale_pos_weight': [1.0,], # posiive  증가, class imbalance 경감, scale_pos_weight > 0.0, default=1.0. \n",
    "#               'min_child_samples' : [15], # default: 20, 숫자가 작으면 accuracy가 올라감\n",
    "              'subsample_for_bin' : [250000, 300000], # default: 200000, \n",
    "#               'reg_alpha' : [0, 0.5, 1], # =='lambda_l1': [0, 5], # default 0\n",
    "#               'reg_lambda' : [0, 0.5, 1], # == lambda_l2': [0, 5], #default 0\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'learning_rate': (0.0005, 0.003, 'log-uniform'),\n",
    "    'num_leaves': (3, 10),      \n",
    "    'max_depth': (0, 50), #[-1], #(0, 50),\n",
    "    'min_child_samples': (10, 40),\n",
    "#     'max_bin': (100, 1000),\n",
    "    'subsample': (0.01, 1.0, 'uniform'),\n",
    "#     'subsample_freq': (0, 10),\n",
    "    'colsample_bytree': (0.1, 1.0, 'uniform'),\n",
    "#     'min_child_weight': (0, 10),\n",
    "    'subsample_for_bin': (100000, 500000),\n",
    "#     'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "#     'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "#     'scale_pos_weight': (1e-2, 2, 'log-uniform'),\n",
    "#     'scale_pos_weight': np.arange(0,2,0.01) ,\n",
    "    'n_estimators': (800, 1500),\n",
    "    'reg_alpha' : (0, 4, 'uniform'), # =='lambda_l1': [0, 5], # default 0\n",
    "    'reg_lambda' : (0, 4, 'uniform'), # == lambda_l2': [0, 5], #default 0\n",
    "    'force_col_wise': ['true'], \n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayecSearchCV\n",
    "#### XGBoost + BayesSearchCV (Search Hyperparameters!),  XGBoost and scikit-optimize: BayesSearchCV and XGBRegressor are incompatible - why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "#     'cv' : 7,\n",
    "    'cv' : None,\n",
    "#     'scoring' : None,\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 20,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = param_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbmgs ******\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] Number of positive: 66, number of negative: 87\n",
      "[LightGBM] [Info] Total Bins 5391\n",
      "[LightGBM] [Info] Number of data points in the train set: 153, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.431373 -> initscore=-0.276253\n",
      "[LightGBM] [Info] Start training from score -0.276253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "**** End of Process ****\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(com_name):\n",
    "    os.makedirs(com_name)\n",
    "    \n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmgs = None\n",
    "    lgbmBS = None\n",
    "\n",
    "    lgbm = lightgbm.LGBMClassifier(random_state=42)\n",
    "\n",
    "    lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                          param_grid = params_o,\n",
    "#                           cv = 10, # StratifiedKFold us default for binary or multiclass\n",
    "#                           scoring = 'precision', \n",
    "#                           scoring = 'accuracy', \n",
    "#                           scoring = ['accuracy', 'precision'], # refit 사용해야 함. 고로 사용하지 않음.\n",
    "                          cv = param_grid['cv'],\n",
    "                          scoring = param_grid['scoring'],\n",
    "                          error_score='raise',\n",
    "                          verbose = 1,\n",
    "                          n_jobs=-1, # 자동 검색 적용\n",
    "                         )\n",
    "    \n",
    "    lgbmBS = BayesSearchCV( estimator = lightgbm.LGBMClassifier( objective='binary',\n",
    "                                                                 metric='precision',\n",
    "                                                                 n_jobs=-1,\n",
    "                                                                 verbose=1 ),\n",
    "                           search_spaces = search_space,\n",
    "                           scoring = param_grid['scoring'],\n",
    "                           cv = param_grid['cv'],\n",
    "#                            cv = StratifiedKFold( n_splits=param_grid['cv'],\n",
    "#                                                  shuffle=True,\n",
    "#                                                  random_state=42 ),\n",
    "                           n_jobs = -1, # 자동 검색 적용\n",
    "                           n_iter = param_grid['iterations'],   \n",
    "                           verbose = 1, refit = True, random_state = 42 \n",
    "                          )\n",
    "                          \n",
    "    print(\"*** after lgbmgs ******\")\n",
    "#     lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "    lgbmBS.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "#     lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss', eval_set = (val_scaled, val_target)) \n",
    "    # eval_set가 있어야 \"early_stopping_rounds\"를 사용할 수 있음.\n",
    "\n",
    "# save model\n",
    "    stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "    dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "    dt = f'{dt[:4]}_{dt[4:]}'\n",
    "#     joblib.dump(lgbmgs, f'./{com_name}/lgbm_{dt}_v{iter}.pkl') # gridsearchcv 저장\n",
    "    joblib.dump(lgbmBS, f'./{com_name}/lgbm_{dt}_v{iter}.pkl') # gridsearchcv 저장\n",
    "    joblib.dump(scaler, f'./{com_name}/scaler_{dt}_v{iter}.pkl') # scaler 저장\n",
    "    \n",
    "#     df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "#     result_dict = calc_results(lgbmgs.best_estimator_, \n",
    "#                                train_scaled, val_scaled, test_scaled,  \n",
    "#                                train_target, val_target, test_target,\n",
    "#                                test_scaled1, test_scaled2, test_scaled3,  \n",
    "#                                test_target1, test_target2, test_target3\n",
    "#                               )\n",
    "    \n",
    "    df_estimator = make_df_from_estimator(lgbmBS.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmBS.best_estimator_, \n",
    "                               train_scaled, val_scaled, test_scaled,  \n",
    "                               train_target, val_target, test_target,\n",
    "                               test_scaled1, test_scaled2, test_scaled3,  \n",
    "                               test_target1, test_target2, test_target3\n",
    "                              )\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_grid = make_df_from_estimator(param_grid, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_grid, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1score = df_concat.loc['f1score'].iloc[0]\n",
    "    \n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1score >= 0.6) :\n",
    "        df_base.to_csv(f'./{com_name}/lgbm_df_{dt}_{round(precision*100):2d}%_ver{iter}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_df_{dt}_{round(precision*100):2d}%_ver{iter}.pkl')\n",
    "#         params_o = make_new_parameter(params_o, df_concat)\n",
    "        save_parameters(iter, com_name, dt, precision, params_o, new_col)\n",
    "        break\n",
    "    if iter >= 1 : \n",
    "        df_base.to_csv(f'./{com_name}/lgbm_df_{dt}_{round(precision*100):2d}%_ver{iter}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_df_{dt}_{round(precision*100):2d}%_ver{iter}.pkl')\n",
    "#         params_o = make_new_parameter(params_o, df_concat)\n",
    "        save_parameters(iter, com_name, dt, precision, params_o, new_col)\n",
    "        break\n",
    "    print(\"******* No.{}  Process is Done! ********\".format(iter))\n",
    "#     params_o = make_new_parameter(params_o, df_concat)\n",
    "    save_parameters(iter, com_name, dt, precision, params_o, new_col)\n",
    "    \n",
    "print(\"**** End of Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value8</th>\n",
       "      <th>value9</th>\n",
       "      <th>value14</th>\n",
       "      <th>value15</th>\n",
       "      <th>value16</th>\n",
       "      <th>value19</th>\n",
       "      <th>value21</th>\n",
       "      <th>value22</th>\n",
       "      <th>value23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test2</th>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test3</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>0.973856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.615671</td>\n",
       "      <td>0.615671</td>\n",
       "      <td>0.625268</td>\n",
       "      <td>0.625268</td>\n",
       "      <td>0.625268</td>\n",
       "      <td>0.654848</td>\n",
       "      <td>0.654848</td>\n",
       "      <td>0.652035</td>\n",
       "      <td>0.554444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.730559</td>\n",
       "      <td>0.730559</td>\n",
       "      <td>0.754953</td>\n",
       "      <td>0.754953</td>\n",
       "      <td>0.754953</td>\n",
       "      <td>0.730559</td>\n",
       "      <td>0.730559</td>\n",
       "      <td>0.237277</td>\n",
       "      <td>0.894984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score1</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score3</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>1059</td>\n",
       "      <td>1059</td>\n",
       "      <td>1318</td>\n",
       "      <td>1318</td>\n",
       "      <td>1318</td>\n",
       "      <td>1059</td>\n",
       "      <td>1059</td>\n",
       "      <td>1500</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision1</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value8          value9         value14  \\\n",
       "parameter                                                           \n",
       "acc_test                 0.591837        0.591837        0.591837   \n",
       "acc_test1                     0.5             0.5          0.5625   \n",
       "acc_test2                  0.5625          0.5625          0.4375   \n",
       "acc_test3                0.705882        0.705882        0.764706   \n",
       "acc_train                0.980392        0.980392        0.954248   \n",
       "acc_val                  0.487179        0.487179        0.487179   \n",
       "best_index                    8.0             8.0             0.0   \n",
       "best_score               0.615671        0.615671        0.625268   \n",
       "boosting_type                gbdt            gbdt            gbdt   \n",
       "class_weight                 None            None            None   \n",
       "colsample_bytree         0.730559        0.730559        0.754953   \n",
       "cv                           None            None            None   \n",
       "f1score                  0.444444        0.444444        0.444444   \n",
       "f1score1                 0.555556        0.555556        0.588235   \n",
       "f1score2                 0.222222        0.222222        0.181818   \n",
       "f1score3                 0.444444        0.444444             0.5   \n",
       "fn                           14.0            14.0            14.0   \n",
       "fn1                           5.0             5.0             5.0   \n",
       "fn2                           6.0             6.0             6.0   \n",
       "fn3                           3.0             3.0             3.0   \n",
       "force_col_wise               true            true            true   \n",
       "fp                            6.0             6.0             6.0   \n",
       "fp1                           3.0             3.0             2.0   \n",
       "fp2                           1.0             1.0             3.0   \n",
       "fp3                           2.0             2.0             1.0   \n",
       "importance_type             split           split           split   \n",
       "iterations                     10              10              10   \n",
       "learning_rate            0.001053        0.001053         0.00088   \n",
       "max_depth                      19              19              34   \n",
       "metric             binary_logloss  binary_logloss  binary_logloss   \n",
       "min_child_samples              15              15              20   \n",
       "min_child_weight            0.001           0.001           0.001   \n",
       "min_split_gain                0.0             0.0             0.0   \n",
       "n_estimators                 1059            1059            1318   \n",
       "n_jobs                         -1              -1              -1   \n",
       "num_col                       110              80              80   \n",
       "num_leaves                      7               7               5   \n",
       "objective                  binary          binary          binary   \n",
       "precision                0.571429        0.571429        0.571429   \n",
       "precision1                  0.625           0.625        0.714286   \n",
       "\n",
       "                          value15         value16         value19  \\\n",
       "parameter                                                           \n",
       "acc_test                 0.591837        0.591837        0.612245   \n",
       "acc_test1                  0.5625          0.5625          0.4375   \n",
       "acc_test2                  0.4375          0.4375           0.625   \n",
       "acc_test3                0.764706        0.764706        0.764706   \n",
       "acc_train                0.954248        0.954248        0.973856   \n",
       "acc_val                  0.487179        0.487179        0.487179   \n",
       "best_index                    0.0             0.0             8.0   \n",
       "best_score               0.625268        0.625268        0.654848   \n",
       "boosting_type                gbdt            gbdt            gbdt   \n",
       "class_weight                 None            None            None   \n",
       "colsample_bytree         0.754953        0.754953        0.730559   \n",
       "cv                           None            None            None   \n",
       "f1score                  0.444444        0.444444        0.457143   \n",
       "f1score1                 0.588235        0.588235        0.470588   \n",
       "f1score2                 0.181818        0.181818             0.4   \n",
       "f1score3                      0.5             0.5             0.5   \n",
       "fn                           14.0            14.0            14.0   \n",
       "fn1                           5.0             5.0             6.0   \n",
       "fn2                           6.0             6.0             5.0   \n",
       "fn3                           3.0             3.0             3.0   \n",
       "force_col_wise               true            true            true   \n",
       "fp                            6.0             6.0             5.0   \n",
       "fp1                           2.0             2.0             3.0   \n",
       "fp2                           3.0             3.0             1.0   \n",
       "fp3                           1.0             1.0             1.0   \n",
       "importance_type             split           split           split   \n",
       "iterations                     10              20              20   \n",
       "learning_rate             0.00088         0.00088        0.001053   \n",
       "max_depth                      34              34              19   \n",
       "metric             binary_logloss  binary_logloss  binary_logloss   \n",
       "min_child_samples              20              20              10   \n",
       "min_child_weight            0.001           0.001           0.001   \n",
       "min_split_gain                0.0             0.0             0.0   \n",
       "n_estimators                 1318            1318            1059   \n",
       "n_jobs                         -1              -1              -1   \n",
       "num_col                        80              80              80   \n",
       "num_leaves                      5               5               7   \n",
       "objective                  binary          binary          binary   \n",
       "precision                0.571429        0.571429        0.615385   \n",
       "precision1               0.714286        0.714286        0.571429   \n",
       "\n",
       "                          value21         value22         value23  \n",
       "parameter                                                          \n",
       "acc_test                 0.612245        0.632653        0.612245  \n",
       "acc_test1                  0.4375           0.625          0.4375  \n",
       "acc_test2                   0.625             0.5             0.5  \n",
       "acc_test3                0.764706        0.764706        0.882353  \n",
       "acc_train                0.973856             1.0        0.915033  \n",
       "acc_val                  0.487179        0.487179        0.461538  \n",
       "best_index                    8.0            19.0             1.0  \n",
       "best_score               0.654848        0.652035        0.554444  \n",
       "boosting_type                gbdt            gbdt            gbdt  \n",
       "class_weight                 None            None            None  \n",
       "colsample_bytree         0.730559        0.237277        0.894984  \n",
       "cv                           None            None            None  \n",
       "f1score                  0.457143        0.526316        0.486486  \n",
       "f1score1                 0.470588        0.666667        0.470588  \n",
       "f1score2                      0.4        0.333333             0.2  \n",
       "f1score3                      0.5             0.5             0.8  \n",
       "fn                           14.0            12.0            13.0  \n",
       "fn1                           6.0             4.0             6.0  \n",
       "fn2                           5.0             5.0             6.0  \n",
       "fn3                           3.0             3.0             1.0  \n",
       "force_col_wise               true            true            true  \n",
       "fp                            5.0             6.0             6.0  \n",
       "fp1                           3.0             2.0             3.0  \n",
       "fp2                           1.0             3.0             2.0  \n",
       "fp3                           1.0             1.0             1.0  \n",
       "importance_type             split           split           split  \n",
       "iterations                     20              20              20  \n",
       "learning_rate            0.001053           0.003        0.002749  \n",
       "max_depth                      19              50              43  \n",
       "metric             binary_logloss  binary_logloss  binary_logloss  \n",
       "min_child_samples              10              10              14  \n",
       "min_child_weight            0.001           0.001           0.001  \n",
       "min_split_gain                0.0             0.0             0.0  \n",
       "n_estimators                 1059            1500            1048  \n",
       "n_jobs                         -1              -1              -1  \n",
       "num_col                        80              80             110  \n",
       "num_leaves                      7              10               7  \n",
       "objective                  binary          binary          binary  \n",
       "precision                0.615385           0.625             0.6  \n",
       "precision1               0.571429            0.75        0.571429  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.iloc[:40, 5:].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(colsample_bytree=0.7549531688595925, force_col_wise='true',\n",
      "               learning_rate=0.0008804604510248291, max_depth=34,\n",
      "               metric='binary_logloss', n_estimators=1318, num_leaves=5,\n",
      "               objective='binary', subsample=0.5544643023916863,\n",
      "               subsample_for_bin=150734, verbose=1)\n"
     ]
    }
   ],
   "source": [
    "# print(lgbmgs.best_estimator_)\n",
    "print(lgbmBS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgbmgs.best_estimator_\n",
    "model = lgbmBS.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sox_cr</th>\n",
       "      <td>0.220104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigneretc_1</th>\n",
       "      <td>0.158411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spxhc_cr</th>\n",
       "      <td>0.126197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrct_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixk_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcl_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_10_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrci_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spxhc_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcd_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrci_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splrcl_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixtr_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixut_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbi_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigner_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_cr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_f_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_2_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_2_cr_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  importance\n",
       "sox_cr              0.220104\n",
       "foreigneretc_1      0.158411\n",
       "spxhc_cr            0.126197\n",
       "splrct_cr_2         0.000000\n",
       "vol_2               0.000000\n",
       "institution_1       0.000000\n",
       "insurance_1         0.000000\n",
       "ixk_cr_2            0.000000\n",
       "splrcl_cr_2         0.000000\n",
       "bond_kor_10_cr_2    0.000000\n",
       "splrci_cr_2         0.000000\n",
       "spxhc_cr_2          0.000000\n",
       "splrcd_cr           0.000000\n",
       "splrci_cr           0.000000\n",
       "splrcl_cr           0.000000\n",
       "bond_usa_3m_cr      0.000000\n",
       "ixtr_cr             0.000000\n",
       "ixut_cr             0.000000\n",
       "nbi_cr              0.000000\n",
       "high_1              0.000000\n",
       "close_1             0.000000\n",
       "foreigner_1         0.000000\n",
       "spx_cr              0.000000\n",
       "privequity_2        0.000000\n",
       "insurance_2         0.000000\n",
       "ixic_f_cr_2         0.000000\n",
       "bond_kor_2_cr_2     0.000000\n",
       "kospi_cr_2          0.000000\n",
       "bond_usa_2_cr_2     0.000000\n",
       "weekday             0.000000"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:75]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_o[new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용된 column을 불러와서 신규column 지정하여 최적의 column 찾기에 사용\n",
    "directory_for_ml = '../machine_learning/sec/'\n",
    "fname = f'columns_ver1_0323_1535_72_0.74%.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "new_col = load_from_pickle(f_name)\n",
    "new_col =  new_col[:61]+new_col[-5:] # 원하는 column 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망\n",
    "##### 사용하지 않음. lighgbm으로 충분함. 추후 필요시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(inp_num, a_layer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='sigmoid', input_shape=(inp_num,)))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(36, activation='sigmoid'))\n",
    "#     model.add(Dense(24, activation='sigmoid'))\n",
    "    model.add(Dense(15, activation='sigmoid'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    model.add(Dropout(0.3))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_fn(10, len(data_new.columns), 2, Dropout(0.3))\n",
    "try :\n",
    "    del model\n",
    "    print(\"delete del\")\n",
    "except:\n",
    "    pass\n",
    "model = model_fn(len(data.columns))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath='best_model_{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5', \\\n",
    "#                                                 monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=f'./{com_name}/best_model_deep/best_model.h5', save_best_only=True)\n",
    "# earlystopping_cb = keras.callbacks.EarlyStopping(patience=100, monitor='val_accuracy', mode='max', restore_best_weights=True)\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=200, monitor='val_loss', mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_scaled, train_target, epochs=2000, verbose=0,\n",
    "                    callbacks=[earlystopping_cb],\n",
    "#                     callbacks=[checkpoint_cb, earlystopping_cb],\n",
    "                    validation_data=(val_scaled, val_target))\n",
    "# batch_size="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "# plt.title(plt_title+plt_title2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "# plt.title(plt_title+plt_title2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature columns\n",
    "directory = f'./{com_name}/best_model_deep/'\n",
    "save_to_pickle(directory+f'data_columns_{com_name}.pkl', data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_cb.stopped_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_scaled, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_val = load_model('best_model.h5')\n",
    "model_val.evaluate(test_scaled, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(np.array(test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_list = [1 if i > 0.5 else 0 for i in y_predict[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = [ [x, y] for x, y in zip(test_target, y_predict)]\n",
    "# compare = [ [x, y] for x, y in zip(test_target, y_predict_list)]\n",
    "compare # 실제값. 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "# 정밀도 : 양성으로 예측된 것(TP+FP) 중 얼마나 많은 샘플이 진짜 양성(TP)인지 측정\n",
    "precision_score(test_target, y_predict_list)  # 정밀도, 입력값의 순서 중요힘. (실제값, 예측값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현율 : 전체 양성 샘플(TP+FN) 중에서 얼마나 많은 샘플이 진짜 양성(TP)인지 측정\n",
    "recall_score(test_target, y_predict_list)  # 재현율, 입력값의 순서 중요힘. (실제값, 예측값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_target, y_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_target, y_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(test_target, y_predict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 정밀도, f1-score, \n",
    "2. confusion matrix ((1,1), (2,2), 두개가 큰 비중이면 good, (1,2)은 틀린것을 맞다라고 구분, (2,1)은 맞는 것을 틀린 것이다 라고 결정하는 항목) 따라서\n",
    "    (2,2) -> (1,2) -> (1,1)로 확인하고. <br>\n",
    "    (1,2)가 크면 모델 제외 (정밀도(precision = TP / (TP + FP) )가 높아야 함. 낮으면 손해를 보게 됨.), <br>\n",
    "    재현율(Recall = TP / (TP + FN) ) 은 손해를 끼치지는 않음.\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/fasthill/My-gist/main/data/picture/confusion_matrix.png\" width=\"800\"/> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_for_ml = '../data/data_for_ml/expand_date/'\n",
    "ss = pd.read_csv(directory_for_ml+'df_sec_sel.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
