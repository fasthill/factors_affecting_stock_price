{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM\n",
    "\n",
    "### train, val, test data로 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    fields=my_dict.keys()\n",
    "    values = my_dict.values()\n",
    "    pd.DataFrame([fields, values], index=['parameter','value']).T.to_csv(path)\n",
    "#     df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "#     df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) \n",
    "    \n",
    "# def load_dict_from_csv(path):\n",
    "#     df = pd.read_csv(path, header=None)\n",
    "#     my_dict = df.to_dict()\n",
    "#     return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'iter_{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(lgbm, model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict_train = model.predict(train_scaled)\n",
    "    y_predict_val = model.predict(val_scaled)\n",
    "    y_predict_test = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbm.best_score_ \n",
    "    result_dict['best_index'] = lgbm.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['train_precision'] = precision_score(train_target, y_predict_train)\n",
    "    cm = confusion_matrix(train_target, y_predict_train)\n",
    "    result_dict['train_tn'] = cm[0,0]\n",
    "    result_dict['train_fp'] = cm[0,1]\n",
    "    result_dict['train_fn'] = cm[1,0]\n",
    "    result_dict['train_tp'] = cm[1,1]\n",
    "    result_dict['val_precision'] = precision_score(val_target, y_predict_val)\n",
    "    cm = confusion_matrix(val_target, y_predict_val)\n",
    "    result_dict['val_tn'] = cm[0,0]\n",
    "    result_dict['val_fp'] = cm[0,1]\n",
    "    result_dict['val_fn'] = cm[1,0]\n",
    "    result_dict['val_tp'] = cm[1,1]\n",
    "    result_dict['test_precision'] = precision_score(test_target, y_predict_test)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict_test)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict_test)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict_test)\n",
    "    cm = confusion_matrix(test_target, y_predict_test)\n",
    "    result_dict['test_tn'] = cm[0,0]\n",
    "    result_dict['test_fp'] = cm[0,1]\n",
    "    result_dict['test_fn'] = cm[1,0]\n",
    "    result_dict['test_tp'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_results(com_name, model, scaler, columns, df_base):\n",
    "    joblib.dump(model, f'{directory_for_model}{com_name}/best_model.pkl') # estimaor 저장\n",
    "    joblib.dump(scaler, f'{directory_for_model}{com_name}/best_scaler.pkl') # scaler 저장\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_model_p.pkl', model)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_scaler_p.pkl', scaler)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_columns.pkl', new_col)\n",
    "    save_list_to_csv(f'{directory_for_model}{com_name}/best_columns.csv', new_col)\n",
    "    df_base.to_pickle(f'{directory_for_model}{com_name}/best_result.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(*dicts):\n",
    "    dsum = {}\n",
    "    d_k = []\n",
    "    d_v = []\n",
    "    for dic in dicts:\n",
    "        d_k.extend(list(dic.keys()))  # sum keys list\n",
    "        d_v.extend(list(dic.values()))  # sum values list\n",
    "    for i in range(len(d_k)):\n",
    "        dsum[d_k[i]] = d_v[i]\n",
    "    return dsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_combine_sorted(df_base_l, df_params_l):\n",
    "    o_num = list(df_base_l.index).index('best_score')\n",
    "    df1 = df_base.iloc[:o_num, :]\n",
    "    df2 = df_base.iloc[o_num:, :]\n",
    "    df3 = pd.concat([df1, df_params_l], axis=0)\n",
    "    df3.sort_index(axis=0, inplace=True)\n",
    "    df_sorted = pd.concat([df3, df2], axis=0)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..')) # 현재 폴더로 이동\n",
    "if module_path+\"\\\\data\\\\base_data\\\\common_data\" not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\data\\\\base_data\\\\common_data\") #  공통으로 사용하는 각종 리스트, 코드 등 \n",
    "    \n",
    "import common_data as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_style(df_s, row_index_l):\n",
    "#     xin = [list(df_s.index).index(x) for x in row_index_l]\n",
    "    xin = []\n",
    "    for x in list(df_s.index):\n",
    "        try:\n",
    "            if x in row_index_l:\n",
    "                xin.append(list(df_s.index).index(x))\n",
    "        except:\n",
    "            pass\n",
    "    return df_s.reset_index('parameter').style.apply(\n",
    "        lambda x: ['background-color: yellow' if row in xin else '' for row in range(len(df_s.index))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = cd.code_all # 전체 회사 코드\n",
    "code =  {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "#             'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', \n",
    "            'privequity_1',  'insurance_1', 'corporateetc_1', # bank_1, 'financeetc_1 제외\n",
    "            'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "#             'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', \n",
    "            'privequity_2', 'insurance_2', 'corporateetc_2', # bank_2, 'financeetc_2 제외\n",
    "            'foreigneretc_2']\n",
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']\n",
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']\n",
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]\n",
    "col_futures = ['ixic_f_cr', 'ixic_f_cr_2', 'spx_f_cr', 'spx_f_cr_2', 'dji_f_cr', 'dji_f_cr_2',\n",
    "           'wti_cr','wti_cr_2', 'dxy_cr', 'dxy_cr_2', 'bond_usa_10_cr', 'bond_usa_10_cr_2' ]\n",
    "column_o = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr\n",
    "\n",
    "col_except_futures = [item for item in column_o if item not in col_futures]\n",
    "\n",
    "new_col = col_except_futures.copy()\n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   \n",
    "\n",
    "# col_futures : futures는 당일 종료가 되지 않는 data이므로 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "df_params = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = list(code.values())[0][1]\n",
    "\n",
    "directory_for_ml = '../../data/data_for_ml/predict/'\n",
    "fname = f'df_{com_name}_combine.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df_o = pd.read_pickle(f_name) \n",
    "df_o = df_o.iloc[:-1] # /predict/를 사용할 경우 마지막 prediction data 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_index = list(df_o.index).index(datetime.date(2022, 3, 2))\n",
    "train_end_index = list(df_o.index).index(datetime.date(2023, 3, 31))\n",
    "val_end_index = list(df_o.index).index(datetime.date(2023, 4, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_o_train = df_o.iloc[train_start_index:train_end_index+1]\n",
    "df_o_val = df_o.iloc[train_end_index+1:val_end_index+1]\n",
    "df_o_test = df_o.iloc[val_end_index+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o_train[new_col]\n",
    "train_input = df.iloc[:, :-5]\n",
    "train_target = df.iloc[:, -5]\n",
    "\n",
    "df = df_o_val[new_col]\n",
    "val_input = df.iloc[:, :-5]\n",
    "val_target = df.iloc[:, -5]\n",
    "\n",
    "df = df_o_test[new_col]\n",
    "test_input = df.iloc[:, :-5]\n",
    "test_target = df.iloc[:, -5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = None\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'boosting_type' : ['gbdt', 'dart', ],# ['gbdt', 'dart', 'goss'],\n",
    "    'learning_rate': (0.0001, 0.004, 'log-uniform'),\n",
    "    'num_leaves': (3, 20),      \n",
    "    'max_depth': (0, 50), #[-1], #(0, 50),\n",
    "    'min_child_samples': (5, 40),\n",
    "#     'min_child_weight': (0.001, 10.0), # 값을 변동시 같은 값이 최적값으로 선정되더라고 precision이 틀림. 반드시 값을 바꾸면서 진행해야 함.\n",
    "#     'min_split_loss': (0, 5), \n",
    "    'max_bin': (100, 1000), # 사용시 0.75%로 올라감 default: 255\n",
    "#     'max_cat_threshold' : (1, 100),\n",
    "    'subsample': (0.005, 1.0, 'uniform'), # == bagging_fraction\n",
    "#     'subsample_freq': (1, 10), # mobis에서 적용시 값이 많이 올라감. default:0\n",
    "    'colsample_bytree': (0.5, 1.0, 'uniform'),\n",
    "    'subsample_for_bin': (100000, 500000),\n",
    "    'scale_pos_weight' : (0.2, 2.0, 'uniform'),\n",
    "#     'scale_pos_weight': np.arange(0.2, 2, 0.1) ,\n",
    "    'n_estimators': (700, 5000),\n",
    "    'reg_alpha' : (0.0, 4.0, 'uniform'), # =='lambda_l1': [0, 5], # default 0\n",
    "    'reg_lambda' : (0.0, 4.0, 'uniform'), # == lambda_l2': [0, 5], #default 0    \n",
    "#     'reg_alpha' : np.arange(0, 4, 0.1),\n",
    "#     'reg_lambda' : np.arange(0, 4, 0.1),\n",
    "    'force_col_wise': ['true'], \n",
    "    'importance_type': ['split'], # ['gain'], default: split\n",
    "    'boost_from_average' : [True, False],\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "}\n",
    "\n",
    "params_space = search_space.copy() # for Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'cv' : 5,  # usually 5 or 10, default: 3\n",
    "#     'cv' : None,\n",
    "#     'scoring' : None,\n",
    "#     'scoring' : 'f1',\n",
    "#     'scoring' : 'roc_auc',\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'average_precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 50,  # default : 50, number of parameter settings.\n",
    "    # The number of parameter settings that are tried is given by n_iter.\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_for_model = '../../data/data_for_ml/model/model/0. test/'\n",
    "directory_for_model = '../../data/data_for_ml/model/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbm BS ******\n",
      "******* No.2 BS Process is Done! ********\n",
      "**** End of BayesSearchCV Process ****\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "# if not os.path.exists(com_name):\n",
    "#     os.makedirs(com_name)\n",
    "if not os.path.exists(directory_for_model+com_name):\n",
    "    os.makedirs(directory_for_model+com_name)\n",
    "\n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmBS = None\n",
    "gsbs = 'bs'\n",
    "\n",
    "lgbmBS = BayesSearchCV( estimator = lightgbm.LGBMClassifier(verbose=0, random_state=42),\n",
    "                       search_spaces = params_space,\n",
    "                       scoring = param_grid['scoring'],\n",
    "                       cv = StratifiedKFold( n_splits=param_grid['cv'],\n",
    "                                             shuffle=True,\n",
    "                                             random_state=42 ),\n",
    "                       n_jobs = -1, # 자동 검색 적용\n",
    "                       n_iter = param_grid['iterations'],   \n",
    "                       verbose = 0, refit = True, random_state = 42 \n",
    "                      )\n",
    "\n",
    "print(\"*** after lgbm BS ******\")\n",
    "lgbmBS.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "\n",
    "# save model\n",
    "stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "dt = f'{dt[:4]}_{dt[4:]}'\n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmBS.best_estimator_.get_params(), iter)\n",
    "df_estimator.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "\n",
    "# metrics accuracy,,,, 3단계 precision 등까지. dictionary\n",
    "result_dict = calc_results(lgbmBS, lgbmBS.best_estimator_, \n",
    "                           train_scaled, val_scaled, test_scaled,  \n",
    "                           train_target, val_target, test_target,\n",
    "                          )\n",
    "\n",
    "df_grid = make_df_from_estimator(param_grid, iter) # gridcv parameter\n",
    "df_grid.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "df_result = make_df_from_estimator(result_dict, iter)  # dict 를 df로\n",
    "df_concat = pd.concat([df_grid, df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "# acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "# precision = df_concat.loc['test_precision'].iloc[0]\n",
    "# f1score = df_concat.loc['f1score'].iloc[0]\n",
    "\n",
    "params_search = add_dict(param_grid, search_space)\n",
    "df_params_search = make_df_from_estimator(params_search, iter)\n",
    "df_params = pd.merge(df_params,df_params_search, how='outer', left_index=True, right_index=True)\n",
    "  \n",
    "print(\"******* No.{} BS Process is Done! ********\".format(iter))\n",
    "    \n",
    "print(\"**** End of BayesSearchCV Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one = df_combine_sorted(df_base, df_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aff1b_row5_col0, #T_aff1b_row5_col1, #T_aff1b_row5_col2, #T_aff1b_row10_col0, #T_aff1b_row10_col1, #T_aff1b_row10_col2, #T_aff1b_row15_col0, #T_aff1b_row15_col1, #T_aff1b_row15_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aff1b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aff1b_level0_col0\" class=\"col_heading level0 col0\" >parameter</th>\n",
       "      <th id=\"T_aff1b_level0_col1\" class=\"col_heading level0 col1\" >iter_1</th>\n",
       "      <th id=\"T_aff1b_level0_col2\" class=\"col_heading level0 col2\" >iter_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aff1b_row0_col0\" class=\"data row0 col0\" >best_score</td>\n",
       "      <td id=\"T_aff1b_row0_col1\" class=\"data row0 col1\" >0.713234</td>\n",
       "      <td id=\"T_aff1b_row0_col2\" class=\"data row0 col2\" >0.716239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aff1b_row1_col0\" class=\"data row1 col0\" >best_index</td>\n",
       "      <td id=\"T_aff1b_row1_col1\" class=\"data row1 col1\" >5.000000</td>\n",
       "      <td id=\"T_aff1b_row1_col2\" class=\"data row1 col2\" >18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aff1b_row2_col0\" class=\"data row2 col0\" >acc_train</td>\n",
       "      <td id=\"T_aff1b_row2_col1\" class=\"data row2 col1\" >0.756863</td>\n",
       "      <td id=\"T_aff1b_row2_col2\" class=\"data row2 col2\" >0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aff1b_row3_col0\" class=\"data row3 col0\" >acc_val</td>\n",
       "      <td id=\"T_aff1b_row3_col1\" class=\"data row3 col1\" >0.526316</td>\n",
       "      <td id=\"T_aff1b_row3_col2\" class=\"data row3 col2\" >0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aff1b_row4_col0\" class=\"data row4 col0\" >acc_test</td>\n",
       "      <td id=\"T_aff1b_row4_col1\" class=\"data row4 col1\" >0.769231</td>\n",
       "      <td id=\"T_aff1b_row4_col2\" class=\"data row4 col2\" >0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_aff1b_row5_col0\" class=\"data row5 col0\" >train_precision</td>\n",
       "      <td id=\"T_aff1b_row5_col1\" class=\"data row5 col1\" >0.911765</td>\n",
       "      <td id=\"T_aff1b_row5_col2\" class=\"data row5 col2\" >0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_aff1b_row6_col0\" class=\"data row6 col0\" >train_tn</td>\n",
       "      <td id=\"T_aff1b_row6_col1\" class=\"data row6 col1\" >131.000000</td>\n",
       "      <td id=\"T_aff1b_row6_col2\" class=\"data row6 col2\" >124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_aff1b_row7_col0\" class=\"data row7 col0\" >train_fp</td>\n",
       "      <td id=\"T_aff1b_row7_col1\" class=\"data row7 col1\" >6.000000</td>\n",
       "      <td id=\"T_aff1b_row7_col2\" class=\"data row7 col2\" >13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_aff1b_row8_col0\" class=\"data row8 col0\" >train_fn</td>\n",
       "      <td id=\"T_aff1b_row8_col1\" class=\"data row8 col1\" >56.000000</td>\n",
       "      <td id=\"T_aff1b_row8_col2\" class=\"data row8 col2\" >68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_aff1b_row9_col0\" class=\"data row9 col0\" >train_tp</td>\n",
       "      <td id=\"T_aff1b_row9_col1\" class=\"data row9 col1\" >62.000000</td>\n",
       "      <td id=\"T_aff1b_row9_col2\" class=\"data row9 col2\" >50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_aff1b_row10_col0\" class=\"data row10 col0\" >val_precision</td>\n",
       "      <td id=\"T_aff1b_row10_col1\" class=\"data row10 col1\" >1.000000</td>\n",
       "      <td id=\"T_aff1b_row10_col2\" class=\"data row10 col2\" >0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_aff1b_row11_col0\" class=\"data row11 col0\" >val_tn</td>\n",
       "      <td id=\"T_aff1b_row11_col1\" class=\"data row11 col1\" >7.000000</td>\n",
       "      <td id=\"T_aff1b_row11_col2\" class=\"data row11 col2\" >6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_aff1b_row12_col0\" class=\"data row12 col0\" >val_fp</td>\n",
       "      <td id=\"T_aff1b_row12_col1\" class=\"data row12 col1\" >0.000000</td>\n",
       "      <td id=\"T_aff1b_row12_col2\" class=\"data row12 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_aff1b_row13_col0\" class=\"data row13 col0\" >val_fn</td>\n",
       "      <td id=\"T_aff1b_row13_col1\" class=\"data row13 col1\" >9.000000</td>\n",
       "      <td id=\"T_aff1b_row13_col2\" class=\"data row13 col2\" >8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_aff1b_row14_col0\" class=\"data row14 col0\" >val_tp</td>\n",
       "      <td id=\"T_aff1b_row14_col1\" class=\"data row14 col1\" >3.000000</td>\n",
       "      <td id=\"T_aff1b_row14_col2\" class=\"data row14 col2\" >4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_aff1b_row15_col0\" class=\"data row15 col0\" >test_precision</td>\n",
       "      <td id=\"T_aff1b_row15_col1\" class=\"data row15 col1\" >1.000000</td>\n",
       "      <td id=\"T_aff1b_row15_col2\" class=\"data row15 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_aff1b_row16_col0\" class=\"data row16 col0\" >recall</td>\n",
       "      <td id=\"T_aff1b_row16_col1\" class=\"data row16 col1\" >0.500000</td>\n",
       "      <td id=\"T_aff1b_row16_col2\" class=\"data row16 col2\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_aff1b_row17_col0\" class=\"data row17 col0\" >f1score</td>\n",
       "      <td id=\"T_aff1b_row17_col1\" class=\"data row17 col1\" >0.666667</td>\n",
       "      <td id=\"T_aff1b_row17_col2\" class=\"data row17 col2\" >0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_aff1b_row18_col0\" class=\"data row18 col0\" >roc</td>\n",
       "      <td id=\"T_aff1b_row18_col1\" class=\"data row18 col1\" >0.750000</td>\n",
       "      <td id=\"T_aff1b_row18_col2\" class=\"data row18 col2\" >0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_aff1b_row19_col0\" class=\"data row19 col0\" >test_tn</td>\n",
       "      <td id=\"T_aff1b_row19_col1\" class=\"data row19 col1\" >7.000000</td>\n",
       "      <td id=\"T_aff1b_row19_col2\" class=\"data row19 col2\" >7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_aff1b_row20_col0\" class=\"data row20 col0\" >test_fp</td>\n",
       "      <td id=\"T_aff1b_row20_col1\" class=\"data row20 col1\" >0.000000</td>\n",
       "      <td id=\"T_aff1b_row20_col2\" class=\"data row20 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_aff1b_row21_col0\" class=\"data row21 col0\" >test_fn</td>\n",
       "      <td id=\"T_aff1b_row21_col1\" class=\"data row21 col1\" >3.000000</td>\n",
       "      <td id=\"T_aff1b_row21_col2\" class=\"data row21 col2\" >3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aff1b_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_aff1b_row22_col0\" class=\"data row22 col0\" >test_tp</td>\n",
       "      <td id=\"T_aff1b_row22_col1\" class=\"data row22 col1\" >3.000000</td>\n",
       "      <td id=\"T_aff1b_row22_col2\" class=\"data row22 col2\" >3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a1123efe0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_index =  ['train_precision', 'val_precision', 'test_precision']\n",
    "df_style(df_one.iloc[52:80, :], row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9cccf_row17_col0, #T_9cccf_row17_col1, #T_9cccf_row27_col0, #T_9cccf_row27_col1, #T_9cccf_row37_col0, #T_9cccf_row37_col1, #T_9cccf_row48_col0, #T_9cccf_row48_col1 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9cccf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9cccf_level0_col0\" class=\"col_heading level0 col0\" >parameter</th>\n",
       "      <th id=\"T_9cccf_level0_col1\" class=\"col_heading level0 col1\" >iter_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9cccf_row0_col0\" class=\"data row0 col0\" >boost_from_average</td>\n",
       "      <td id=\"T_9cccf_row0_col1\" class=\"data row0 col1\" >[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9cccf_row1_col0\" class=\"data row1 col0\" >boost_from_average</td>\n",
       "      <td id=\"T_9cccf_row1_col1\" class=\"data row1 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9cccf_row2_col0\" class=\"data row2 col0\" >boosting_type</td>\n",
       "      <td id=\"T_9cccf_row2_col1\" class=\"data row2 col1\" >['gbdt', 'dart']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9cccf_row3_col0\" class=\"data row3 col0\" >boosting_type</td>\n",
       "      <td id=\"T_9cccf_row3_col1\" class=\"data row3 col1\" >gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9cccf_row4_col0\" class=\"data row4 col0\" >class_weight</td>\n",
       "      <td id=\"T_9cccf_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9cccf_row5_col0\" class=\"data row5 col0\" >colsample_bytree</td>\n",
       "      <td id=\"T_9cccf_row5_col1\" class=\"data row5 col1\" >(0.5, 1.0, 'uniform')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9cccf_row6_col0\" class=\"data row6 col0\" >colsample_bytree</td>\n",
       "      <td id=\"T_9cccf_row6_col1\" class=\"data row6 col1\" >0.581804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9cccf_row7_col0\" class=\"data row7 col0\" >cv</td>\n",
       "      <td id=\"T_9cccf_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9cccf_row8_col0\" class=\"data row8 col0\" >cv</td>\n",
       "      <td id=\"T_9cccf_row8_col1\" class=\"data row8 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_9cccf_row9_col0\" class=\"data row9 col0\" >force_col_wise</td>\n",
       "      <td id=\"T_9cccf_row9_col1\" class=\"data row9 col1\" >['true']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_9cccf_row10_col0\" class=\"data row10 col0\" >force_col_wise</td>\n",
       "      <td id=\"T_9cccf_row10_col1\" class=\"data row10 col1\" >true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_9cccf_row11_col0\" class=\"data row11 col0\" >importance_type</td>\n",
       "      <td id=\"T_9cccf_row11_col1\" class=\"data row11 col1\" >split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_9cccf_row12_col0\" class=\"data row12 col0\" >importance_type</td>\n",
       "      <td id=\"T_9cccf_row12_col1\" class=\"data row12 col1\" >['split']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_9cccf_row13_col0\" class=\"data row13 col0\" >iterations</td>\n",
       "      <td id=\"T_9cccf_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_9cccf_row14_col0\" class=\"data row14 col0\" >iterations</td>\n",
       "      <td id=\"T_9cccf_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_9cccf_row15_col0\" class=\"data row15 col0\" >learning_rate</td>\n",
       "      <td id=\"T_9cccf_row15_col1\" class=\"data row15 col1\" >(0.0001, 0.004, 'log-uniform')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_9cccf_row16_col0\" class=\"data row16 col0\" >learning_rate</td>\n",
       "      <td id=\"T_9cccf_row16_col1\" class=\"data row16 col1\" >0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_9cccf_row17_col0\" class=\"data row17 col0\" >max_bin</td>\n",
       "      <td id=\"T_9cccf_row17_col1\" class=\"data row17 col1\" >513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_9cccf_row18_col0\" class=\"data row18 col0\" >max_bin</td>\n",
       "      <td id=\"T_9cccf_row18_col1\" class=\"data row18 col1\" >(100, 1000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_9cccf_row19_col0\" class=\"data row19 col0\" >max_depth</td>\n",
       "      <td id=\"T_9cccf_row19_col1\" class=\"data row19 col1\" >27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_9cccf_row20_col0\" class=\"data row20 col0\" >max_depth</td>\n",
       "      <td id=\"T_9cccf_row20_col1\" class=\"data row20 col1\" >(0, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_9cccf_row21_col0\" class=\"data row21 col0\" >metric</td>\n",
       "      <td id=\"T_9cccf_row21_col1\" class=\"data row21 col1\" >['binary_logloss']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_9cccf_row22_col0\" class=\"data row22 col0\" >metric</td>\n",
       "      <td id=\"T_9cccf_row22_col1\" class=\"data row22 col1\" >binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_9cccf_row23_col0\" class=\"data row23 col0\" >min_child_samples</td>\n",
       "      <td id=\"T_9cccf_row23_col1\" class=\"data row23 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_9cccf_row24_col0\" class=\"data row24 col0\" >min_child_samples</td>\n",
       "      <td id=\"T_9cccf_row24_col1\" class=\"data row24 col1\" >(5, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_9cccf_row25_col0\" class=\"data row25 col0\" >min_child_weight</td>\n",
       "      <td id=\"T_9cccf_row25_col1\" class=\"data row25 col1\" >0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_9cccf_row26_col0\" class=\"data row26 col0\" >min_split_gain</td>\n",
       "      <td id=\"T_9cccf_row26_col1\" class=\"data row26 col1\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_9cccf_row27_col0\" class=\"data row27 col0\" >n_estimators</td>\n",
       "      <td id=\"T_9cccf_row27_col1\" class=\"data row27 col1\" >(700, 5000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_9cccf_row28_col0\" class=\"data row28 col0\" >n_estimators</td>\n",
       "      <td id=\"T_9cccf_row28_col1\" class=\"data row28 col1\" >3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_9cccf_row29_col0\" class=\"data row29 col0\" >n_jobs</td>\n",
       "      <td id=\"T_9cccf_row29_col1\" class=\"data row29 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_9cccf_row30_col0\" class=\"data row30 col0\" >num_col</td>\n",
       "      <td id=\"T_9cccf_row30_col1\" class=\"data row30 col1\" >98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_9cccf_row31_col0\" class=\"data row31 col0\" >num_col</td>\n",
       "      <td id=\"T_9cccf_row31_col1\" class=\"data row31 col1\" >98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_9cccf_row32_col0\" class=\"data row32 col0\" >num_leaves</td>\n",
       "      <td id=\"T_9cccf_row32_col1\" class=\"data row32 col1\" >(3, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_9cccf_row33_col0\" class=\"data row33 col0\" >num_leaves</td>\n",
       "      <td id=\"T_9cccf_row33_col1\" class=\"data row33 col1\" >13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_9cccf_row34_col0\" class=\"data row34 col0\" >objective</td>\n",
       "      <td id=\"T_9cccf_row34_col1\" class=\"data row34 col1\" >['binary']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_9cccf_row35_col0\" class=\"data row35 col0\" >objective</td>\n",
       "      <td id=\"T_9cccf_row35_col1\" class=\"data row35 col1\" >binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_9cccf_row36_col0\" class=\"data row36 col0\" >random_state</td>\n",
       "      <td id=\"T_9cccf_row36_col1\" class=\"data row36 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_9cccf_row37_col0\" class=\"data row37 col0\" >reg_alpha</td>\n",
       "      <td id=\"T_9cccf_row37_col1\" class=\"data row37 col1\" >(0.0, 4.0, 'uniform')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_9cccf_row38_col0\" class=\"data row38 col0\" >reg_alpha</td>\n",
       "      <td id=\"T_9cccf_row38_col1\" class=\"data row38 col1\" >1.992693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_9cccf_row39_col0\" class=\"data row39 col0\" >reg_lambda</td>\n",
       "      <td id=\"T_9cccf_row39_col1\" class=\"data row39 col1\" >(0.0, 4.0, 'uniform')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_9cccf_row40_col0\" class=\"data row40 col0\" >reg_lambda</td>\n",
       "      <td id=\"T_9cccf_row40_col1\" class=\"data row40 col1\" >3.872697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_9cccf_row41_col0\" class=\"data row41 col0\" >scale_pos_weight</td>\n",
       "      <td id=\"T_9cccf_row41_col1\" class=\"data row41 col1\" >(0.2, 2.0, 'uniform')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_9cccf_row42_col0\" class=\"data row42 col0\" >scale_pos_weight</td>\n",
       "      <td id=\"T_9cccf_row42_col1\" class=\"data row42 col1\" >0.668451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_9cccf_row43_col0\" class=\"data row43 col0\" >scoring</td>\n",
       "      <td id=\"T_9cccf_row43_col1\" class=\"data row43 col1\" >precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_9cccf_row44_col0\" class=\"data row44 col0\" >scoring</td>\n",
       "      <td id=\"T_9cccf_row44_col1\" class=\"data row44 col1\" >precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_9cccf_row45_col0\" class=\"data row45 col0\" >silent</td>\n",
       "      <td id=\"T_9cccf_row45_col1\" class=\"data row45 col1\" >warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_9cccf_row46_col0\" class=\"data row46 col0\" >subsample</td>\n",
       "      <td id=\"T_9cccf_row46_col1\" class=\"data row46 col1\" >(0.005, 1.0, 'uniform')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_9cccf_row47_col0\" class=\"data row47 col0\" >subsample</td>\n",
       "      <td id=\"T_9cccf_row47_col1\" class=\"data row47 col1\" >0.648771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_9cccf_row48_col0\" class=\"data row48 col0\" >subsample_for_bin</td>\n",
       "      <td id=\"T_9cccf_row48_col1\" class=\"data row48 col1\" >(100000, 500000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_9cccf_row49_col0\" class=\"data row49 col0\" >subsample_for_bin</td>\n",
       "      <td id=\"T_9cccf_row49_col1\" class=\"data row49 col1\" >477471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_9cccf_row50_col0\" class=\"data row50 col0\" >subsample_freq</td>\n",
       "      <td id=\"T_9cccf_row50_col1\" class=\"data row50 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_9cccf_row51_col0\" class=\"data row51 col0\" >verbose</td>\n",
       "      <td id=\"T_9cccf_row51_col1\" class=\"data row51 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_9cccf_row52_col0\" class=\"data row52 col0\" >best_score</td>\n",
       "      <td id=\"T_9cccf_row52_col1\" class=\"data row52 col1\" >0.713234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_9cccf_row53_col0\" class=\"data row53 col0\" >best_index</td>\n",
       "      <td id=\"T_9cccf_row53_col1\" class=\"data row53 col1\" >5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_9cccf_row54_col0\" class=\"data row54 col0\" >acc_train</td>\n",
       "      <td id=\"T_9cccf_row54_col1\" class=\"data row54 col1\" >0.756863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_9cccf_row55_col0\" class=\"data row55 col0\" >acc_val</td>\n",
       "      <td id=\"T_9cccf_row55_col1\" class=\"data row55 col1\" >0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_9cccf_row56_col0\" class=\"data row56 col0\" >acc_test</td>\n",
       "      <td id=\"T_9cccf_row56_col1\" class=\"data row56 col1\" >0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_9cccf_row57_col0\" class=\"data row57 col0\" >train_precision</td>\n",
       "      <td id=\"T_9cccf_row57_col1\" class=\"data row57 col1\" >0.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_9cccf_row58_col0\" class=\"data row58 col0\" >train_tn</td>\n",
       "      <td id=\"T_9cccf_row58_col1\" class=\"data row58 col1\" >131.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9cccf_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_9cccf_row59_col0\" class=\"data row59 col0\" >train_fp</td>\n",
       "      <td id=\"T_9cccf_row59_col1\" class=\"data row59 col1\" >6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17a4256a8c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_index = ['n_estimators', 'reg_alpha', 'max_bin', 'subsample_for_bin']\n",
    "df_style(df_one.head(60), row_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.716239</td>\n",
       "      <td>0.032697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.713234</td>\n",
       "      <td>0.056372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.062869</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.692250</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.688143</td>\n",
       "      <td>0.091326</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.685140</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.679061</td>\n",
       "      <td>0.075857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.676515</td>\n",
       "      <td>0.064621</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655819</td>\n",
       "      <td>0.050079</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636308</td>\n",
       "      <td>0.085987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.633034</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.606166</td>\n",
       "      <td>0.057386</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594454</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.593647</td>\n",
       "      <td>0.050547</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.586677</td>\n",
       "      <td>0.045425</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552014</td>\n",
       "      <td>0.048498</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.543062</td>\n",
       "      <td>0.042260</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  rank_test_score\n",
       "18         0.716239        0.032697                1\n",
       "5          0.713234        0.056372                2\n",
       "7          0.709000        0.062869                3\n",
       "16         0.692250        0.089111                4\n",
       "11         0.688143        0.091326                5\n",
       "12         0.685140        0.078857                6\n",
       "15         0.679061        0.075857                7\n",
       "8          0.676515        0.064621                8\n",
       "2          0.655819        0.050079                9\n",
       "3          0.636308        0.085987               10\n",
       "14         0.633034        0.030391               11\n",
       "13         0.606166        0.057386               12\n",
       "0          0.594454        0.046664               13\n",
       "6          0.593647        0.050547               14\n",
       "9          0.586677        0.045425               15\n",
       "4          0.552014        0.048498               16\n",
       "19         0.543062        0.042260               17\n",
       "17         0.000000        0.000000               18\n",
       "1          0.000000        0.000000               18\n",
       "10         0.000000        0.000000               18"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter 조합별 측정치 비교\n",
    "df_result =  pd.DataFrame(lgbmBS.cv_results_)\n",
    "df_result.loc[:, ['mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_boost_from_average', 'param_boosting_type',\n",
       "       'param_colsample_bytree', 'param_force_col_wise',\n",
       "       'param_importance_type', 'param_learning_rate', 'param_max_bin',\n",
       "       'param_max_depth', 'param_metric', 'param_min_child_samples',\n",
       "       'param_n_estimators', 'param_num_leaves', 'param_objective',\n",
       "       'param_reg_alpha', 'param_reg_lambda', 'param_scale_pos_weight',\n",
       "       'param_subsample', 'param_subsample_for_bin', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.713234</td>\n",
       "      <td>0.056372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.062869</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.676515</td>\n",
       "      <td>0.064621</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655819</td>\n",
       "      <td>0.050079</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636308</td>\n",
       "      <td>0.085987</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.594454</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.593647</td>\n",
       "      <td>0.050547</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.586677</td>\n",
       "      <td>0.045425</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552014</td>\n",
       "      <td>0.048498</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  rank_test_score\n",
       "5         0.713234        0.056372                1\n",
       "7         0.709000        0.062869                2\n",
       "8         0.676515        0.064621                3\n",
       "2         0.655819        0.050079                4\n",
       "3         0.636308        0.085987                5\n",
       "0         0.594454        0.046664                6\n",
       "6         0.593647        0.050547                7\n",
       "9         0.586677        0.045425                8\n",
       "4         0.552014        0.048498                9\n",
       "1         0.000000        0.000000               10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter 조합별 측정치 비교\n",
    "df_result =  pd.DataFrame(lgbmBS.cv_results_)\n",
    "df_result.loc[:, ['mean_test_score', 'std_test_score', 'rank_test_score']].sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space, parameters and results save\n",
    "df_one.to_csv(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.csv')\n",
    "df_one.to_pickle(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 아래 내용은 위의 df_one을 대체함.\n",
    "# parameter and results save\n",
    "df_base.to_csv(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.csv')\n",
    "df_base.to_pickle(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.pkl')\n",
    "\n",
    "# search_space, parameters save\n",
    "df_params.to_csv(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.csv')\n",
    "df_params.to_pickle(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "# save model\n",
    "# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\n",
    "joblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\n",
    "joblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\n",
    "save_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 가장 좋은 결과 저장\n",
    "save_best_results(com_name, lgbmBS.best_estimator_, scaler, new_col, df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lgbmBS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmBS.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=train_input.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.tail(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:35]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter 조합별 측정치 비교 결과 확인후 robust한 index select하여 아래 진행 후 bayessearchcv 진행\n",
    "# 아래는 index가 44인 경우\n",
    "second_best_index =  44  # select from parameter 비교 from .cv_results_\n",
    "\n",
    "search_space_secondbest = {\n",
    "    'boosting_type' : [df_result.iloc[second_best_index,:]['param_boosting_type']],\n",
    "    'learning_rate': [df_result.iloc[second_best_index,:]['param_learning_rate']],\n",
    "    'num_leaves': [df_result.iloc[second_best_index,:]['param_num_leaves']],\n",
    "    'max_depth': [df_result.iloc[second_best_index,:]['param_max_depth']],\n",
    "    'min_child_samples': [df_result.iloc[second_best_index,:]['param_min_child_samples']],\n",
    "#     'min_child_weight': [df_result.iloc[second_best_index,:]['param_min_child_weight']],\n",
    "#     'min_split_loss': [df_result.iloc[second_best_index,:]['param_min_split_loss']],\n",
    "    'max_bin': [df_result.iloc[second_best_index,:]['param_max_bin']],\n",
    "#     'max_cat_threshold' : [df_result.iloc[second_best_index,:]['param_max_cat_threshold']],\n",
    "    'subsample': [df_result.iloc[second_best_index,:]['param_subsample']],\n",
    "#     'subsample_freq': [df_result.iloc[second_best_index,:]['param_subsample_freq']],\n",
    "    'colsample_bytree': [df_result.iloc[second_best_index,:]['param_colsample_bytree']],\n",
    "    'subsample_for_bin': [df_result.iloc[second_best_index,:]['param_subsample_for_bin']],\n",
    "    'scale_pos_weight' : [df_result.iloc[second_best_index,:]['param_scale_pos_weight']],\n",
    "#     'scale_pos_weight': [df_result.iloc[second_best_index,:]['param_scale_pos_weight']],\n",
    "    'n_estimators': [df_result.iloc[second_best_index,:]['param_n_estimators']],\n",
    "    'reg_alpha' : [df_result.iloc[second_best_index,:]['param_reg_alpha']],\n",
    "    'reg_lambda' : [df_result.iloc[second_best_index,:]['param_reg_lambda']],\n",
    "#     'reg_alpha' : [df_result.iloc[second_best_index,:]['param_reg_alpha']],\n",
    "#     'reg_lambda' : [df_result.iloc[second_best_index,:]['param_reg_lambda']],\n",
    "    'force_col_wise': [df_result.iloc[second_best_index,:]['param_force_col_wise']],\n",
    "    'importance_type': [df_result.iloc[second_best_index,:]['param_importance_type']],\n",
    "    'boost_from_average' : [df_result.iloc[second_best_index,:]['param_boost_from_average']],\n",
    "    'objective':[df_result.iloc[second_best_index,:]['param_objective']],\n",
    "    'metric': [df_result.iloc[second_best_index,:]['param_metric']],\n",
    "}\n",
    "\n",
    "params_space = search_space_secondbest.copy() # for Bayesian Optimization"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
