{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    fields=my_dict.keys()\n",
    "    values = my_dict.values()\n",
    "    pd.DataFrame([fields, values], index=['parameter','value']).T.to_csv(path)\n",
    "#     df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "#     df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) \n",
    "    \n",
    "# def load_dict_from_csv(path):\n",
    "#     df = pd.read_csv(path, header=None)\n",
    "#     my_dict = df.to_dict()\n",
    "#     return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'iter_{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(lgbm, model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target,\n",
    "                 test_scaled1, test_scaled2, test_scaled3, test_target1, test_target2, test_target3):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbm.best_score_ \n",
    "    result_dict['best_index'] = lgbm.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled1)\n",
    "    result_dict['acc_test1'] = model.score(test_scaled1, test_target1)\n",
    "    result_dict['precision1'] = precision_score(test_target1, y_predict)\n",
    "    result_dict['recall1'] = recall_score(test_target1, y_predict)\n",
    "    result_dict['f1score1'] = f1_score(test_target1, y_predict)\n",
    "    result_dict['roc1'] = roc_auc_score(test_target1, y_predict)\n",
    "    cm = confusion_matrix(test_target1, y_predict)\n",
    "    result_dict['tn1'] = cm[0,0]\n",
    "    result_dict['fp1'] = cm[0,1]\n",
    "    result_dict['fn1'] = cm[1,0]\n",
    "    result_dict['tp1'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled2)\n",
    "    result_dict['acc_test2'] = model.score(test_scaled2, test_target2)\n",
    "    result_dict['precision2'] = precision_score(test_target2, y_predict)\n",
    "    result_dict['recall2'] = recall_score(test_target2, y_predict)\n",
    "    result_dict['f1score2'] = f1_score(test_target2, y_predict)\n",
    "    result_dict['roc2'] = roc_auc_score(test_target2, y_predict)\n",
    "    cm = confusion_matrix(test_target2, y_predict)\n",
    "    result_dict['tn2'] = cm[0,0]\n",
    "    result_dict['fp2'] = cm[0,1]\n",
    "    result_dict['fn2'] = cm[1,0]\n",
    "    result_dict['tp2'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled3)\n",
    "    result_dict['acc_test3'] = model.score(test_scaled3, test_target3)\n",
    "    result_dict['precision3'] = precision_score(test_target3, y_predict)\n",
    "    result_dict['recall3'] = recall_score(test_target3, y_predict)\n",
    "    result_dict['f1score3'] = f1_score(test_target3, y_predict)\n",
    "    result_dict['roc3'] = roc_auc_score(test_target3, y_predict)\n",
    "    cm = confusion_matrix(test_target3, y_predict)\n",
    "    result_dict['tn3'] = cm[0,0]\n",
    "    result_dict['fp3'] = cm[0,1]\n",
    "    result_dict['fn3'] = cm[1,0]\n",
    "    result_dict['tp3'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_results(com_name, model, scaler, columns, df_base):\n",
    "    joblib.dump(model, f'{directory_for_model}{com_name}/best_model.pkl') # estimaor 저장\n",
    "    joblib.dump(scaler, f'{directory_for_model}{com_name}/best_scaler.pkl') # scaler 저장\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_model_p.pkl', model)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_scaler_p.pkl', scaler)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_columns.pkl', new_col)\n",
    "    save_list_to_csv(f'{directory_for_model}{com_name}/best_columns.csv', new_col)\n",
    "    df_base.to_pickle(f'{directory_for_model}{com_name}/best_result.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(*dicts):\n",
    "    dsum = {}\n",
    "    d_k = []\n",
    "    d_v = []\n",
    "    for dic in dicts:\n",
    "        d_k.extend(list(dic.keys()))  # sum keys list\n",
    "        d_v.extend(list(dic.values()))  # sum values list\n",
    "    for i in range(len(d_k)):\n",
    "        dsum[d_k[i]] = d_v[i]\n",
    "    return dsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_combine_sorted(df_base_l, df_params_l):\n",
    "    o_num = list(df_base_l.index).index('best_score')\n",
    "    df1 = df_base.iloc[:o_num, :]\n",
    "    df2 = df_base.iloc[o_num:, :]\n",
    "    df3 = pd.concat([df1, df_params_l], axis=0)\n",
    "    df3.sort_index(axis=0, inplace=True)\n",
    "    df_sorted = pd.concat([df3, df2], axis=0)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..')) # 현재 폴더로 이동\n",
    "if module_path+\"\\\\data\\\\base_data\\\\common_data\" not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\data\\\\base_data\\\\common_data\") #  공통으로 사용하는 각종 리스트, 코드 등 \n",
    "    \n",
    "import common_data as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = cd.code_all # 전체 회사 코드\n",
    "code = {'032830': ['삼성생명', 'sslife']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "#             'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', \n",
    "            'privequity_1',  'insurance_1', 'corporateetc_1', # bank_1, 'financeetc_1 제외\n",
    "            'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "#             'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', \n",
    "            'privequity_2', 'insurance_2', 'corporateetc_2', # bank_2, 'financeetc_2 제외\n",
    "            'foreigneretc_2']\n",
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']\n",
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']\n",
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]\n",
    "col_futures = ['ixic_f_cr', 'ixic_f_cr_2', 'spx_f_cr', 'spx_f_cr_2', 'dji_f_cr', 'dji_f_cr_2',\n",
    "           'wti_cr','wti_cr_2', 'dxy_cr', 'dxy_cr_2', 'bond_usa_10_cr', 'bond_usa_10_cr_2' ]\n",
    "column_o = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr\n",
    "\n",
    "col_except_futures = [item for item in column_o if item not in col_futures]\n",
    "\n",
    "new_col = col_except_futures.copy()\n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   \n",
    "\n",
    "# col_futures : futures는 당일 종료가 되지 않는 data이므로 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "df_params = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 신규 분석 데이터는 아래 것으로 사용\n",
    "\n",
    "com_name = list(code.values())[0][1]\n",
    "\n",
    "directory_for_ml = '../data/data_for_ml/predict/'\n",
    "fname = f'df_{com_name}_combine.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df_o = pd.read_pickle(f_name) \n",
    "df_o = df_o.iloc[:-1] # /predict/를 사용할 경우 마지막 prediction data 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = None\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'boosting_type' : ['gbdt', 'dart', ],# ['gbdt', 'dart', 'goss'],\n",
    "    'learning_rate': (0.0001, 0.004, 'log-uniform'),\n",
    "    'num_leaves': (3, 20),      \n",
    "    'max_depth': (0, 50), #[-1], #(0, 50),\n",
    "    'min_child_samples': (5, 40),\n",
    "#     'min_child_weight': (0.001, 10.0), # 값을 변동시 같은 값이 최적값으로 선정되더라고 precision이 틀림. 반드시 값을 바꾸면서 진행해야 함.\n",
    "#     'min_split_loss': (0, 5), \n",
    "    'max_bin': (100, 1000), # 사용시 0.75%로 올라감 default: 255\n",
    "#     'max_cat_threshold' : (1, 100),\n",
    "    'subsample': (0.005, 1.0, 'uniform'), # == bagging_fraction\n",
    "#     'subsample_freq': (1, 10), # mobis에서 적용시 값이 많이 올라감. default:0\n",
    "    'colsample_bytree': (0.5, 1.0, 'uniform'),\n",
    "    'subsample_for_bin': (100000, 500000),\n",
    "    'scale_pos_weight' : (0.2, 2.0, 'uniform'),\n",
    "#     'scale_pos_weight': np.arange(0.2, 2, 0.1) ,\n",
    "    'n_estimators': (700, 5000),\n",
    "    'reg_alpha' : (0.0, 4.0, 'uniform'), # =='lambda_l1': [0, 5], # default 0\n",
    "    'reg_lambda' : (0.0, 4.0, 'uniform'), # == lambda_l2': [0, 5], #default 0    \n",
    "#     'reg_alpha' : np.arange(0, 4, 0.1),\n",
    "#     'reg_lambda' : np.arange(0, 4, 0.1),\n",
    "    'force_col_wise': ['true'], \n",
    "    'importance_type': ['split'], # ['gain'], default: split\n",
    "    'boost_from_average' : [True, False],\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "}\n",
    "\n",
    "params_space = search_space.copy() # for Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'cv' : 3,\n",
    "#     'cv' : None,\n",
    "#     'scoring' : None,\n",
    "#     'scoring' : 'f1',\n",
    "#     'scoring' : 'roc_auc',\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'average_precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 50,  # default : 50, number of parameter settings.\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_for_model = '../data/data_for_ml/model/model/0. test/'\n",
    "directory_for_model = '../data/data_for_ml/model/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbm BS ******\n",
      "******* No.7 BS Process is Done! ********\n",
      "**** End of BayesSearchCV Process ****\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(directory_for_model+com_name):\n",
    "    os.makedirs(directory_for_model+com_name)\n",
    "\n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmBS = None\n",
    "gsbs = 'bs'\n",
    "\n",
    "lgbmBS = BayesSearchCV( estimator = lightgbm.LGBMClassifier(verbose=0, random_state=42),\n",
    "                       search_spaces = params_space,\n",
    "                       scoring = param_grid['scoring'],\n",
    "                       cv = StratifiedKFold( n_splits=param_grid['cv'],\n",
    "                                             shuffle=True,\n",
    "                                             random_state=42 ),\n",
    "                       n_jobs = -1, # 자동 검색 적용\n",
    "                       n_iter = param_grid['iterations'],   \n",
    "                       verbose = 0, refit = True, random_state = 42 \n",
    "                      )\n",
    "\n",
    "print(\"*** after lgbm BS ******\")\n",
    "lgbmBS.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "\n",
    "# save model\n",
    "stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "dt = f'{dt[:4]}_{dt[4:]}'\n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmBS.best_estimator_.get_params(), iter)\n",
    "df_estimator.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "\n",
    "# metrics accuracy,,,, 3단계 precision 등까지. dictionary\n",
    "result_dict = calc_results(lgbmBS, lgbmBS.best_estimator_, \n",
    "                           train_scaled, val_scaled, test_scaled,  \n",
    "                           train_target, val_target, test_target,\n",
    "                           test_scaled1, test_scaled2, test_scaled3,  \n",
    "                           test_target1, test_target2, test_target3\n",
    "                          )\n",
    "\n",
    "df_grid = make_df_from_estimator(param_grid, iter) # gridcv parameter\n",
    "df_grid.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "df_result = make_df_from_estimator(result_dict, iter)  # dict 를 df로\n",
    "df_concat = pd.concat([df_grid, df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "precision = df_concat.loc['precision'].iloc[0]\n",
    "f1score = df_concat.loc['f1score'].iloc[0]\n",
    "\n",
    "params_search = add_dict(param_grid, search_space)\n",
    "df_params_search = make_df_from_estimator(params_search, iter)\n",
    "df_params = pd.merge(df_params,df_params_search, how='outer', left_index=True, right_index=True)\n",
    "  \n",
    "print(\"******* No.{} BS Process is Done! ********\".format(iter))\n",
    "    \n",
    "print(\"**** End of BayesSearchCV Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_1</th>\n",
       "      <th>iter_2</th>\n",
       "      <th>iter_3</th>\n",
       "      <th>iter_4</th>\n",
       "      <th>iter_5</th>\n",
       "      <th>iter_6</th>\n",
       "      <th>iter_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.718831</td>\n",
       "      <td>0.622334</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.718831</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.718831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>221</td>\n",
       "      <td>671</td>\n",
       "      <td>715</td>\n",
       "      <td>221</td>\n",
       "      <td>1000</td>\n",
       "      <td>912</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 3000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 6000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>1571</td>\n",
       "      <td>4780</td>\n",
       "      <td>2924</td>\n",
       "      <td>1571</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>2.993751</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.907527</td>\n",
       "      <td>2.993751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95316</td>\n",
       "      <td>2.993751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 2.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>2.911742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.911742</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.049682</td>\n",
       "      <td>2.911742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>0.599426</td>\n",
       "      <td>1.12303</td>\n",
       "      <td>0.744319</td>\n",
       "      <td>0.599426</td>\n",
       "      <td>0.820759</td>\n",
       "      <td>0.729823</td>\n",
       "      <td>0.599426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04062</td>\n",
       "      <td>0.707982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855742</td>\n",
       "      <td>0.534441</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>260724</td>\n",
       "      <td>500000</td>\n",
       "      <td>304058</td>\n",
       "      <td>260724</td>\n",
       "      <td>100000</td>\n",
       "      <td>281873</td>\n",
       "      <td>260724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.620157</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.645483</td>\n",
       "      <td>0.65117</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.16129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.27027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          iter_1   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               dart   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                        0.718831   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                            split   \n",
       "importance_type                          [split]   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "learning_rate                              0.004   \n",
       "max_bin                                      221   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     36   \n",
       "max_depth                                (0, 50)   \n",
       "metric                          [binary_logloss]   \n",
       "metric                            binary_logloss   \n",
       "min_child_samples                              5   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                1571   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                               (3, 20)   \n",
       "num_leaves                                     3   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_alpha                               2.993751   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                              2.911742   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.599426   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample                                    1.0   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_for_bin                         260724   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.716667   \n",
       "best_index                                  49.0   \n",
       "acc_train                                   0.63   \n",
       "acc_val                                     0.58   \n",
       "acc_test                                0.571429   \n",
       "precision                               0.833333   \n",
       "recall                                   0.16129   \n",
       "f1score                                  0.27027   \n",
       "\n",
       "                                          iter_2   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                         False   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                        0.622334   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                            split   \n",
       "importance_type                          [split]   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "learning_rate                           0.001018   \n",
       "max_bin                                      671   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     36   \n",
       "max_depth                                (0, 50)   \n",
       "metric                          [binary_logloss]   \n",
       "metric                            binary_logloss   \n",
       "min_child_samples                             33   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                4780   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                               (3, 20)   \n",
       "num_leaves                                    19   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_alpha                                    4.0   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                                   0.0   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                         1.12303   \n",
       "scoring                                 accuracy   \n",
       "scoring                                 accuracy   \n",
       "silent                                      warn   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample                                0.04062   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_for_bin                         500000   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.620157   \n",
       "best_index                                  30.0   \n",
       "acc_train                                   0.87   \n",
       "acc_val                                     0.48   \n",
       "acc_test                                0.571429   \n",
       "precision                               0.555556   \n",
       "recall                                  0.645161   \n",
       "f1score                                 0.597015   \n",
       "\n",
       "                                          iter_3   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                             0.5   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                            split   \n",
       "importance_type                          [split]   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "learning_rate                             0.0001   \n",
       "max_bin                                      715   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     13   \n",
       "max_depth                                (0, 50)   \n",
       "metric                          [binary_logloss]   \n",
       "metric                            binary_logloss   \n",
       "min_child_samples                             16   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 3000)   \n",
       "n_estimators                                2924   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                               (3, 20)   \n",
       "num_leaves                                    14   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_alpha                               2.907527   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                                   4.0   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.744319   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample                               0.707982   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_for_bin                         304058   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.690359   \n",
       "best_index                                  23.0   \n",
       "acc_train                                   0.76   \n",
       "acc_val                                      0.6   \n",
       "acc_test                                0.571429   \n",
       "precision                               0.642857   \n",
       "recall                                  0.290323   \n",
       "f1score                                      0.4   \n",
       "\n",
       "                                          iter_4   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               dart   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                        0.718831   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                            split   \n",
       "importance_type                          [split]   \n",
       "iterations                                    60   \n",
       "iterations                                    60   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "learning_rate                              0.004   \n",
       "max_bin                                      221   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     36   \n",
       "max_depth                                (0, 50)   \n",
       "metric                          [binary_logloss]   \n",
       "metric                            binary_logloss   \n",
       "min_child_samples                              5   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                1571   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                               (3, 20)   \n",
       "num_leaves                                     3   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_alpha                               2.993751   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                              2.911742   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.599426   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample                                    1.0   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_for_bin                         260724   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.716667   \n",
       "best_index                                  49.0   \n",
       "acc_train                                   0.63   \n",
       "acc_val                                     0.58   \n",
       "acc_test                                0.571429   \n",
       "precision                               0.833333   \n",
       "recall                                   0.16129   \n",
       "f1score                                  0.27027   \n",
       "\n",
       "                                          iter_5   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                         False   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                             0.5   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                            split   \n",
       "importance_type                          [split]   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "learning_rate                             0.0001   \n",
       "max_bin                                     1000   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     22   \n",
       "max_depth                                (0, 50)   \n",
       "metric                          [binary_logloss]   \n",
       "metric                            binary_logloss   \n",
       "min_child_samples                             23   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                 700   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                               (3, 20)   \n",
       "num_leaves                                     3   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                    (0.0, 2.0, uniform)   \n",
       "reg_alpha                                    0.0   \n",
       "reg_lambda                   (0.0, 2.0, uniform)   \n",
       "reg_lambda                                   2.0   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.820759   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample                               0.855742   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_for_bin                         100000   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.645483   \n",
       "best_index                                  22.0   \n",
       "acc_train                                   0.73   \n",
       "acc_val                                     0.58   \n",
       "acc_test                                0.650794   \n",
       "precision                               0.655172   \n",
       "recall                                  0.612903   \n",
       "f1score                                 0.633333   \n",
       "\n",
       "                                          iter_6                        iter_7  \n",
       "parameter                                                                       \n",
       "boost_from_average                 [True, False]                 [True, False]  \n",
       "boost_from_average                         False                          True  \n",
       "boosting_type                       [gbdt, dart]                  [gbdt, dart]  \n",
       "boosting_type                               dart                          dart  \n",
       "class_weight                                None                          None  \n",
       "colsample_bytree             (0.5, 1.0, uniform)           (0.5, 1.0, uniform)  \n",
       "colsample_bytree                             0.5                      0.718831  \n",
       "cv                                             3                             3  \n",
       "cv                                             3                             3  \n",
       "force_col_wise                            [true]                        [true]  \n",
       "force_col_wise                              true                          true  \n",
       "importance_type                            split                         split  \n",
       "importance_type                          [split]                       [split]  \n",
       "iterations                                    50                            50  \n",
       "iterations                                    50                            50  \n",
       "learning_rate       (0.0001, 0.004, log-uniform)  (0.0001, 0.004, log-uniform)  \n",
       "learning_rate                             0.0001                         0.004  \n",
       "max_bin                                      912                           221  \n",
       "max_bin                              (100, 1000)                   (100, 1000)  \n",
       "max_depth                                     50                            36  \n",
       "max_depth                                (0, 50)                       (0, 50)  \n",
       "metric                          [binary_logloss]              [binary_logloss]  \n",
       "metric                            binary_logloss                binary_logloss  \n",
       "min_child_samples                             40                             5  \n",
       "min_child_samples                        (5, 40)                       (5, 40)  \n",
       "min_child_weight                           0.001                         0.001  \n",
       "min_split_gain                               0.0                           0.0  \n",
       "n_estimators                         (700, 6000)                   (700, 5000)  \n",
       "n_estimators                                 700                          1571  \n",
       "n_jobs                                        -1                            -1  \n",
       "num_col                                       98                            98  \n",
       "num_col                                       98                            98  \n",
       "num_leaves                               (3, 20)                       (3, 20)  \n",
       "num_leaves                                     3                             3  \n",
       "objective                               [binary]                      [binary]  \n",
       "objective                                 binary                        binary  \n",
       "random_state                                  42                            42  \n",
       "reg_alpha                    (0.0, 2.0, uniform)           (0.0, 4.0, uniform)  \n",
       "reg_alpha                                1.95316                      2.993751  \n",
       "reg_lambda                   (0.0, 2.0, uniform)           (0.0, 4.0, uniform)  \n",
       "reg_lambda                              0.049682                      2.911742  \n",
       "scale_pos_weight             (0.2, 2.0, uniform)           (0.2, 2.0, uniform)  \n",
       "scale_pos_weight                        0.729823                      0.599426  \n",
       "scoring                                precision                     precision  \n",
       "scoring                                precision                     precision  \n",
       "silent                                      warn                          warn  \n",
       "subsample                  (0.005, 1.0, uniform)         (0.005, 1.0, uniform)  \n",
       "subsample                               0.534441                           1.0  \n",
       "subsample_for_bin               (100000, 500000)              (100000, 500000)  \n",
       "subsample_for_bin                         281873                        260724  \n",
       "subsample_freq                                 0                             0  \n",
       "verbose                                        0                             0  \n",
       "best_score                               0.65117                      0.716667  \n",
       "best_index                                  19.0                          49.0  \n",
       "acc_train                                  0.675                          0.63  \n",
       "acc_val                                     0.56                          0.58  \n",
       "acc_test                                0.634921                      0.571429  \n",
       "precision                               0.666667                      0.833333  \n",
       "recall                                  0.516129                       0.16129  \n",
       "f1score                                 0.581818                       0.27027  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one = df_combine_sorted(df_base, df_params)\n",
    "df_one.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_1</th>\n",
       "      <th>iter_2</th>\n",
       "      <th>iter_3</th>\n",
       "      <th>iter_4</th>\n",
       "      <th>iter_5</th>\n",
       "      <th>iter_6</th>\n",
       "      <th>iter_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.620157</td>\n",
       "      <td>0.690359</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.645483</td>\n",
       "      <td>0.65117</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.16129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.27027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.56502</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.567036</td>\n",
       "      <td>0.56502</td>\n",
       "      <td>0.650202</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.56502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test1</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              iter_1    iter_2    iter_3    iter_4    iter_5    iter_6   \n",
       "parameter                                                                \n",
       "best_score  0.716667  0.620157  0.690359  0.716667  0.645483   0.65117  \\\n",
       "best_index      49.0      30.0      23.0      49.0      22.0      19.0   \n",
       "acc_train       0.63      0.87      0.76      0.63      0.73     0.675   \n",
       "acc_val         0.58      0.48       0.6      0.58      0.58      0.56   \n",
       "acc_test    0.571429  0.571429  0.571429  0.571429  0.650794  0.634921   \n",
       "precision   0.833333  0.555556  0.642857  0.833333  0.655172  0.666667   \n",
       "recall       0.16129  0.645161  0.290323   0.16129  0.612903  0.516129   \n",
       "f1score      0.27027  0.597015       0.4   0.27027  0.633333  0.581818   \n",
       "roc          0.56502  0.572581  0.567036   0.56502  0.650202  0.633065   \n",
       "tn              31.0      16.0      27.0      31.0      22.0      24.0   \n",
       "fp               1.0      16.0       5.0       1.0      10.0       8.0   \n",
       "fn              26.0      11.0      22.0      26.0      12.0      15.0   \n",
       "tp               5.0      20.0       9.0       5.0      19.0      16.0   \n",
       "acc_test1   0.619048   0.52381   0.47619  0.619048   0.52381  0.571429   \n",
       "precision1       1.0       0.5       0.4       1.0       0.5  0.571429   \n",
       "recall1          0.2       0.5       0.2       0.2       0.5       0.4   \n",
       "f1score1    0.333333       0.5  0.266667  0.333333       0.5  0.470588   \n",
       "roc1             0.6  0.522727  0.463636       0.6  0.522727  0.563636   \n",
       "\n",
       "              iter_7  \n",
       "parameter             \n",
       "best_score  0.716667  \n",
       "best_index      49.0  \n",
       "acc_train       0.63  \n",
       "acc_val         0.58  \n",
       "acc_test    0.571429  \n",
       "precision   0.833333  \n",
       "recall       0.16129  \n",
       "f1score      0.27027  \n",
       "roc          0.56502  \n",
       "tn              31.0  \n",
       "fp               1.0  \n",
       "fn              26.0  \n",
       "tp               5.0  \n",
       "acc_test1   0.619048  \n",
       "precision1       1.0  \n",
       "recall1          0.2  \n",
       "f1score1    0.333333  \n",
       "roc1             0.6  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.iloc[52:70, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space, parameters and results save\n",
    "df_one.to_csv(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.csv')\n",
    "df_one.to_pickle(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 아래 내용은 위의 df_one을 대체함.\n",
    "# parameter and results save\n",
    "df_base.to_csv(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.csv')\n",
    "df_base.to_pickle(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.pkl')\n",
    "\n",
    "# search_space, parameters save\n",
    "df_params.to_csv(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.csv')\n",
    "df_params.to_pickle(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# save model\\n# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\\njoblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\\nsave_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\\njoblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\\nsave_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\\nsave_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# save model\n",
    "# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\n",
    "joblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\n",
    "joblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\n",
    "save_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 가장 좋은 결과 저장\n",
    "save_best_results(com_name, lgbmBS.best_estimator_, scaler, new_col, df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lgbmBS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmBS.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.tail(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:35]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
