{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(model, train_scaled, val_scaled, test_scaled, test_target):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbmgs.best_score_ \n",
    "    result_dict['best_index'] = lgbmgs.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1_score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'df_mobis_sel.pkl'\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "val_scaled = ss.transform(val_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_test= { \n",
    "#     \"num_iterations\": [100, 200, 300, 400, 500],\n",
    "#     \"num_class\": [1]\n",
    "#     \"metric\" : \"rmse\",\n",
    "#     \"bagging_frequency\" : 5,\n",
    "#     \"bagging_seed\" : 2018,\n",
    "#     \"verbosity\" : -1,\n",
    "\n",
    "#     # Selected rounded-off params\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'feature_fraction': 0.1,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 0,\n",
    "#     'max_depth': 9,\n",
    "#     'min_child_weight': 5,\n",
    "#     'min_split_gain': 0,\n",
    "#     'num_leaves': 24 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = {\n",
    "    \"boosting_type\" : ['gbdt'], # ['dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "    \"num_iterations\" : [5], #[450, 500, 550], #\"num_iterations\" \n",
    "    \"learning_rate\": [0.007, 0.008, 0.009, 0.01, 0.015, 0.02], \n",
    "    \"max_depth\": [None, 2, 3, 4], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \"num_leaves\": [2, 3, 4, 5, 6], #  # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "    \"subsample\": [None, 0.001, 0.002],# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \"colsample_bytree\": [ 0.25, 0.3, 0.35, 0.4, 0.45], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    \"objective\": ['binary'],\n",
    "    \"metric\": ['binary_logloss'], # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    \"n_estimators\": [None, 3, 4, 5],\n",
    "    \"max_delta_step\": [0.5, 0.6, 0.7, 0.8, 0.9], # best value found, default = 0\n",
    "    \"scale_pos_weight\": [2], # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "    \n",
    "# ************* 아래 하나씩 테스트해서 취사 선택해야 함. **************\n",
    "#     \"bagging_frequency\" : [5], \n",
    "#     \"early_stopping_rounds\" : [200],\n",
    "#     \"num_threads\": [0], # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "#     \"min_data_in_leaf\": [None], # 과적합 방지 파라미터\n",
    "#     \"lambda_l1\": [0], # default 0\n",
    "#     \"lambda_l2\": [0], #default 0\n",
    "#     \"min_gain_to_split\": [None], # 분기하기 위해 필요한 최소한의 gain을 의미, 정규화시 사용\n",
    "#     \"num_threads\": = 0, # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "#     \"max_bin\": [32],  # data 준비할 때 사용하는 parameter     \n",
    "#     \"is_unbalance\": [1],  # 불균형 셋 조정\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_lr(lr):\n",
    "    \n",
    "    def count_zero(x):\n",
    "        if x < 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x * 10**iter >= 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return iter\n",
    "        elif x >= 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x / 10**iter < 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return -iter\n",
    "    \n",
    "    def back_step(lr, lr_step):\n",
    "        if lr - lr_step*2 <=0 :\n",
    "            tenth = 10**(count_zero(lr)+1)\n",
    "            return int(lr*tenth/3)/tenth, int(lr*tenth/2)/tenth\n",
    "        else:\n",
    "            return lr_step, lr_step*2\n",
    "    \n",
    "    if lr <= 0.001:\n",
    "        lr_step = 0.0002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.01:\n",
    "        lr_step = 0.002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.1:\n",
    "        lr_step = 0.02\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 1:\n",
    "        lr_step = 0.2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 10:\n",
    "        lr_step = 2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    else:\n",
    "        lr_step = 20\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "\n",
    "    return [lr-lr_step_m2, lr-lr_step_m1, lr, lr+lr_step, lr+lr_step*2]\n",
    "\n",
    "def new_depth(depth):\n",
    "    if (depth == None) | (depth <= 2):\n",
    "        new_depth = [None, 1, 2, 3, 4]\n",
    "    elif depth <= 10:\n",
    "        new_depth = [depth-2, depth-1, depth, depth+1, depth+2]\n",
    "    elif depth <= 20:\n",
    "        new_depth = [depth-4, depth-2, depth, depth+2, depth+4]\n",
    "    else:\n",
    "        new_depth = [depth-8, depth-4, depth, depth+4, depth+8]\n",
    "    return new_depth\n",
    "\n",
    "def new_subsample(subsam):\n",
    "    if (subsam == None) | (subsam <= 0.002):\n",
    "        new_subsam = [None, 0.001, 0.002, 0.003]\n",
    "    elif subsam <= 0.01:\n",
    "        step = 0.001\n",
    "    elif subsam <= 0.1:\n",
    "        step = 0.01\n",
    "    elif subsam <= 1:\n",
    "        step = 0.2\n",
    "        \n",
    "    return [subsam-step, subsam, subsam+step]\n",
    "    \n",
    "def make_new_parameter(df_concat):\n",
    "    param_new = {}\n",
    "    param[\"boosting_type\"] = ['gbdt'], \n",
    "    num_i = df_concat.loc[\"num_iterations\"].iloc[0]\n",
    "    param_new[\"num_iterations\"] = [num_i-100, num_i, num_i+100], #새로운 값을 중간에 배치, 100단위로 순서\n",
    "    \n",
    "    lr = df_concat.loc[\"learning_rate\"].iloc[0]\n",
    "    param_new[\"learning_rate\"] = new_lr(lr),\n",
    "    \n",
    "    depth = df_concat.loc[\"max_depth\"].iloc[0]\n",
    "    param_new[\"max_depth\"] = new_depth(depth), # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \n",
    "    leaves = df_concat.loc[\"num_leaves\"].iloc[0]  \n",
    "    param_new[\"num_leaves\"] = new_depth(leaves), #  # 두번째로 중요, num_leaves = 2^max_depth보다 작아야 함. 데이터가 적으면 작은 숫자로\n",
    "    \n",
    "    subsam = df_concat.loc[\"subsample\"].iloc[0]  \n",
    "    param_new[\"subsample\"] = new_subsample(subsam),# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \n",
    "    param_new[\"colsample_bytree\"] = [0.25, 0.3, 0.35, 0.4, 0.45], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    param_new[\"objective\"] = ['binary'],\n",
    "    param_new[\"metric\"] = ['binary_logloss'], # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    param_new[\"n_estimators\"] = [None, 3, 4, 5],\n",
    "    param_new[\"max_delta_step\"] = [0.5, 0.6, 0.7, 0.8, 0.9], # best value found, default = 0\n",
    "    param_new[\"scale_pos_weight\"] = [2], # class imb\n",
    "    \n",
    "    print(\"--------end of parameter setting -------*\")\n",
    "    \n",
    "    return param_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36000 candidates, totalling 180000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[237], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m lgbmgs\u001b[38;5;241m.\u001b[39mfit(train_scaled, train_target, eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     22\u001b[0m df_estimator \u001b[38;5;241m=\u001b[39m make_df_from_estimator(lgbmgs\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mget_params(), \u001b[38;5;28miter\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgbmgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df_result \u001b[38;5;241m=\u001b[39m make_df_from_estimator(result_dict, \u001b[38;5;28miter\u001b[39m)\n\u001b[0;32m     26\u001b[0m df_concat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_estimator, df_result])\n",
      "Cell \u001b[1;32mIn[226], line 12\u001b[0m, in \u001b[0;36mcalc_results\u001b[1;34m(model, train_scaled, val_scaled, test_scaled, test_target)\u001b[0m\n\u001b[0;32m     10\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m precision_score(test_target, y_predict)\n\u001b[0;32m     11\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m recall_score(test_target, y_predict)\n\u001b[1;32m---> 12\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m roc_auc_score(test_target, y_predict)\n\u001b[0;32m     14\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(test_target, y_predict)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmgs = None\n",
    "\n",
    "    lgbm = lightgbm.LGBMClassifier( random_state=42)\n",
    "\n",
    "    lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                          param_grid = params_o,\n",
    "                          cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "    #                       scoring = 'precision', \n",
    "                          scoring = 'accuracy', \n",
    "                          error_score='raise',\n",
    "                          verbose = 1,\n",
    "                          n_jobs=-1, # 자동 검색 적용\n",
    "                          )\n",
    "\n",
    "    lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') # \n",
    "\n",
    "    df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1_score = df_concat.loc['f1_score'].iloc[0]\n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1_score >= 0.6) :\n",
    "        break\n",
    "    print(\"********Processing*********\")\n",
    "    params_o = make_new_parameter(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36000 candidates, totalling 180000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "iter =0 \n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmgs = None\n",
    "\n",
    "lgbm = lightgbm.LGBMClassifier( random_state=42)\n",
    "\n",
    "lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                      param_grid = params_o,\n",
    "                      cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "#                       scoring = 'precision', \n",
    "                      scoring = 'accuracy', \n",
    "                      error_score='raise',\n",
    "                      verbose = 1,\n",
    "                      n_jobs=-1, # 자동 검색 적용\n",
    "                      )\n",
    "\n",
    "lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') # \n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "df_result = make_df_from_estimator(result_dict, iter)\n",
    "df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: LGBMClassifier(colsample_bytree=0.4, learning_rate=0.02, max_delta_step=0.8,\n",
      "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
      "               num_iterations=450, num_leaves=3, objective='binary',\n",
      "               random_state=42, scale_pos_weight=2, subsample=None)\n",
      "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.02, 'max_delta_step': 0.8, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 450, 'num_leaves': 3, 'objective': 'binary', 'scale_pos_weight': 2, 'subsample': None}\n",
      "Best Score: 0.7913043478260869, Best Index: 84963\n",
      "train accuracy: 0.9826, val accuracy 0.8621, test accuracy 0.7568\n",
      "precision : 0.6667, recall : 0.7143, f1score : 0.6897, roc : 0.7484\n",
      "[[18  5]\n",
      " [ 4 10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Estimator: {}\".format(lgbmgs.best_estimator_)) \n",
    "print(\"Best Parameters: {}\".format(lgbmgs.best_params_))  # 최적 파라미터.\n",
    "print('Best Score: {}, Best Index: {}'.format(lgbmgs.best_score_ , lgbmgs.best_index_))  # 교차검증된 점수를 보여줌.\n",
    "\n",
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_pred = model.predict(test_scaled)\n",
    "\n",
    "train_score = model.score(train_scaled, train_target)\n",
    "val_score = model.score(val_scaled, val_target)\n",
    "test_score = model.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, model.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, model.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score, val_score, test_score))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.feature_importances_, index=data.columns, columns=['importance']).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.49140919e+02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.35120301e+01,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.23260339e+02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.20273995e+01, 0.00000000e+00,\n",
       "       2.80728006e+00, 2.73849804e+01, 1.42234201e+01, 0.00000000e+00,\n",
       "       7.20145903e+01, 5.59528667e+02, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.73015022e+00, 4.21148602e+03,\n",
       "       1.57456562e+03, 1.76724701e+01, 0.00000000e+00])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최초의 empty df 생성\n",
    "# df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[239], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_estimator \u001b[38;5;241m=\u001b[39m make_df_from_estimator(lgbmgs\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mget_params(), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlgbmgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_result \u001b[38;5;241m=\u001b[39m make_df_from_estimator(result_dict, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_concat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_estimator, df_result])\n",
      "Cell \u001b[1;32mIn[226], line 12\u001b[0m, in \u001b[0;36mcalc_results\u001b[1;34m(model, train_scaled, val_scaled, test_scaled, test_target)\u001b[0m\n\u001b[0;32m     10\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m precision_score(test_target, y_predict)\n\u001b[0;32m     11\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m recall_score(test_target, y_predict)\n\u001b[1;32m---> 12\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m roc_auc_score(test_target, y_predict)\n\u001b[0;32m     14\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(test_target, y_predict)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), 1)\n",
    "result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "df_result = make_df_from_estimator(result_dict, 1)\n",
    "df_concat = pd.concat([df_estimator, df_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_delta_step</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.686957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.686957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value1\n",
       "parameter                        \n",
       "boosting_type                gbdt\n",
       "class_weight                 None\n",
       "colsample_bytree             0.25\n",
       "importance_type             split\n",
       "learning_rate               0.007\n",
       "max_depth                    None\n",
       "min_child_samples              20\n",
       "min_child_weight            0.001\n",
       "min_split_gain                0.0\n",
       "n_estimators                 None\n",
       "n_jobs                         -1\n",
       "num_leaves                      2\n",
       "objective                  binary\n",
       "random_state                   42\n",
       "reg_alpha                     0.0\n",
       "reg_lambda                    0.0\n",
       "silent                       warn\n",
       "subsample                    None\n",
       "subsample_for_bin          200000\n",
       "subsample_freq                  0\n",
       "max_delta_step                0.5\n",
       "metric             binary_logloss\n",
       "num_iterations                  5\n",
       "scale_pos_weight                2\n",
       "best_score               0.686957\n",
       "best_index                    0.0\n",
       "acc_train                0.686957\n",
       "acc_val                  0.689655\n",
       "acc_test                 0.621622\n",
       "precision                     0.0\n",
       "recall                        0.0\n",
       "f1_score                      0.0\n",
       "roc                           0.5\n",
       "tn                           23.0\n",
       "fp                            0.0\n",
       "fn                           14.0\n",
       "tp                            0.0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_delta_step</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.686957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.686957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value1\n",
       "boosting_type                gbdt\n",
       "class_weight                 None\n",
       "colsample_bytree             0.25\n",
       "importance_type             split\n",
       "learning_rate               0.007\n",
       "max_depth                    None\n",
       "min_child_samples              20\n",
       "min_child_weight            0.001\n",
       "min_split_gain                0.0\n",
       "n_estimators                 None\n",
       "n_jobs                         -1\n",
       "num_leaves                      2\n",
       "objective                  binary\n",
       "random_state                   42\n",
       "reg_alpha                     0.0\n",
       "reg_lambda                    0.0\n",
       "silent                       warn\n",
       "subsample                    None\n",
       "subsample_for_bin          200000\n",
       "subsample_freq                  0\n",
       "max_delta_step                0.5\n",
       "metric             binary_logloss\n",
       "num_iterations                  5\n",
       "scale_pos_weight                2\n",
       "best_score               0.686957\n",
       "best_index                    0.0\n",
       "acc_train                0.686957\n",
       "acc_val                  0.689655\n",
       "acc_test                 0.621622\n",
       "precision                     0.0\n",
       "recall                        0.0\n",
       "f1_score                      0.0\n",
       "roc                           0.5\n",
       "tn                           23.0\n",
       "fp                            0.0\n",
       "fn                           14.0\n",
       "tp                            0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.index =['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type',\n",
    "       'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight',\n",
    "       'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective',\n",
    "       'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample',\n",
    "       'subsample_for_bin', 'subsample_freq', 'max_delta_step', 'metric',\n",
    "       'num_iterations', 'scale_pos_weight', 'best_score', 'best_index',\n",
    "       'acc_train', 'acc_val', 'acc_test', 'precision', 'recall', 'f1_score',\n",
    "       'roc', 'tn', 'fp', 'fn', 'tp']\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = [df_estimator, df_result]\n",
    "# df_merged= reduce(lambda  left,right: pd.merge(left,right, how='outer', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 34560 candidates, totalling 172800 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, learning_rate=0.006, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.006, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8159420289855073, Best Index: 30690\n",
    "train accuracy: 0.8487, val accuracy 0.7667, test accuracy 0.7895\n",
    "precision : 0.8182, recall : 0.6000, f1score : 0.6923, roc : 0.7565\n",
    "[[21  2]\n",
    " [ 6  9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobis\n",
    "Fitting 5 folds for each of 34560 candidates, totalling 172800 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.007, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.007, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7652173913043478, Best Index: 4770\n",
    "train accuracy: 0.8174, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 1.0000, recall : 0.3571, f1score : 0.5263, roc : 0.6786\n",
    "[[23  0]\n",
    " [ 9  5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.007, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.007, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7652173913043478, Best Index: 18585\n",
    "train accuracy: 0.8174, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 1.0000, recall : 0.3571, f1score : 0.5263, roc : 0.6786\n",
    "[[23  0]\n",
    " [ 9  5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.007, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.007, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7652173913043478, Best Index: 18585\n",
    "train accuracy: 0.8174, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 1.0000, recall : 0.3571, f1score : 0.5263, roc : 0.6786\n",
    "[[23  0]\n",
    " [ 9  5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.008, max_delta_step=0.7,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=4, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.008, 'max_delta_step': 0.7, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 4, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.773913043478261, Best Index: 20319\n",
    "train accuracy: 0.9217, val accuracy 0.8966, test accuracy 0.7027\n",
    "precision : 0.7143, recall : 0.3571, f1score : 0.4762, roc : 0.6351\n",
    "[[21  2]\n",
    " [ 9  5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Estimator: LGBMClassifier(colsample_bytree=0.35, learning_rate=0.01, max_delta_step=0.8,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=550, num_leaves=4, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.35, 'learning_rate': 0.01, 'max_delta_step': 0.8, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 550, 'num_leaves': 4, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7826086956521741, Best Index: 106596\n",
    "train accuracy: 0.9826, val accuracy 0.8966, test accuracy 0.7568\n",
    "precision : 0.7273, recall : 0.5714, f1score : 0.6400, roc : 0.7205\n",
    "[[20  3]\n",
    " [ 6  8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Estimator: LGBMClassifier(colsample_bytree=0.4, learning_rate=0.02, max_delta_step=0.8,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=450, num_leaves=3, objective='binary',\n",
    "               random_state=42, scale_pos_weight=2, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.02, 'max_delta_step': 0.8, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 450, 'num_leaves': 3, 'objective': 'binary', 'scale_pos_weight': 2, 'subsample': None}\n",
    "Best Score: 0.7913043478260869, Best Index: 84963\n",
    "train accuracy: 0.9826, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 0.6667, recall : 0.7143, f1score : 0.6897, roc : 0.7484\n",
    "[[18  5]\n",
    " [ 4 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_delta_step</th>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.791304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>84963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.982609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.748447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value3\n",
       "parameter                        \n",
       "boosting_type                gbdt\n",
       "class_weight                 None\n",
       "colsample_bytree              0.4\n",
       "importance_type             split\n",
       "learning_rate                0.02\n",
       "max_depth                    None\n",
       "min_child_samples              20\n",
       "min_child_weight            0.001\n",
       "min_split_gain                0.0\n",
       "n_estimators                 None\n",
       "n_jobs                         -1\n",
       "num_leaves                      3\n",
       "objective                  binary\n",
       "random_state                   42\n",
       "reg_alpha                     0.0\n",
       "reg_lambda                    0.0\n",
       "silent                       warn\n",
       "subsample                    None\n",
       "subsample_for_bin          200000\n",
       "subsample_freq                  0\n",
       "max_delta_step                0.8\n",
       "metric             binary_logloss\n",
       "num_iterations                450\n",
       "scale_pos_weight                2\n",
       "best_score               0.791304\n",
       "best_index                84963.0\n",
       "acc_train                0.982609\n",
       "acc_val                  0.862069\n",
       "acc_test                 0.756757\n",
       "precision                0.666667\n",
       "recall                   0.714286\n",
       "f1score                  0.689655\n",
       "roc                      0.748447\n",
       "tn                           18.0\n",
       "fp                            5.0\n",
       "fn                            4.0\n",
       "tp                           10.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def nlr(lr):\n",
    "    \n",
    "    def count_zero(x):\n",
    "        if x < 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x * 10**iter >= 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return iter\n",
    "        elif x >= 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x / 10**iter < 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return -iter\n",
    "    \n",
    "    def back_step(lr, lr_step):\n",
    "        if lr - lr_step*2 <=0 :\n",
    "            tenth = 10**(count_zero(lr)+1)\n",
    "            return int(lr*tenth/3)/tenth, int(lr*tenth/2)/tenth\n",
    "        else:\n",
    "            return lr_step, lr_step*2\n",
    "    \n",
    "    if lr <= 0.001:\n",
    "        lr_step = 0.0002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.01:\n",
    "        lr_step = 0.002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.1:\n",
    "        lr_step = 0.02\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 1:\n",
    "        lr_step = 0.2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 10:\n",
    "        lr_step = 2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    else:\n",
    "        lr_step = 20\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "\n",
    "    return [lr-lr_step_m2, lr-lr_step_m1, lr, lr+lr_step, lr+lr_step*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0006000000000000001, 0.0008, 0.001, 0.0012000000000000001, 0.0014]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlr(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttt 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr= 0.003\n",
    "lr_step = 0.002\n",
    "tenth = 10**(count_zero(lr)+1)\n",
    "print(\"ttt\", tenth)\n",
    "int(lr*tenth/3)/tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_step(lr, lr_step):\n",
    "    if lr - lr_step*2 <=0 :\n",
    "        print(\"88\")\n",
    "        tenth = 10**(count_zero(lr)+1)\n",
    "        return int(lr*tenth/3)/tenth\n",
    "    else:\n",
    "        return lr_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0006"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = back_step(lr, lr_step)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_lr(lr):\n",
    "    if lr <= 0.0004:\n",
    "        return [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]\n",
    "    elif lr <= 0.0005:\n",
    "        lr_step = 0.0002\n",
    "    elif lr <= 0.004:\n",
    "        return [0.001, 0.002, 0.003, 0.004, 0.005]\n",
    "    elif lr <= 0.005:\n",
    "        lr_step = 0.002\n",
    "    elif lr <= 0.1:\n",
    "        lr_step = 0.02\n",
    "    elif lr <= 1:\n",
    "        lr_step = 0.2\n",
    "    elif lr <= 10:\n",
    "        lr_step = 2\n",
    "    else:\n",
    "        lr_step = 20\n",
    "    if (lr-lr_step) <= 0:\n",
    "        return [lr, lr+lr_step, lr+lr_step*2]\n",
    "    else:\n",
    "        return [lr-lr_step*2, lr-lr_step, lr, lr+lr_step, lr+lr_step*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.001, 0.001, 0.003, 0.005, 0.007]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.002\n",
    "lr_step = 0.0002\n",
    "np.linspace(lr-lr, lr+lr_step*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            tenth = 10**(count_zero(lr)+1)\n",
    "            return int(lr*tenth/3)/tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_s,lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  5.71428571, 11.42857143, 17.14285714, 22.85714286,\n",
       "       28.57142857, 34.28571429])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,1*4,7, endpoint=False)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.75, 1.5 , 2.25, 3.  ])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.003\n",
    "np.linspace(0, a*1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero(x):\n",
    "    if x*10 >= 1:\n",
    "        return 1\n",
    "    elif x*100 >= 1:\n",
    "        return 2\n",
    "    elif x*1000 >= 1 :\n",
    "        return 3\n",
    "    elif x*10000 >= 1 :\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zero(x):\n",
    "    if x < 1:\n",
    "        iter = 1\n",
    "        while True:\n",
    "            if x * 10**iter >= 1:\n",
    "                break\n",
    "            iter = iter+1\n",
    "        return iter\n",
    "    elif x >= 1:\n",
    "        iter = 1\n",
    "        while True:\n",
    "            if x / 10**iter < 1:\n",
    "                break\n",
    "            iter = iter+1\n",
    "        return -iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_zero(.010011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t(x):\n",
    "    def y(x):\n",
    "        if x > 10:\n",
    "            return 5\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return y(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my\u001b[49m(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_subsample(subsam):\n",
    "    if (subsam == None) | (subsam <= 0.002):\n",
    "        new_subsam = [None, 0.001, 0.002, 0.003]\n",
    "    elif subsam <= 0.01:\n",
    "        step = 0.001\n",
    "    elif subsam <= 0.1:\n",
    "        step = 0.01\n",
    "    elif subsam <= 1:\n",
    "        step = 0.2\n",
    "        \n",
    "    return [subsam-step, subsam, subsam+step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
