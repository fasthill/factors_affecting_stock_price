{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'df_shgroup_sel.pkl'\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "val_scaled = ss.transform(val_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test= { \n",
    "    \"num_iterations\": [100, 200, 300, 400, 500],\n",
    "    \"num_class\": [1]\n",
    "    \"metric\" : \"rmse\",\n",
    "    \"bagging_frequency\" : 5,\n",
    "    \"bagging_seed\" : 2018,\n",
    "    \"verbosity\" : -1,\n",
    "\n",
    "    # Selected rounded-off params\n",
    "    'bagging_fraction': 0.7,\n",
    "    'feature_fraction': 0.1,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 0,\n",
    "    'max_depth': 9,\n",
    "    'min_child_weight': 5,\n",
    "    'min_split_gain': 0,\n",
    "    'num_leaves': 24 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2880 candidates, totalling 14400 fits\n",
      "Best Estimator: LGBMClassifier(colsample_bytree=0.34, learning_rate=0.006, max_delta_step=0.5,\n",
      "               max_depth=None, metric='loss', n_estimators=None,\n",
      "               num_iterations=1000, num_leaves=2, objective='binary',\n",
      "               random_state=42, subsample=None)\n",
      "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.34, 'learning_rate': 0.006, 'max_depth': None, 'metric': 'loss', 'n_estimators': None, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
      "Best Score: 0.798913043478261, Best Index: 0\n",
      "train accuracy: 0.8739, val accuracy 0.7667, test accuracy 0.7895\n",
      "precision : 0.8182, recall : 0.6000, f1score : 0.6923, roc : 0.7565\n",
      "[[21  2]\n",
      " [ 6  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "params_o = {\n",
    "    \"boosting_type\" : ['gbdt'],\n",
    "    \"max_depth\": [None, 2, 3, 4],\n",
    "    \"num_leaves\": [2, 3, 4],\n",
    "#     num_leaves 는 10 (왜냐면 작은 데이터이기 때문)\n",
    "    \"learning_rate\": [ 0.006, 0.007, 0.008, 0.01],\n",
    "    \"objective\": ['binary'],\n",
    "#     \"metric\": ['loss'],\n",
    "    \"metric\": ['binary_logloss'],\n",
    "    \"colsample_bytree\": [ 0.34, 0.35, 0.36, 0.37, 0.38],\n",
    "    \"subsample\": [None, 0.001, 0.002],\n",
    "    \"n_estimators\": [None, 3, 4, 5],\n",
    "#     min_data_in_leaf : 큰 값으로 세팅하는 것은 Tree가 너무 깊게 확장되는 것을 막을 수 있지만 \n",
    "#     under-fitting 언더 피팅이 발생할 수도 있습니다.\n",
    "    \n",
    "}\n",
    "\n",
    "lgbm = None\n",
    "lgbmgs = None\n",
    "\n",
    "lgbm = lightgbm.LGBMClassifier( random_state=42, \n",
    "                               learning_rate =0.22, # default = 0.1\n",
    "                               num_iterations=1000, # default=100\n",
    "                               max_depth=5, # <= 0 means no limit, default=-1\n",
    "#                                bagging_fraction=0.9, # 0.0 < bagging_fraction <= 1.0, default=1\n",
    "#                                feature_fraction=0.8, # 0.0 < feature_fraction <= 1.0, default=1\n",
    "                               objective= 'binary', \n",
    "#                                num_threads = 0, # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "                               max_delta_step = 0.5 # best value found, default = 0\n",
    "#                                scale_pos_weight=40, # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "                               \n",
    "                                )\n",
    "\n",
    "lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                      param_grid = params_o,\n",
    "                      cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "#                       scoring = 'precision', \n",
    "                      scoring = 'accuracy', \n",
    "                      verbose = 1,\n",
    "                      n_jobs=-1, # 자동 검색 적용\n",
    "                      )\n",
    "\n",
    "lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss')\n",
    "    \n",
    "print(\"Best Estimator: {}\".format(lgbmgs.best_estimator_)) \n",
    "print(\"Best Parameters: {}\".format(lgbmgs.best_params_))  # 최적 파라미터.\n",
    "print('Best Score: {}, Best Index: {}'.format(lgbmgs.best_score_ , lgbmgs.best_index_))  # 교차검증된 점수를 보여줌.\n",
    "\n",
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_pred = model.predict(test_scaled)\n",
    "\n",
    "train_score = model.score(train_scaled, train_target)\n",
    "val_score = model.score(val_scaled, val_target)\n",
    "test_score = model.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, model.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, model.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score, val_score, test_score))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.feature_importances_, index=data.columns, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)\n",
    "df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['mean_test_score', 'std_test_score']:\n",
    "        print(i,\" : \", gsearch1.cv_results_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.34, learning_rate=0.006, max_delta_step=0.5,\n",
       "               max_depth=None, metric=&#x27;loss&#x27;, n_estimators=None,\n",
       "               num_iterations=1000, num_leaves=2, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, subsample=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.34, learning_rate=0.006, max_delta_step=0.5,\n",
       "               max_depth=None, metric=&#x27;loss&#x27;, n_estimators=None,\n",
       "               num_iterations=1000, num_leaves=2, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, subsample=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.34, learning_rate=0.006, max_delta_step=0.5,\n",
       "               max_depth=None, metric='loss', n_estimators=None,\n",
       "               num_iterations=1000, num_leaves=2, objective='binary',\n",
       "               random_state=42, subsample=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최초의 empty df 생성\n",
    "# df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = make_df_from_estimator(result_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_estimator, df_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = [df_estimator, df_result]\n",
    "# df_merged= reduce(lambda  left,right: pd.merge(left,right, how='outer', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_delta_step</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.798913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.87395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.756522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     value1\n",
       "parameter                  \n",
       "boosting_type          gbdt\n",
       "class_weight           None\n",
       "colsample_bytree       0.34\n",
       "importance_type       split\n",
       "learning_rate         0.006\n",
       "max_depth              None\n",
       "min_child_samples        20\n",
       "min_child_weight      0.001\n",
       "min_split_gain          0.0\n",
       "n_estimators           None\n",
       "n_jobs                   -1\n",
       "num_leaves                2\n",
       "objective            binary\n",
       "random_state             42\n",
       "reg_alpha               0.0\n",
       "reg_lambda              0.0\n",
       "silent                 warn\n",
       "subsample              None\n",
       "subsample_for_bin    200000\n",
       "subsample_freq            0\n",
       "num_iterations         1000\n",
       "max_delta_step          0.5\n",
       "metric                 loss\n",
       "best_score         0.798913\n",
       "best_index              0.0\n",
       "acc_train           0.87395\n",
       "acc_val            0.766667\n",
       "acc_test           0.789474\n",
       "precision          0.818182\n",
       "recall                  0.6\n",
       "f1score            0.692308\n",
       "roc                0.756522\n",
       "tn                     21.0\n",
       "fp                      2.0\n",
       "fn                      6.0\n",
       "tp                      9.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_estimator, df_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estimator: {}\".format(lgbmgs.best_estimator_)) \n",
    "print(\"Best Parameters: {}\".format(lgbmgs.best_params_))  # 최적 파라미터.\n",
    "print('Best Score: {}, Best Index: {}'.format(lgbmgs.best_score_ , lgbmgs.best_index_))  # 교차검증된 점수를 보여줌.\n",
    "\n",
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_pred = model.predict(test_scaled)\n",
    "\n",
    "train_score = model.score(train_scaled, train_target)\n",
    "val_score = model.score(val_scaled, val_target)\n",
    "test_score = model.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, model.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, model.predict(test_scaled))\n",
    "\n",
    "train accuracy: 0.8739, val accuracy 0.7667, test accuracy 0.7895\n",
    "precision : 0.8182, recall : 0.6000, f1score : 0.6923, roc : 0.7565\n",
    "[[21  2]\n",
    " [ 6  9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best Score: 0.798913043478261, Best Index: 0\n",
    "train accuracy: 0.8739, val accuracy 0.7667, test accuracy 0.7895\n",
    "precision : 0.8182, recall : 0.6000, f1score : 0.6923, roc : 0.7565\n",
    "[[21  2]\n",
    " [ 6  9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_predict = model.predict(test_scaled)\n",
    "result_dict= {}\n",
    "result_dict['best_score'] = lgbmgs.best_score_ \n",
    "result_dict['best_index'] = lgbmgs.best_index_\n",
    "result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "cm = confusion_matrix(test_target, y_predict)\n",
    "result_dict['tn'] = cm[0,0]\n",
    "result_dict['fp'] = cm[0,1]\n",
    "result_dict['fn'] = cm[1,0]\n",
    "result_dict['tp'] = cm[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = make_df_from_estimator(result_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.798913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.873950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.756522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               value1\n",
       "parameter            \n",
       "best_score   0.798913\n",
       "best_index   0.000000\n",
       "acc_train    0.873950\n",
       "acc_val      0.766667\n",
       "acc_test     0.789474\n",
       "precision    0.818182\n",
       "recall       0.600000\n",
       "f1score      0.692308\n",
       "roc          0.756522\n",
       "tn          21.000000\n",
       "fp           2.000000\n",
       "fn           6.000000\n",
       "tp           9.000000"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798913043478261"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmgs.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_.values()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_target, model.predict(test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 튜닝 :\n",
    "\n",
    "데이터 사이언티스트는 언제나 어떤 파라미터를 언제 사용할지 그리고 어떤 값이 최적의 파라미터 값일지 결정하기 위해 고민합니다.\n",
    "\n",
    "아래 소개되는 기법들은 모델 정확도를 향상시키기 위해 사용될 수 있습니다.\n",
    "\n",
    "num_leaves : Tree 모델의 복잡성을 컨트롤하는 주요 파라미터입니다. 이상적으로 num_leaves 값은 2 ^ (max_depth) 값보다 적거나 같아야 합니다. 이것보다 많은 값은 과적합을 유발할 것입니다.\n",
    "min_data_in_leaf : 큰 값으로 세팅하는 것은 Tree가 너무 깊게 확장되는 것을 막을 수 있지만 under-fitting 언더 피팅이 발생할 수도 있습니다. 관행적으로, 수백 또는 수천 개로 정하는 것이 큰 데이터 세트에 충분합니다.\n",
    "max_depth : Tree 깊이를 명확하게 제한하기 위해 max_depth 값을 설정할 수도 있습니다.\n",
    "더 빠른 속도를 위하여 :\n",
    "\n",
    "bagging_fraction과 baggin_freq 을 설정하여 bagging 을 적용하십시오\n",
    "feature_fraction을 설정하여 feature sub-sampling을 하십시오\n",
    "작은 max_bin 값을 사용하십시오\n",
    "save_binary 를 값을 통해 다가오는 학습에서 데이터 로딩 속도를 줄이십시오\n",
    "parallel learning 병렬 학습을 적용하십시오\n",
    "더 나은 정확도를 위해 :\n",
    "\n",
    "큰 max_bin 값을 사용하십시오 (아마 속도는 느려질 수 있습니다)\n",
    "작은 learning_rate 값을 큰 num_iterations 값과 함께 사용하십시오\n",
    "큰 num_leaves 값을 사용하십시오 (아마 과적합을 유발할 수도 있습니다)\n",
    "더 큰 트레이닝 데이터를 사용하십시오\n",
    "dart 를 사용하십시오\n",
    "범주형 feature를 사용하십시오\n",
    "과적합을 해결하기 위해 :\n",
    "\n",
    "작은 max_bin 값을 사용하십시오\n",
    "작은 num_leaves 값을 사용하십시오\n",
    "min_data_in_leaf 와 min_sum_hessian_in_leaf 파라미터를 사용하십시오\n",
    "bagging_fraction 과 bagging_freq 을 사용하여 bagging 을 적용하십시오\n",
    "feature_fraction을 세팅하여 feature sub-sampling을 하십시오\n",
    "lambda_l1, lambda_l2 그리고 min_gain_to_split 파라미터를 이용해 regularization (정규화) 를 적용하십시오\n",
    "max_depth 를 설정해 Deep Tree 가 만들어지는 것을 방지하십시오"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
