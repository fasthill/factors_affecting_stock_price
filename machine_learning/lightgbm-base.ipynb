{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(model, train_scaled, val_scaled, test_scaled, test_target):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbmgs.best_score_ \n",
    "    result_dict['best_index'] = lgbmgs.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'df_mobis_sel.pkl'\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "val_scaled = ss.transform(val_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_test= { \n",
    "#     \"num_iterations\": [100, 200, 300, 400, 500],\n",
    "#     \"num_class\": [1]\n",
    "#     \"metric\" : \"rmse\",\n",
    "#     \"bagging_frequency\" : 5,\n",
    "#     \"bagging_seed\" : 2018,\n",
    "#     \"verbosity\" : -1,\n",
    "\n",
    "#     # Selected rounded-off params\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'feature_fraction': 0.1,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 0,\n",
    "#     'max_depth': 9,\n",
    "#     'min_child_weight': 5,\n",
    "#     'min_split_gain': 0,\n",
    "#     'num_leaves': 24 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = {\n",
    "    \"boosting_type\" : ['gbdt'], # ['dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "    \"num_iterations\" : [100], #[450, 500, 550], #\"num_iterations\" \n",
    "    \"learning_rate\": [0.007, 0.008, 0.009, 0.01, 0.015, 0.02], \n",
    "    \"max_depth\": [None, 2, 3, 4], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \"num_leaves\": [2, 3, 4, 5, 6], #  # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "    \"subsample\": [None, 0.001, 0.002],# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \"colsample_bytree\": [ 0.25, 0.3, 0.35, 0.4, 0.45], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    \"objective\": ['binary'],\n",
    "    \"metric\": ['binary_logloss'], # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    \"n_estimators\": [None, 3, 4, 5],\n",
    "    \"max_delta_step\": [0.5, 0.6, 0.7, 0.8, 0.9], # best value found, default = 0\n",
    "    \"scale_pos_weight\": [2], # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "    \n",
    "# ************* 아래 하나씩 테스트해서 취사 선택해야 함. **************\n",
    "#     \"bagging_frequency\" : [5], \n",
    "#     \"early_stopping_rounds\" : [200],\n",
    "#     \"num_threads\": [0], # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "#     \"min_data_in_leaf\": [None], # 과적합 방지 파라미터\n",
    "#     \"lambda_l1\": [0], # default 0\n",
    "#     \"lambda_l2\": [0], #default 0\n",
    "#     \"min_gain_to_split\": [None], # 분기하기 위해 필요한 최소한의 gain을 의미, 정규화시 사용\n",
    "#     \"num_threads\": = 0, # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "#     \"max_bin\": [32],  # data 준비할 때 사용하는 parameter     \n",
    "#     \"is_unbalance\": [1],  # 불균형 셋 조정\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_num_iter(num_i):\n",
    "    if num_i <= 10:\n",
    "        new_num = [10, 50, 100]\n",
    "    elif num_i <= 100:\n",
    "        new_num = [50, 100, 150, 200]\n",
    "    elif num_i <= 200:\n",
    "        new_num = [150, 200, 300]\n",
    "    else:\n",
    "        new_num = [num_i - 100, num_i, num_i + 100]\n",
    "    return new_num\n",
    "\n",
    "def new_lr(lr):\n",
    "    \n",
    "    def count_zero(x):\n",
    "        if x < 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x * 10**iter >= 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return iter\n",
    "        elif x >= 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x / 10**iter < 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return -iter\n",
    "    \n",
    "    def back_step(lr, lr_step):\n",
    "        if lr - lr_step*2 <=0 :\n",
    "            tenth = 10**(count_zero(lr)+1)\n",
    "            return int(lr*tenth/3)/tenth, int(lr*tenth/2)/tenth\n",
    "        else:\n",
    "            return lr_step, lr_step*2\n",
    "    \n",
    "    if lr <= 0.001:\n",
    "        lr_step = 0.0002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.01:\n",
    "        lr_step = 0.002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.1:\n",
    "        lr_step = 0.02\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 1:\n",
    "        lr_step = 0.2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 10:\n",
    "        lr_step = 2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    else:\n",
    "        lr_step = 20\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "\n",
    "    return [lr-lr_step_m2, lr-lr_step_m1, lr, lr+lr_step, lr+lr_step*2]\n",
    "\n",
    "def new_depth(depth):\n",
    "    if depth == None:\n",
    "        new_depth = [None, 1, 2, 3, 4]\n",
    "    elif depth <= 2:\n",
    "        new_depth = [None, 1, 2, 3, 4]\n",
    "    elif depth <= 10:\n",
    "        new_depth = [depth-2, depth-1, depth, depth+1, depth+2]\n",
    "    elif depth <= 20:\n",
    "        new_depth = [depth-4, depth-2, depth, depth+2, depth+4]\n",
    "    else:\n",
    "        new_depth = [depth-8, depth-4, depth, depth+4, depth+8]\n",
    "    return new_depth\n",
    "\n",
    "def new_leaves(leaves):\n",
    "    if leaves == None:\n",
    "        new_leaves = [2, 3, 4]\n",
    "    elif leaves <= 3:\n",
    "        new_leaves = [2, 3, 4]\n",
    "    elif leaves <= 10:\n",
    "        new_leaves = [leaves-2, leaves-1, leaves, leaves+1, leaves+2]\n",
    "    elif leaves <= 20:\n",
    "        new_leaves = [leaves-4, leaves-2, leaves, leaves+2, leaves+4]\n",
    "    else:\n",
    "        new_leaves = [leaves-8, leaves-4, leaves, leaves+4, leaves+8]\n",
    "    return new_leaves\n",
    "\n",
    "def new_subsample(subsam):\n",
    "    if subsam == None:\n",
    "        return [None, 0.001, 0.002, 0.003]\n",
    "    elif subsam <= 0.002:\n",
    "        return [None, 0.001, 0.002, 0.003]\n",
    "    elif subsam <= 0.01:\n",
    "        step = 0.001\n",
    "    elif subsam <= 0.1:\n",
    "        step = 0.01\n",
    "    elif subsam <= 1:\n",
    "        step = 0.2\n",
    "        \n",
    "    return [subsam-step, subsam, subsam+step]\n",
    "    \n",
    "def make_new_parameter(params_o, df_concat):\n",
    "    param_new = {}\n",
    "    param_new[\"boosting_type\"] = ['gbdt']\n",
    "    \n",
    "    num_i = df_concat.loc[\"num_iterations\"].iloc[0]\n",
    "    param_new[\"num_iterations\"] = new_num_iter(num_i) #새로운 값을 중간에 배치, 100단위로 순서\n",
    "    \n",
    "    lr = df_concat.loc[\"learning_rate\"].iloc[0]\n",
    "    param_new[\"learning_rate\"] = new_lr(lr)\n",
    "    \n",
    "    depth = df_concat.loc[\"max_depth\"].iloc[0]\n",
    "    param_new[\"max_depth\"] = new_depth(depth) # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \n",
    "    leaves = df_concat.loc[\"num_leaves\"].iloc[0]  \n",
    "    param_new[\"num_leaves\"] = new_leaves(leaves) #  # 두번째로 중요, num_leaves = 2^max_depth보다 작아야 함. 데이터가 적으면 작은 숫자로\n",
    "    \n",
    "    subsam = df_concat.loc[\"subsample\"].iloc[0]  \n",
    "    param_new[\"subsample\"] = new_subsample(subsam) # 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \n",
    "    param_new[\"colsample_bytree\"] = [0.25, 0.3, 0.35, 0.4, 0.45] # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    param_new[\"objective\"] = ['binary']\n",
    "    param_new[\"metric\"] = ['binary_logloss'] # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    param_new[\"n_estimators\"] = [None, 3, 4, 5]\n",
    "    param_new[\"max_delta_step\"] = [0.5, 0.6, 0.7, 0.8, 0.9] # best value found, default = 0\n",
    "    param_new[\"scale_pos_weight\"] = [2] # class imb\n",
    "    \n",
    "    print(\"--------end of parameter setting -------*\")\n",
    "    \n",
    "    return param_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36000 candidates, totalling 180000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 90000 candidates, totalling 450000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 200000 candidates, totalling 1000000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: andom_state\n",
      "********Processing*********\n",
      "--------end of parameter setting -------*\n",
      "Fitting 5 folds for each of 150000 candidates, totalling 750000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 20\u001b[0m\n\u001b[0;32m      8\u001b[0m lgbm \u001b[38;5;241m=\u001b[39m lightgbm\u001b[38;5;241m.\u001b[39mLGBMClassifier( andom_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     10\u001b[0m lgbmgs \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m lgbm,\n\u001b[0;32m     11\u001b[0m                       param_grid \u001b[38;5;241m=\u001b[39m params_o,\n\u001b[0;32m     12\u001b[0m                       cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;66;03m# StratifiedKFold us default for binary or multiclass\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m                       n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# 자동 검색 적용\u001b[39;00m\n\u001b[0;32m     18\u001b[0m                       )\n\u001b[1;32m---> 20\u001b[0m \u001b[43mlgbmgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     22\u001b[0m df_estimator \u001b[38;5;241m=\u001b[39m make_df_from_estimator(lgbmgs\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mget_params(), \u001b[38;5;28miter\u001b[39m)\n\u001b[0;32m     23\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m calc_results(lgbmgs\u001b[38;5;241m.\u001b[39mbest_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmgs = None\n",
    "\n",
    "    lgbm = lightgbm.LGBMClassifier(random_state=42)\n",
    "\n",
    "    lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                          param_grid = params_o,\n",
    "                          cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "                          scoring = 'precision', \n",
    "#                           scoring = 'accuracy', \n",
    "                          error_score='raise',\n",
    "                          verbose = 1,\n",
    "                          n_jobs=-1, # 자동 검색 적용\n",
    "                          )\n",
    "\n",
    "    lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') # \n",
    "\n",
    "    df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1score = df_concat.loc['f1score'].iloc[0]\n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1score >= 0.6) :\n",
    "        break\n",
    "    if iter >= 7 : break\n",
    "    print(\"*******Np.{}**Processing*********\".format(iter))\n",
    "    params_o = make_new_parameter(params_o, df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "directory = './'\n",
    "df_base.to_pickle(directory + 'df_mobis_lgbm.pkl')\n",
    "df_base.to_csv(directory + 'df_mobis_lgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "      <th>value3</th>\n",
       "      <th>value4</th>\n",
       "      <th>value5</th>\n",
       "      <th>value6</th>\n",
       "      <th>value7</th>\n",
       "      <th>value8</th>\n",
       "      <th>value9</th>\n",
       "      <th>value10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andom_state</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_delta_step</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_iterations</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>0.0</td>\n",
       "      <td>89312.0</td>\n",
       "      <td>157488.0</td>\n",
       "      <td>106088.0</td>\n",
       "      <td>106088.0</td>\n",
       "      <td>106088.0</td>\n",
       "      <td>106088.0</td>\n",
       "      <td>106088.0</td>\n",
       "      <td>106088.0</td>\n",
       "      <td>106088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.982609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.72973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.585404</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "      <td>0.712733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value1          value2          value3  \\\n",
       "parameter                                                           \n",
       "boosting_type                gbdt            gbdt            gbdt   \n",
       "class_weight                 None            None            None   \n",
       "colsample_bytree             0.25            0.45             0.4   \n",
       "importance_type             split           split           split   \n",
       "learning_rate               0.007           0.011           0.051   \n",
       "max_depth                    None            None               2   \n",
       "min_child_samples              20              20              20   \n",
       "min_child_weight            0.001           0.001           0.001   \n",
       "min_split_gain                0.0             0.0             0.0   \n",
       "n_estimators                 None            None            None   \n",
       "n_jobs                         -1              -1              -1   \n",
       "num_leaves                      2               4               4   \n",
       "objective                  binary          binary          binary   \n",
       "random_state                 None            None            None   \n",
       "reg_alpha                     0.0             0.0             0.0   \n",
       "reg_lambda                    0.0             0.0             0.0   \n",
       "silent                       warn            warn            warn   \n",
       "subsample                    None            None            None   \n",
       "subsample_for_bin          200000          200000          200000   \n",
       "subsample_freq                  0               0               0   \n",
       "andom_state                    42              42              42   \n",
       "max_delta_step                0.5             0.9             0.8   \n",
       "metric             binary_logloss  binary_logloss  binary_logloss   \n",
       "num_iterations                  5             100             150   \n",
       "scale_pos_weight                2               2               2   \n",
       "best_score               0.686957        0.765217        0.791304   \n",
       "best_index                    0.0         89312.0        157488.0   \n",
       "acc_train                0.686957        0.843478        0.982609   \n",
       "acc_val                  0.689655        0.862069        0.862069   \n",
       "acc_test                 0.621622        0.675676         0.72973   \n",
       "precision                     0.0            0.75        0.642857   \n",
       "recall                        0.0        0.214286        0.642857   \n",
       "f1score                       0.0        0.333333        0.642857   \n",
       "roc                           0.5        0.585404        0.712733   \n",
       "tn                           23.0            22.0            18.0   \n",
       "fp                            0.0             1.0             5.0   \n",
       "fn                           14.0            11.0             5.0   \n",
       "tp                            0.0             3.0             9.0   \n",
       "\n",
       "                           value4          value5          value6  \\\n",
       "parameter                                                           \n",
       "boosting_type                gbdt            gbdt            gbdt   \n",
       "class_weight                 None            None            None   \n",
       "colsample_bytree              0.4             0.4             0.4   \n",
       "importance_type             split           split           split   \n",
       "learning_rate               0.051           0.051           0.051   \n",
       "max_depth                       2               2               2   \n",
       "min_child_samples              20              20              20   \n",
       "min_child_weight            0.001           0.001           0.001   \n",
       "min_split_gain                0.0             0.0             0.0   \n",
       "n_estimators                 None            None            None   \n",
       "n_jobs                         -1              -1              -1   \n",
       "num_leaves                      4               4               4   \n",
       "objective                  binary          binary          binary   \n",
       "random_state                 None            None            None   \n",
       "reg_alpha                     0.0             0.0             0.0   \n",
       "reg_lambda                    0.0             0.0             0.0   \n",
       "silent                       warn            warn            warn   \n",
       "subsample                    None            None            None   \n",
       "subsample_for_bin          200000          200000          200000   \n",
       "subsample_freq                  0               0               0   \n",
       "andom_state                    42              42              42   \n",
       "max_delta_step                0.8             0.8             0.8   \n",
       "metric             binary_logloss  binary_logloss  binary_logloss   \n",
       "num_iterations                150             150             150   \n",
       "scale_pos_weight                2               2               2   \n",
       "best_score               0.791304        0.791304        0.791304   \n",
       "best_index               106088.0        106088.0        106088.0   \n",
       "acc_train                0.982609        0.982609        0.982609   \n",
       "acc_val                  0.862069        0.862069        0.862069   \n",
       "acc_test                  0.72973         0.72973         0.72973   \n",
       "precision                0.642857        0.642857        0.642857   \n",
       "recall                   0.642857        0.642857        0.642857   \n",
       "f1score                  0.642857        0.642857        0.642857   \n",
       "roc                      0.712733        0.712733        0.712733   \n",
       "tn                           18.0            18.0            18.0   \n",
       "fp                            5.0             5.0             5.0   \n",
       "fn                            5.0             5.0             5.0   \n",
       "tp                            9.0             9.0             9.0   \n",
       "\n",
       "                           value7          value8          value9  \\\n",
       "parameter                                                           \n",
       "boosting_type                gbdt            gbdt            gbdt   \n",
       "class_weight                 None            None            None   \n",
       "colsample_bytree              0.4             0.4             0.4   \n",
       "importance_type             split           split           split   \n",
       "learning_rate               0.051           0.051           0.051   \n",
       "max_depth                       2               2               2   \n",
       "min_child_samples              20              20              20   \n",
       "min_child_weight            0.001           0.001           0.001   \n",
       "min_split_gain                0.0             0.0             0.0   \n",
       "n_estimators                 None            None            None   \n",
       "n_jobs                         -1              -1              -1   \n",
       "num_leaves                      4               4               4   \n",
       "objective                  binary          binary          binary   \n",
       "random_state                 None            None            None   \n",
       "reg_alpha                     0.0             0.0             0.0   \n",
       "reg_lambda                    0.0             0.0             0.0   \n",
       "silent                       warn            warn            warn   \n",
       "subsample                    None            None            None   \n",
       "subsample_for_bin          200000          200000          200000   \n",
       "subsample_freq                  0               0               0   \n",
       "andom_state                    42              42              42   \n",
       "max_delta_step                0.8             0.8             0.8   \n",
       "metric             binary_logloss  binary_logloss  binary_logloss   \n",
       "num_iterations                150             150             150   \n",
       "scale_pos_weight                2               2               2   \n",
       "best_score               0.791304        0.791304        0.791304   \n",
       "best_index               106088.0        106088.0        106088.0   \n",
       "acc_train                0.982609        0.982609        0.982609   \n",
       "acc_val                  0.862069        0.862069        0.862069   \n",
       "acc_test                  0.72973         0.72973         0.72973   \n",
       "precision                0.642857        0.642857        0.642857   \n",
       "recall                   0.642857        0.642857        0.642857   \n",
       "f1score                  0.642857        0.642857        0.642857   \n",
       "roc                      0.712733        0.712733        0.712733   \n",
       "tn                           18.0            18.0            18.0   \n",
       "fp                            5.0             5.0             5.0   \n",
       "fn                            5.0             5.0             5.0   \n",
       "tp                            9.0             9.0             9.0   \n",
       "\n",
       "                          value10  \n",
       "parameter                          \n",
       "boosting_type                gbdt  \n",
       "class_weight                 None  \n",
       "colsample_bytree              0.4  \n",
       "importance_type             split  \n",
       "learning_rate               0.051  \n",
       "max_depth                       2  \n",
       "min_child_samples              20  \n",
       "min_child_weight            0.001  \n",
       "min_split_gain                0.0  \n",
       "n_estimators                 None  \n",
       "n_jobs                         -1  \n",
       "num_leaves                      4  \n",
       "objective                  binary  \n",
       "random_state                 None  \n",
       "reg_alpha                     0.0  \n",
       "reg_lambda                    0.0  \n",
       "silent                       warn  \n",
       "subsample                    None  \n",
       "subsample_for_bin          200000  \n",
       "subsample_freq                  0  \n",
       "andom_state                    42  \n",
       "max_delta_step                0.8  \n",
       "metric             binary_logloss  \n",
       "num_iterations                150  \n",
       "scale_pos_weight                2  \n",
       "best_score               0.791304  \n",
       "best_index               106088.0  \n",
       "acc_train                0.982609  \n",
       "acc_val                  0.862069  \n",
       "acc_test                  0.72973  \n",
       "precision                0.642857  \n",
       "recall                   0.642857  \n",
       "f1score                  0.642857  \n",
       "roc                      0.712733  \n",
       "tn                           18.0  \n",
       "fp                            5.0  \n",
       "fn                            5.0  \n",
       "tp                            9.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = make_new_parameter(params_o, df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter =0 \n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmgs = None\n",
    "\n",
    "lgbm = lightgbm.LGBMClassifier( random_state=42)\n",
    "\n",
    "lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                      param_grid = params_o,\n",
    "                      cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "#                       scoring = 'precision', \n",
    "                      scoring = 'accuracy', \n",
    "                      error_score='raise',\n",
    "                      verbose = 1,\n",
    "                      n_jobs=-1, # 자동 검색 적용\n",
    "                      )\n",
    "\n",
    "lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') # \n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "df_result = make_df_from_estimator(result_dict, iter)\n",
    "df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estimator: {}\".format(lgbmgs.best_estimator_)) \n",
    "print(\"Best Parameters: {}\".format(lgbmgs.best_params_))  # 최적 파라미터.\n",
    "print('Best Score: {}, Best Index: {}'.format(lgbmgs.best_score_ , lgbmgs.best_index_))  # 교차검증된 점수를 보여줌.\n",
    "\n",
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_pred = model.predict(test_scaled)\n",
    "\n",
    "train_score = model.score(train_scaled, train_target)\n",
    "val_score = model.score(val_scaled, val_target)\n",
    "test_score = model.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, model.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, model.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score, val_score, test_score))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgbmgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = lgbmgs.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.feature_importances_, index=data.columns, columns=['importance']).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mbooster_\u001b[38;5;241m.\u001b[39mfeature_importance(importance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최초의 empty df 생성\n",
    "# df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), 1)\n",
    "result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "df_result = make_df_from_estimator(result_dict, 1)\n",
    "df_concat = pd.concat([df_estimator, df_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.index =['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type',\n",
    "       'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight',\n",
    "       'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective',\n",
    "       'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample',\n",
    "       'subsample_for_bin', 'subsample_freq', 'max_delta_step', 'metric',\n",
    "       'num_iterations', 'scale_pos_weight', 'best_score', 'best_index',\n",
    "       'acc_train', 'acc_val', 'acc_test', 'precision', 'recall', 'f1score',\n",
    "       'roc', 'tn', 'fp', 'fn', 'tp']\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = [df_estimator, df_result]\n",
    "# df_merged= reduce(lambda  left,right: pd.merge(left,right, how='outer', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'boosting_type': ['gbdt'],\n",
    " 'num_iterations': [10, 50, 100],\n",
    " 'learning_rate': [0.003, 0.005, 0.007, 0.009000000000000001, 0.011],\n",
    " 'max_depth': [None, 1, 2, 3, 4],\n",
    " 'num_leaves': [None, 1, 2, 3, 4],\n",
    " 'subsample': [None, 0.001, 0.002, 0.003],\n",
    " 'colsample_bytree': [0.25, 0.3, 0.35, 0.4, 0.45],\n",
    " 'objective': ['binary'],\n",
    " 'metric': ['binary_logloss'],\n",
    " 'n_estimators': [None, 3, 4, 5],\n",
    " 'max_delta_step': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    " 'scale_pos_weight': [2]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"boosting_type\" : ['gbdt'], # ['dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "    \"num_iterations\" : [5], #[450, 500, 550], #\"num_iterations\" \n",
    "    \"learning_rate\": [0.007, 0.008, 0.009, 0.01, 0.015, 0.02], \n",
    "    \"max_depth\": [None, 2, 3, 4], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \"num_leaves\": [2, 3, 4, 5, 6], #  # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "    \"subsample\": [None, 0.001, 0.002],# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \"colsample_bytree\": [ 0.25, 0.3, 0.35, 0.4, 0.45], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    \"objective\": ['binary'],\n",
    "    \"metric\": ['binary_logloss'], # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    \"n_estimators\": [None, 3, 4, 5],\n",
    "    \"max_delta_step\": [0.5, 0.6, 0.7, 0.8, 0.9], # best value found, default = 0\n",
    "    \"scale_pos_weight\": [2], # cla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = params_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"boosting_type\"] == pa[\"boosting_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_new[\"max_delta_step\"] = [0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"max_delta_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"num_iterations\"] = new_num_iter(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"num_iterations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = make_new_parameter(params_o, df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_iter(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = {}\n",
    "aaa['bb'] = new_num_iter(20)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa['bb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa[\"boosting_type\"] = ['gbdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_new = {}\n",
    "param_new[\"boosting_type\"] = ['gbdt'], \n",
    "num_i = df_concat.loc[\"num_iterations\"].iloc[0]\n",
    "param_new[\"num_iterations\"] = new_num_iter(num_i), #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll = {}\n",
    "lll[\"boosting_type\"] = ['gbdt'], \n",
    "\n",
    "num_i = df_concat.loc[\"num_iterations\"].iloc[0]\n",
    "\n",
    "lll[\"num_iterations\"] = new_num_iter(num_i), #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
