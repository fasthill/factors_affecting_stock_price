{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_list = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbmgs.best_score_ \n",
    "    result_dict['best_index'] = lgbmgs.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = 'sec'\n",
    "fname = f'df_{com_name}_sel.pkl'\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "val_scaled = ss.transform(val_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_test= { \n",
    "#     \"num_iterations\": [100, 200, 300, 400, 500],\n",
    "#     \"num_class\": [1]\n",
    "#     \"metric\" : \"rmse\",\n",
    "#     \"bagging_frequency\" : 5,\n",
    "#     \"bagging_seed\" : 2018,\n",
    "#     \"verbosity\" : -1,\n",
    "\n",
    "#     # Selected rounded-off params\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'feature_fraction': 0.1,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 0,\n",
    "#     'max_depth': 9,\n",
    "#     'min_child_weight': 5,\n",
    "#     'min_split_gain': 0,\n",
    "#     'num_leaves': 24 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = {\n",
    "    \"boosting_type\" : ['gbdt'], # ['dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "    \"num_iterations\" : [300], #[450, 500, 550], #\"num_iterations\" \n",
    "    \"learning_rate\": [0.03, 0.04, 0.051, 0.06, 0.07], \n",
    "    \"max_depth\": [-1, 2, 3, 4], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \"num_leaves\": [2, 3, 4, 5, 6], #  # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "    \"subsample\": [1, 0.001, 0.002],# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \"colsample_bytree\": [0.3, 0.35, 0.4, 0.45, 0.5], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    \"objective\": ['binary'],\n",
    "    \"metric\": ['binary_logloss'], # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    \"n_estimators\": [None, 3, 4, 5],\n",
    "    \"max_delta_step\": [0.4, 0.5, 0.6, 0.7, 0.8], # best value found, default = 0\n",
    "    \"scale_pos_weight\": [2, 10, 15], # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "#     \"is_unbalance\": [True],  # 불균형 셋 조정. 주의: \"scale_pos_weight\"과 동시에 사용할 수 없음\n",
    "    #---------------------------------------------\n",
    "#     \"scoring\": ['accuracy', 'precision'], \n",
    "#     \"early_stopping_rounds\" : [200],\n",
    "  \n",
    "# ************* 아래 하나씩 테스트해서 취사 선택해야 함. **************\n",
    "#     \"bagging_frequency\" : [5], \n",
    "#     \"num_threads\": [0], # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "#     \"min_data_in_leaf\": [None], # 과적합 방지 파라미터\n",
    "#     \"lambda_l1\": [0], # default 0\n",
    "#     \"lambda_l2\": [0], #default 0\n",
    "#     \"min_gain_to_split\": [None], # 분기하기 위해 필요한 최소한의 gain을 의미, 정규화시 사용\n",
    "#     \"num_threads\": = 0, # == nthread=4, # Gpu 수, default=0, 자동 검색후 적용\n",
    "#     \"max_bin\": [32],  # data 준비할 때 사용하는 parameter     \n",
    "\n",
    "#         parameters = {'learning_rate': [0.01,0.02,0.03],\n",
    "#                   'subsample'    : [0.9, 0.5, 0.2],\n",
    "#                   'n_estimators' : [100,500,1000],\n",
    "#                   'max_depth'    : [4,6,8]\n",
    "#                  }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = {\n",
    "    \"boosting_type\" : ['gbdt'], # ['dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "#     \"num_iterations\" : [200], #[450, 500, 550], #\"num_iterations\" \n",
    "    \"learning_rate\": [0.06, 0.065, 0.07, 0.075, 0.08], \n",
    "    \"max_depth\": [-1, 2, 3, 4], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \"num_leaves\": [2, 3, 4, 5, 6], #  # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "    \"subsample\": [1, 0.001, 0.002],# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \"colsample_bytree\": [0.3, 0.35, 0.4, 0.45, 0.5], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    \"objective\": ['binary'],\n",
    "    \"metric\": ['binary_logloss'], # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    \"n_estimators\": [80, 100, 120],\n",
    "    \"max_delta_step\": [ 0.8, 0.9], # best value found, default = 0\n",
    "    \"scale_pos_weight\": [10], # class imbalance 경감, scale_pos_weight > 0.0, default=1.0\n",
    "#     \"scoring\": ['accuracy', 'precision'],   \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_num_iter(num_i):\n",
    "    if num_i <= 10:\n",
    "        new_num = [10, 50, 100]\n",
    "    elif num_i <= 100:\n",
    "        new_num = [50, 100, 150, 200]\n",
    "    elif num_i <= 200:\n",
    "        new_num = [150, 200, 300]\n",
    "    else:\n",
    "        new_num = [num_i - 100, num_i, num_i + 100]\n",
    "    return new_num\n",
    "\n",
    "def new_lr(lr):\n",
    "    \n",
    "    def count_zero(x):\n",
    "        if x < 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x * 10**iter >= 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return iter\n",
    "        elif x >= 1:\n",
    "            iter = 1\n",
    "            while True:\n",
    "                if x / 10**iter < 1:\n",
    "                    break\n",
    "                iter = iter+1\n",
    "            return -iter\n",
    "    \n",
    "    def back_step(lr, lr_step):\n",
    "        if lr - lr_step*2 <=0 :\n",
    "            tenth = 10**(count_zero(lr)+1)\n",
    "            return int(lr*tenth/3)/tenth, int(lr*tenth/2)/tenth\n",
    "        else:\n",
    "            return lr_step, lr_step*2\n",
    "    \n",
    "    if lr <= 0.001:\n",
    "        lr_step = 0.0002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.01:\n",
    "        lr_step = 0.002\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 0.1:\n",
    "        lr_step = 0.02\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 1:\n",
    "        lr_step = 0.2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    elif lr <= 10:\n",
    "        lr_step = 2\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "    else:\n",
    "        lr_step = 20\n",
    "        lr_step_m1, lr_step_m2 = back_step(lr, lr_step)\n",
    "\n",
    "    return [lr-lr_step_m2, lr-lr_step_m1, lr, lr+lr_step, lr+lr_step*2]\n",
    "\n",
    "def new_depth(depth):\n",
    "    if depth == None:\n",
    "        new_depth = [None, 1, 2, 3, 4]\n",
    "        new_depth = [1, 2, 3, 4]\n",
    "    elif depth <= 2:\n",
    "        new_depth = [1, 2, 3, 4]\n",
    "    elif depth <= 4:\n",
    "        new_depth = [3, 4, 5, 6]\n",
    "    elif depth <= 6:\n",
    "        new_depth = [5, 6, 7, 8]\n",
    "    else:\n",
    "        new_depth = [7, 8, 9, 10, 11]\n",
    "    return new_depth\n",
    "\n",
    "def new_leaves(leaves):\n",
    "    if leaves <= 3:\n",
    "        new_leaves = [2, 3, 4]\n",
    "    elif leaves <= 10:\n",
    "        new_leaves = [leaves-2, leaves-1, leaves, leaves+1, leaves+2]\n",
    "    elif leaves <= 20:\n",
    "        new_leaves = [leaves-4, leaves-2, leaves, leaves+2, leaves+4]\n",
    "    else:\n",
    "        new_leaves = [leaves-8, leaves-4, leaves, leaves+4, leaves+8]\n",
    "    return new_leaves\n",
    "\n",
    "def new_subsample(subsam):\n",
    "    if subsam == 0.002:\n",
    "        return [0.0005, 0.001, 0.002, 0.003]\n",
    "    elif subsam <= 0.01:\n",
    "        step = 0.001\n",
    "    elif subsam <= 0.1:\n",
    "        step = 0.01\n",
    "    elif subsam <= 1:\n",
    "        step = 0.2\n",
    "        \n",
    "    return [subsam-step, subsam, subsam+step]\n",
    "    \n",
    "def new_nestimator(nest):\n",
    "    if nest <= 10:\n",
    "        return [5, 10, 30]\n",
    "    elif nest <= 50:\n",
    "        return [10, 30, 50, 70]\n",
    "    elif nest <= 100:\n",
    "        return [60, 80, 100, 120]\n",
    "    elif nest <= 140:\n",
    "        return [100, 120, 140, 160]\n",
    "    else :\n",
    "        return [140, 160, 190, 220]\n",
    "    \n",
    "def make_new_parameter(params_o, df_concat):\n",
    "    param_new = {}\n",
    "    param_new[\"boosting_type\"] = ['gbdt']\n",
    "    \n",
    "    num_i = df_concat.loc[\"num_iterations\"].iloc[0]\n",
    "    param_new[\"num_iterations\"] = new_num_iter(num_i) #새로운 값을 중간에 배치, 100단위로 순서\n",
    "    \n",
    "    lr = df_concat.loc[\"learning_rate\"].iloc[0]\n",
    "    param_new[\"learning_rate\"] = new_lr(lr)\n",
    "    \n",
    "    depth = df_concat.loc[\"max_depth\"].iloc[0]\n",
    "    param_new[\"max_depth\"] = new_depth(depth) # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "    \n",
    "    leaves = df_concat.loc[\"num_leaves\"].iloc[0]  \n",
    "    param_new[\"num_leaves\"] = new_leaves(leaves) #  # 두번째로 중요, num_leaves = 2^max_depth보다 작아야 함. 데이터가 적으면 작은 숫자로\n",
    "    \n",
    "    subsam = df_concat.loc[\"subsample\"].iloc[0]  \n",
    "    param_new[\"subsample\"] = new_subsample(subsam) # 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "    \n",
    "    param_new[\"colsample_bytree\"] = [0.25, 0.3, 0.35, 0.4, 0.45] # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "    param_new[\"objective\"] = ['binary']\n",
    "    param_new[\"metric\"] = ['binary_logloss'] # \"metric\": ['loss'], # mae : mean absolute error, mse : mean squared error, \n",
    "                      # binary_logloss : loss for binary classification, multi_logloss : loss for multi classification\n",
    "\n",
    "    nest = df_concat.loc[\"n_estimators\"].iloc[0] \n",
    "    param_new[\"n_estimators\"] = new_nestimator(nest) # [None, 3, 4, 5]\n",
    "    param_new[\"max_delta_step\"] = [0.5, 0.6, 0.7, 0.8, 0.9] # best value found, default = 0\n",
    "    param_new[\"scale_pos_weight\"] = [3, 10, 20] #  class imbalance 경감, scale_pos_weight > 0.0, defaut\n",
    "#     param_new[\"is_unbalance\"] = [1],  # 불균형 셋 조정, 주의: \"scale_pos_weight\" 동시에 사용할 수 없음.\n",
    "    \n",
    "#     param_new[\"scoring\"] = ['accuracy', 'precision'],\n",
    "#     param_new[\"early_stopping_rounds\"] = [50],\n",
    "\n",
    "    \n",
    "    print(\"-------- End of Parameter Setting -------\")\n",
    "    \n",
    "    return param_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbmgs ******\n",
      "Fitting 5 folds for each of 12000 candidates, totalling 60000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* No.1  Process is Done! ********\n",
      "-------- End of Parameter Setting -------\n",
      "*** after lgbmgs ******\n",
      "Fitting 5 folds for each of 202500 candidates, totalling 1012500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* No.2  Process is Done! ********\n",
      "-------- End of Parameter Setting -------\n",
      "*** after lgbmgs ******\n",
      "Fitting 5 folds for each of 337500 candidates, totalling 1687500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* No.3  Process is Done! ********\n",
      "-------- End of Parameter Setting -------\n",
      "*** after lgbmgs ******\n",
      "Fitting 5 folds for each of 337500 candidates, totalling 1687500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kange\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* No.4  Process is Done! ********\n",
      "-------- End of Parameter Setting -------\n",
      "*** after lgbmgs ******\n",
      "Fitting 5 folds for each of 337500 candidates, totalling 1687500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 26\u001b[0m\n\u001b[0;32m     14\u001b[0m     lgbmgs \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m lgbm,\n\u001b[0;32m     15\u001b[0m                           param_grid \u001b[38;5;241m=\u001b[39m params_o,\n\u001b[0;32m     16\u001b[0m                           cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;66;03m# StratifiedKFold us default for binary or multiclass\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m                           n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;66;03m# 자동 검색 적용\u001b[39;00m\n\u001b[0;32m     23\u001b[0m                          )\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** after lgbmgs ******\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mlgbmgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#     lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss', eval_set = (val_scaled, val_target)) \u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# eval_set가 있어야 \"early_stopping_rounds\"를 사용할 수 있음.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     stamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39misoformat() \u001b[38;5;66;03m# 파일명 끝에 생성날짜 시간 추가\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(com_name):\n",
    "    os.makedirs(com_name)\n",
    "    \n",
    "iter = 0\n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmgs = None\n",
    "\n",
    "    lgbm = lightgbm.LGBMClassifier(random_state=42)\n",
    "\n",
    "    lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                          param_grid = params_o,\n",
    "                          cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "                          scoring = 'precision', \n",
    "#                           scoring = 'accuracy', \n",
    "#                           scoring = ['accuracy', 'precision'], # refit 사용해야 함. 고로 사용하지 않음.\n",
    "                          error_score='raise',\n",
    "                          verbose = 1,\n",
    "                          n_jobs=-1, # 자동 검색 적용\n",
    "                         )\n",
    "                          \n",
    "    print(\"*** after lgbmgs ******\")\n",
    "    lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "#     lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss', eval_set = (val_scaled, val_target)) \n",
    "    # eval_set가 있어야 \"early_stopping_rounds\"를 사용할 수 있음.\n",
    "\n",
    "# save model\n",
    "    stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "    dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "    joblib.dump(lgbmgs, f'./{com_name}/lgbm_v{iter}_{dt}.pkl')\n",
    "    \n",
    "    df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmgs.best_estimator_, \n",
    "                               train_scaled, val_scaled, test_scaled,  \n",
    "                               train_target, val_target, test_target)\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1score = df_concat.loc['f1score'].iloc[0]\n",
    "    \n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1score >= 0.6) :\n",
    "        df_base.to_csv(f'./{com_name}/lgbm_ver{iter}_df_{dt}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_ver{iter}_df_{dt}.pkl')\n",
    "        break\n",
    "    if iter >= 7 : \n",
    "        df_base.to_csv(f'./{com_name}/lgbm_ver{iter}_df_{dt}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_ver{iter}_df_{dt}.pkl')\n",
    "        break\n",
    "    print(\"******* No.{}  Process is Done! ********\".format(iter))\n",
    "    params_o = make_new_parameter(params_o, df_concat)\n",
    "    save_to_pickle(f'./{com_name}/params_ver{iter}_{dt}.pkl', params_o)\n",
    "    \n",
    "print(\"**** End of Process ****\")\n",
    "# save model, save df, stoppping 기준 수립\n",
    "# 일단위로 정확도 측정, 정확도, 정밀도?\n",
    "\n",
    "# eval_set, early_stopping_rounds 내용 확인 필. \">\" 에러 확인.\n",
    "# 집어 넣으면 에러 발생하니, 원인을 찾아야 함. 하면 좋은 이유는?\n",
    "\n",
    "# scoring = ['accuracy', 'precision'] 두가지 param 선언이 안되나?\n",
    "# Precision is ill-defined and being set to 0.0 due to no predicted samples.  왜 나오나 확인해야 함.\n",
    "# .predict로 하면 positive로 예측하는 경우가 발생하지 않음. \n",
    "\n",
    "\n",
    "# feature_importance 확인하고 중요한 feature만 갖고 분석해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_csv(f'./{com_name}/lgbm_ver{iter}_df_{dt}.csv')\n",
    "df_base.to_pickle(f'./{com_name}/lgbm_ver{iter}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmgs.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_csv(f'./{com_name}_lgbm_ver000_df.csv')\n",
    "df_base.to_pickle(f'./{com_name}_lgbm_ver000_df_______ppp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_pickle(f'./{com_name}_lgbm_ver000_df_______pppXXXXX.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgbmgs, f'./{com_name}_lgbm_vVV.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgbmgs, f'./{com_name}/lgbm_v{iter}_{stamp[5:16]}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "joblib.dump(lgbmgs, f'./{com_name}/lgbm_v{iter}_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = datetime.datetime.today().isoformat()\n",
    "stamp[5:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp[5:16].replace([\"-\",\"T\",\":\"],\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backs = re.sub(r'[\\\\.]', '*', 'sam.sun\\\\g') \n",
    "backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backs = re.sub(r'[-:T]', '', stamp[5:16]) \n",
    "backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = datetime.datetime.today().isoformat()[5:16] # 파일명 끝에 생성날짜 시간 추가\n",
    "joblib.dump(lgbmgs, f'./{com_name}_lgbm_ver{iter}_{stamp}_____1.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgbmgs, f'./{com_name}_lgbm_ver{iter}_{stamp}OOOOOOOOPP.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "directory = './'\n",
    "df_base.to_pickle(directory + f'df_{com_name}_lgbm.pkl')\n",
    "df_base.to_csv(directory + f'df_{com_name}_lgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv(f'./{com_name}_lgbm_ver{iter}_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = make_new_parameter(params_o, df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter =0 \n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmgs = None\n",
    "\n",
    "lgbm = lightgbm.LGBMClassifier( random_state=42)\n",
    "\n",
    "lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                      param_grid = params_o,\n",
    "                      cv = 5, # StratifiedKFold us default for binary or multiclass\n",
    "#                       scoring = 'precision', \n",
    "                      scoring = 'accuracy', \n",
    "                      error_score='raise',\n",
    "                      verbose = 1,\n",
    "                      n_jobs=-1, # 자동 검색 적용\n",
    "                      )\n",
    "\n",
    "lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') # \n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "df_result = make_df_from_estimator(result_dict, iter)\n",
    "df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estimator: {}\".format(lgbmgs.best_estimator_)) \n",
    "print(\"Best Parameters: {}\".format(lgbmgs.best_params_))  # 최적 파라미터.\n",
    "print('Best Score: {}, Best Index: {}'.format(lgbmgs.best_score_ , lgbmgs.best_index_))  # 교차검증된 점수를 보여줌.\n",
    "\n",
    "model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "y_pred = model.predict(test_scaled)\n",
    "\n",
    "train_score = model.score(train_scaled, train_target)\n",
    "val_score = model.score(val_scaled, val_target)\n",
    "test_score = model.score(test_scaled, test_target)\n",
    "ps, rs, fs, roc = predict_p(test_target, model.predict(test_scaled))\n",
    "cm = confusion_matrix(test_target, model.predict(test_scaled))\n",
    "\n",
    "print(\"train accuracy: {:.4f}, val accuracy {:.4f}, test accuracy {:.4f}\".\n",
    "      format(train_score, val_score, test_score))\n",
    "print(\"precision : {:.4f}, recall : {:.4f}, f1score : {:.4f}, roc : {:.4f}\".\n",
    "     format (ps, rs, fs, roc))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter=5\n",
    "a = f'./{com_name}_lgbm_ver{iter}.h5'\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = pd.DataFrame(model.feature_importances_, index=data.columns, columns=['importance']).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최초의 empty df 생성\n",
    "# df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), 1)\n",
    "result_dict = calc_results(lgbmgs.best_estimator_, train_scaled, val_scaled, test_scaled, test_target)\n",
    "df_result = make_df_from_estimator(result_dict, 1)\n",
    "df_concat = pd.concat([df_estimator, df_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.index =['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type',\n",
    "       'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight',\n",
    "       'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective',\n",
    "       'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample',\n",
    "       'subsample_for_bin', 'subsample_freq', 'max_delta_step', 'metric',\n",
    "       'num_iterations', 'scale_pos_weight', 'best_score', 'best_index',\n",
    "       'acc_train', 'acc_val', 'acc_test', 'precision', 'recall', 'f1score',\n",
    "       'roc', 'tn', 'fp', 'fn', 'tp']\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df_base.merge(df_estimator, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = [df_estimator, df_result]\n",
    "# df_merged= reduce(lambda  left,right: pd.merge(left,right, how='outer', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = params_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"boosting_type\"] == pa[\"boosting_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_new[\"max_delta_step\"] = [0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"max_delta_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"num_iterations\"] = new_num_iter(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o[\"num_iterations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = make_new_parameter(params_o, df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_iter(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = {}\n",
    "aaa['bb'] = new_num_iter(20)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa['bb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa[\"boosting_type\"] = ['gbdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmgs.best_estimator_\n",
    "model.save(f'./{com_name}_lgbm_ver{iter}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgbmgs, f'./{com_name}_lgbm_ver{iter}.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lgbmgs, 'testmodel.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadmodel = joblib.load('testmodel.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadmodel.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './'\n",
    "df_temp = pd.read_pickle(directory + f'df_{com_name}_lgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_num_iter(num_i):\n",
    "    if num_i <= 10:\n",
    "        new_num = [10, 50, 100]\n",
    "    elif num_i <= 100:\n",
    "        new_num = [50, 100, 150, 200]\n",
    "    elif num_i <= 200:\n",
    "        new_num = [150, 200, 300]\n",
    "    else:\n",
    "        new_num = [num_i - 100, num_i, num_i + 100]\n",
    "    return new_num\n",
    "\n",
    "for k in range(1, 300, 5):\n",
    "    a = new_num_iter(k)\n",
    "    print(\"kk\", k, \"list: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = datetime.datetime.today().isoformat()[5:16] # 파일명 끝에 생성날짜 시간 추가\n",
    "joblib.dump(lgbmgs, f'./{com_name}_lgbm_1111.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmgs.best_estimator_.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = joblib.load('mobis_lgbm_1111.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "com_name = 'sec'\n",
    "if not os.path.exists(com_name):\n",
    "    os.makedirs(com_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [1,2,3,4,5],\n",
    "njm_leaves = [3,4,5,6,7],\n",
    "learning_rate = [0.03, 0.05, 0.1, 0.2, 0.3]\n",
    "colsample_bytree = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "subsample = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "n_estimator =[5, 10, 15, 20]\n",
    "num_class = [1]\n",
    "\n",
    "num_leaves = 20~3000\n",
    "max_depth = 3 ~12\n",
    "learning_rate = 0.01 ~ 0.3\n",
    "\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03],\n",
    "                  'subsample'    : [0.9, 0.5, 0.2],\n",
    "                  'n_estimators' : [100,500,1000],\n",
    "                  'max_depth'    : [4,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec\n",
    "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
    "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
    "train accuracy: 1.0000, val accuracy 0.7907, test accuracy 0.8519\n",
    "precision : 0.7368, recall : 0.8235, f1score : 0.7778, roc : 0.8442\n",
    "[[32  5]\n",
    " [ 3 14]]\n",
    "\n",
    "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.41, eval_metric='logloss',\n",
    "               learning_rate=0.004, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=5, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.005)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.41, 'learning_rate': 0.004, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.005}\n",
    "Best Score: 0.9333333333333332, Best Index: 0\n",
    "train accuracy: 0.8081, val accuracy 0.7442, test accuracy 0.7593\n",
    "precision : 1.0000, recall : 0.2353, f1score : 0.3810, roc : 0.6176\n",
    "[[37  0]\n",
    " [13  4]]\n",
    "\n",
    "Fitting 5 folds for each of 18000 candidates, totalling 90000 fits\n",
    "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.8\n",
    "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9\n",
    "Best Estimator: LGBMClassifier(bagging_fraction=0.9, colsample_bytree=0.5, feature_fraction=0.8,\n",
    "               learning_rate=0.05, max_delta_step=0.5, max_depth=2,\n",
    "               metric='auc', num_iterations=500, num_leaves=4,\n",
    "               objective='binary', random_state=42, subsample=0.5)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.5, 'learning_rate': 0.05, 'max_depth': 2, 'metric': 'auc', 'n_estimators': 100, 'num_leaves': 4, 'objective': 'binary', 'subsample': 0.5}\n",
    "Best Score: 0.8375180375180376, Best Index: 726\n",
    "train accuracy: 1.0000, val accuracy 0.7907, test accuracy 0.8148\n",
    "precision : 0.7059, recall : 0.7059, f1score : 0.7059, roc : 0.7854\n",
    "[[32  5]\n",
    " [ 5 12]]\n",
    "\n",
    "Fitting 5 folds for each of 7200 candidates, totalling 36000 fits\n",
    "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.3 will be ignored. Current value: feature_fraction=0.8\n",
    "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.3 will be ignored. Current value: bagging_fraction=0.9\n",
    "Best Estimator: LGBMClassifier(bagging_fraction=0.9, colsample_bytree=0.3, feature_fraction=0.8,\n",
    "               max_delta_step=0.5, max_depth=4, metric='rmse', n_estimators=80,\n",
    "               num_iterations=500, num_leaves=6, objective='binary',\n",
    "               random_state=42, subsample=0.3)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 4, 'metric': 'rmse', 'n_estimators': 80, 'num_leaves': 6, 'objective': 'binary', 'subsample': 0.3}\n",
    "Best Score: 0.8377777777777778, Best Index: 915\n",
    "train accuracy: 1.0000, val accuracy 0.7907, test accuracy 0.8519\n",
    "precision : 0.7368, recall : 0.8235, f1score : 0.7778, roc : 0.8442\n",
    "[[32  5]\n",
    " [ 3 14]]\n",
    "\n",
    "Fitting 5 folds for each of 12500 candidates, totalling 62500 fits\n",
    "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=0.1 will be ignored. Current value: feature_fraction=0.8\n",
    "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=0.1 will be ignored. Current value: bagging_fraction=0.9\n",
    "Best Estimator: LGBMClassifier(bagging_fraction=0.9, colsample_bytree=0.1, feature_fraction=0.8,\n",
    "               learning_rate=0.07, max_delta_step=0.5, max_depth=5,\n",
    "               metric='rmse', n_estimators=50, num_iterations=500, num_leaves=6,\n",
    "               objective='binary', random_state=42, subsample=0.1)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.1, 'learning_rate': 0.07, 'max_depth': 5, 'metric': 'rmse', 'n_estimators': 50, 'num_leaves': 6, 'objective': 'binary', 'subsample': 0.1}\n",
    "Best Score: 0.8377777777777778, Best Index: 315\n",
    "train accuracy: 1.0000, val accuracy 0.8140, test accuracy 0.8519\n",
    "precision : 0.7368, recall : 0.8235, f1score : 0.7778, roc : 0.8442\n",
    "[[32  5]\n",
    " [ 3 14]]\n",
    "\n",
    "Fitting 5 folds for each of 12500 candidates, totalling 62500 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.4, learning_rate=0.03, max_delta_step=0.5,\n",
    "               max_depth=3, metric='loss', n_estimators=30, num_iterations=500,\n",
    "               num_leaves=4, objective='binary', random_state=42,\n",
    "               subsample=0.1)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.03, 'max_depth': 3, 'metric': 'loss', 'n_estimators': 30, 'num_leaves': 4, 'objective': 'binary', 'subsample': 0.1}\n",
    "Best Score: 0.8342857142857143, Best Index: 7605\n",
    "train accuracy: 1.0000, val accuracy 0.7907, test accuracy 0.8704\n",
    "precision : 0.7500, recall : 0.8824, f1score : 0.8108, roc : 0.8736\n",
    "[[32  5]\n",
    " [ 2 15]]\n",
    "\n",
    "Fitting 5 folds for each of 13500 candidates, totalling 67500 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.35, eval_metric='logloss', learning_rate=0.02,\n",
    "               max_delta_step=0.5, max_depth=3, metric='loss', n_estimators=10,\n",
    "               num_iterations=100, num_leaves=4, objective='binary',\n",
    "               random_state=42, subsample=0.05)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.35, 'learning_rate': 0.02, 'max_depth': 3, 'metric': 'loss', 'n_estimators': 10, 'num_iterations': 100, 'num_leaves': 4, 'objective': 'binary', 'subsample': 0.05}\n",
    "Best Score: 1.0, Best Index: 1204\n",
    "train accuracy: 0.7849, val accuracy 0.7442, test accuracy 0.7037\n",
    "precision : 1.0000, recall : 0.0588, f1score : 0.1111, roc : 0.5294\n",
    "[[37  0]\n",
    " [16  1]]\n",
    "\n",
    "Fitting 5 folds for each of 2700 candidates, totalling 13500 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.45, eval_metric='logloss', learning_rate=0.01,\n",
    "               max_delta_step=0.5, max_depth=2, metric='loss', n_estimators=10,\n",
    "               num_iterations=300, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=0.05)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.45, 'learning_rate': 0.01, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 10, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.05}\n",
    "Best Score: 0.8638888888888889, Best Index: 1800\n",
    "train accuracy: 0.9128, val accuracy 0.8140, test accuracy 0.8519\n",
    "precision : 0.8000, recall : 0.7059, f1score : 0.7500, roc : 0.8124\n",
    "[[34  3]\n",
    " [ 5 12]]\n",
    "\n",
    "Fitting 5 folds for each of 2880 candidates, totalling 14400 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.4, eval_metric='logloss', learning_rate=0.01,\n",
    "               max_delta_step=0.5, max_depth=2, metric='loss', n_estimators=5,\n",
    "               num_iterations=200, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=0.03)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.01, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.03}\n",
    "Best Score: 0.9333333333333332, Best Index: 144\n",
    "train accuracy: 0.8023, val accuracy 0.7442, test accuracy 0.7593\n",
    "precision : 1.0000, recall : 0.2353, f1score : 0.3810, roc : 0.6176\n",
    "[[37  0]\n",
    " [13  4]]\n",
    "\n",
    "Fitting 5 folds for each of 2880 candidates, totalling 14400 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.42, eval_metric='logloss', learning_rate=0.01,\n",
    "               max_delta_step=0.5, max_depth=2, metric='loss', n_estimators=5,\n",
    "               num_iterations=300, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=0.03)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.42, 'learning_rate': 0.01, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.03}\n",
    "Best Score: 0.8638888888888889, Best Index: 720\n",
    "train accuracy: 0.9070, val accuracy 0.8140, test accuracy 0.8519\n",
    "precision : 0.8000, recall : 0.7059, f1score : 0.7500, roc : 0.8124\n",
    "[[34  3]\n",
    " [ 5 12]]\n",
    "\n",
    "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.42, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=5, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.01)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.42, 'learning_rate': 0.005, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.01}\n",
    "Best Score: 0.8355555555555556, Best Index: 432\n",
    "train accuracy: 0.8895, val accuracy 0.8372, test accuracy 0.8519\n",
    "precision : 0.8462, recall : 0.6471, f1score : 0.7333, roc : 0.7965\n",
    "[[35  2]\n",
    " [ 6 11]]\n",
    "\n",
    "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.41, eval_metric='logloss',\n",
    "               learning_rate=0.004, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=5, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.005)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.41, 'learning_rate': 0.004, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.005}\n",
    "Best Score: 0.9333333333333332, Best Index: 0\n",
    "train accuracy: 0.8081, val accuracy 0.7442, test accuracy 0.7593\n",
    "precision : 1.0000, recall : 0.2353, f1score : 0.3810, roc : 0.6176\n",
    "[[37  0]\n",
    " [13  4]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver\n",
    "\n",
    "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
    "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
    "train accuracy: 1.0000, val accuracy 0.8205, test accuracy 0.7083\n",
    "precision : 0.6111, recall : 0.6111, f1score : 0.6111, roc : 0.6889\n",
    "[[23  7]\n",
    " [ 7 11]]\n",
    "\n",
    "Fitting 5 folds for each of 4608 candidates, totalling 23040 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=None,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.005, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.8311827956989248, Best Index: 864\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7708\n",
    "precision : 0.8182, recall : 0.5000, f1score : 0.6207, roc : 0.7167\n",
    "[[28  2]\n",
    " [ 9  9]]\n",
    "\n",
    "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.41, eval_metric='logloss',\n",
    "               learning_rate=0.004, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=5, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.005)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.41, 'learning_rate': 0.004, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 5, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.005}\n",
    "Best Score: 0.9444444444444444, Best Index: 0\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7917\n",
    "precision : 0.9000, recall : 0.5000, f1score : 0.6429, roc : 0.7333\n",
    "[[29  1]\n",
    " [ 9  9]]\n",
    "\n",
    "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.003, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.003, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.9777777777777779, Best Index: 216\n",
    "train accuracy: 0.8170, val accuracy 0.8462, test accuracy 0.7292\n",
    "precision : 0.8571, recall : 0.3333, f1score : 0.4800, roc : 0.6500\n",
    "[[29  1]\n",
    " [12  6]]\n",
    "\n",
    "#### scoring을 precision에서 default(accuracy)로 변경한 결과\n",
    "Fitting 5 folds for each of 3456 candidates, totalling 17280 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=2,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.005, 'max_depth': 2, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.8311827956989248, Best Index: 648\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7708\n",
    "precision : 0.8182, recall : 0.5000, f1score : 0.6207, roc : 0.7167\n",
    "[[28  2]\n",
    " [ 9  9]]\n",
    "\n",
    "#### max_depth = None 삽입결과\n",
    "\n",
    "Fitting 5 folds for each of 4608 candidates, totalling 23040 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.38, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=None,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.38, 'learning_rate': 0.005, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.8311827956989248, Best Index: 864\n",
    "train accuracy: 0.8758, val accuracy 0.8974, test accuracy 0.7708\n",
    "precision : 0.8182, recall : 0.5000, f1score : 0.6207, roc : 0.7167\n",
    "[[28  2]\n",
    " [ 9  9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skhinix\n",
    "\n",
    "Fitting 5 folds for each of 2880 candidates, totalling 14400 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, learning_rate=0.008, max_delta_step=0.5,\n",
    "               max_depth=None, metric='loss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.008, 'max_depth': None, 'metric': 'loss', 'n_estimators': None, 'num_leaves': 3, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8201426024955436, Best Index: 1443\n",
    "train accuracy: 0.8795, val accuracy 0.8571, test accuracy 0.8269\n",
    "precision : 0.8571, recall : 0.6316, f1score : 0.7273, roc : 0.7855\n",
    "[[31  2]\n",
    " [ 7 12]]\n",
    "4 values from sklearn\n",
    "precision : 0.8571, recall : 0.6316, f1score : 0.7273, roc : 0.7855\n",
    "                \n",
    "                \n",
    "Fitting 5 folds for each of 4608 candidates, totalling 23040 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.39, eval_metric='logloss',\n",
    "               learning_rate=0.005, max_delta_step=0.5, max_depth=None,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.003)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.39, 'learning_rate': 0.005, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.003}\n",
    "Best Score: 0.7782531194295901, Best Index: 2016\n",
    "train accuracy: 0.8434, val accuracy 0.7857, test accuracy 0.8077\n",
    "precision : 0.8462, recall : 0.5789, f1score : 0.6875, roc : 0.7592\n",
    "[[31  2]\n",
    " [ 8 11]]         \n",
    "\n",
    "Fitting 5 folds for each of 7200 candidates, totalling 36000 fits\n",
    "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, eval_metric='logloss',\n",
    "               learning_rate=0.007, max_delta_step=0.5, max_depth=None,\n",
    "               metric='loss', n_estimators=3, num_iterations=500, num_leaves=3,\n",
    "               objective='binary', random_state=42, subsample=0.001)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.007, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 3, 'objective': 'binary', 'subsample': 0.001}\n",
    "Best Score: 0.8083778966131907, Best Index: 1152\n",
    "train accuracy: 0.8795, val accuracy 0.8571, test accuracy 0.8269\n",
    "precision : 0.8571, recall : 0.6316, f1score : 0.7273, roc : 0.7855\n",
    "[[31  2]\n",
    " [ 7 12]]\n",
    "\n",
    "Fitting 5 folds for each of 4320 candidates, totalling 21600 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, learning_rate=0.011, max_delta_step=0.5,\n",
    "               max_depth=None, metric='loss', n_estimators=3,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.011, 'max_depth': None, 'metric': 'loss', 'n_estimators': 3, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8199643493761141, Best Index: 3024\n",
    "train accuracy: 0.8675, val accuracy 0.8095, test accuracy 0.8462\n",
    "precision : 0.8667, recall : 0.6842, f1score : 0.7647, roc : 0.8118\n",
    "[[31  2]\n",
    " [ 6 13]]\n",
    "\n",
    "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.34, learning_rate=0.01, max_delta_step=0.5,\n",
    "               max_depth=None, metric='loss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.34, 'learning_rate': 0.01, 'max_depth': None, 'metric': 'loss', 'n_estimators': None, 'num_leaves': 3, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8199643493761141, Best Index: 3\n",
    "train accuracy: 0.8916, val accuracy 0.9048, test accuracy 0.8462\n",
    "precision : 0.8667, recall : 0.6842, f1score : 0.7647, roc : 0.8118\n",
    "[[31  2]\n",
    " [ 6 13]]\n",
    "\n",
    "Fitting 5 folds for each of 2880 candidates, totalling 14400 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, learning_rate=0.008, max_delta_step=0.5,\n",
    "               max_depth=None, metric='loss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.008, 'max_depth': None, 'metric': 'loss', 'n_estimators': None, 'num_leaves': 3, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8201426024955436, Best Index: 2307\n",
    "train accuracy: 0.8795, val accuracy 0.8571, test accuracy 0.8269\n",
    "precision : 0.8571, recall : 0.6316, f1score : 0.7273, roc : 0.7855\n",
    "[[31  2]\n",
    " [ 7 12]]\n",
    "\n",
    "Fitting 5 folds for each of 2880 candidates, totalling 14400 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, learning_rate=0.008, max_delta_step=0.5,\n",
    "               max_depth=None, metric='loss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=3, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.008, 'max_depth': None, 'metric': 'loss', 'n_estimators': None, 'num_leaves': 3, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8201426024955436, Best Index: 1443\n",
    "train accuracy: 0.8795, val accuracy 0.8571, test accuracy 0.8269\n",
    "precision : 0.8571, recall : 0.6316, f1score : 0.7273, roc : 0.7855\n",
    "[[31  2]\n",
    " [ 7 12]]\n",
    "4 values from sklearn\n",
    "precision : 0.8571, recall : 0.6316, f1score : 0.7273, roc : 0.7855\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobis\n",
    "\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.4, learning_rate=0.02, max_delta_step=0.8,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=450, num_leaves=3, objective='binary',\n",
    "               random_state=42, scale_pos_weight=2, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.02, 'max_delta_step': 0.8, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 450, 'num_leaves': 3, 'objective': 'binary', 'scale_pos_weight': 2, 'subsample': None}\n",
    "Best Score: 0.7913043478260869, Best Index: 84963\n",
    "train accuracy: 0.9826, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 0.6667, recall : 0.7143, f1score : 0.6897, roc : 0.7484\n",
    "[[18  5]\n",
    " [ 4 10]]\n",
    "\n",
    "Fitting 5 folds for each of 34560 candidates, totalling 172800 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.36, learning_rate=0.006, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.36, 'learning_rate': 0.006, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.8159420289855073, Best Index: 30690\n",
    "train accuracy: 0.8487, val accuracy 0.7667, test accuracy 0.7895\n",
    "precision : 0.8182, recall : 0.6000, f1score : 0.6923, roc : 0.7565\n",
    "[[21  2]\n",
    " [ 6  9]]\n",
    "\n",
    "Fitting 5 folds for each of 34560 candidates, totalling 172800 fits\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.007, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.007, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7652173913043478, Best Index: 4770\n",
    "train accuracy: 0.8174, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 1.0000, recall : 0.3571, f1score : 0.5263, roc : 0.6786\n",
    "[[23  0]\n",
    " [ 9  5]]\n",
    "\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.007, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.007, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7652173913043478, Best Index: 18585\n",
    "train accuracy: 0.8174, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 1.0000, recall : 0.3571, f1score : 0.5263, roc : 0.6786\n",
    "[[23  0]\n",
    " [ 9  5]]\n",
    "\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.007, max_delta_step=0.5,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=2, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.007, 'max_delta_step': 0.5, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 2, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7652173913043478, Best Index: 18585\n",
    "train accuracy: 0.8174, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 1.0000, recall : 0.3571, f1score : 0.5263, roc : 0.6786\n",
    "[[23  0]\n",
    " [ 9  5]]\n",
    "\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.25, learning_rate=0.008, max_delta_step=0.7,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=500, num_leaves=4, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.25, 'learning_rate': 0.008, 'max_delta_step': 0.7, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 500, 'num_leaves': 4, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.773913043478261, Best Index: 20319\n",
    "train accuracy: 0.9217, val accuracy 0.8966, test accuracy 0.7027\n",
    "precision : 0.7143, recall : 0.3571, f1score : 0.4762, roc : 0.6351\n",
    "[[21  2]\n",
    " [ 9  5]]\n",
    "\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.35, learning_rate=0.01, max_delta_step=0.8,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=550, num_leaves=4, objective='binary',\n",
    "               random_state=42, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.35, 'learning_rate': 0.01, 'max_delta_step': 0.8, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 550, 'num_leaves': 4, 'objective': 'binary', 'subsample': None}\n",
    "Best Score: 0.7826086956521741, Best Index: 106596\n",
    "train accuracy: 0.9826, val accuracy 0.8966, test accuracy 0.7568\n",
    "precision : 0.7273, recall : 0.5714, f1score : 0.6400, roc : 0.7205\n",
    "[[20  3]\n",
    " [ 6  8]]\n",
    "\n",
    "Best Estimator: LGBMClassifier(colsample_bytree=0.4, learning_rate=0.02, max_delta_step=0.8,\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None,\n",
    "               num_iterations=450, num_leaves=3, objective='binary',\n",
    "               random_state=42, scale_pos_weight=2, subsample=None)\n",
    "Best Parameters: {'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.02, 'max_delta_step': 0.8, 'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, 'num_iterations': 450, 'num_leaves': 3, 'objective': 'binary', 'scale_pos_weight': 2, 'subsample': None}\n",
    "Best Score: 0.7913043478260869, Best Index: 84963\n",
    "train accuracy: 0.9826, val accuracy 0.8621, test accuracy 0.7568\n",
    "precision : 0.6667, recall : 0.7143, f1score : 0.6897, roc : 0.7484\n",
    "[[18  5]\n",
    " [ 4 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"colsample_bytree=0.4, learning_rate=0.02, max_delta_step=0.8, \\\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None, \\\n",
    "               num_iterations=450, num_leaves=3, objective='binary', \\\n",
    "               random_state=42, scale_pos_weight=2, subsample=None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "np.array(a.split(\", \")).replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colsample_bytree=0.4',\n",
       " 'learning_rate=0.02',\n",
       " 'max_delta_step=0.8',\n",
       " '               max_depth=None',\n",
       " \"metric='binary_logloss'\",\n",
       " 'n_estimators=None',\n",
       " '               num_iterations=450',\n",
       " 'num_leaves=3',\n",
       " \"objective='binary'\",\n",
       " '               random_state=42',\n",
       " 'scale_pos_weight=2',\n",
       " 'subsample=None']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a.split(\", \"), columns=['var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var1'] = df['var'].str.split(\"=\").str[0]\n",
    "df['var2'] = df['var'].str.split(\"=\").str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colsample_bytree=0.4</td>\n",
       "      <td>colsample_bytree</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning_rate=0.02</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_delta_step=0.8</td>\n",
       "      <td>max_delta_step</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_depth=None</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metric='binary_logloss'</td>\n",
       "      <td>metric</td>\n",
       "      <td>'binary_logloss'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_estimators=None</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_iterations=450</td>\n",
       "      <td>num_iterations</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_leaves=3</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>objective='binary'</td>\n",
       "      <td>objective</td>\n",
       "      <td>'binary'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_state=42</td>\n",
       "      <td>random_state</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>scale_pos_weight=2</td>\n",
       "      <td>scale_pos_weight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subsample=None</td>\n",
       "      <td>subsample</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  var                           var1  \\\n",
       "0                colsample_bytree=0.4               colsample_bytree   \n",
       "1                  learning_rate=0.02                  learning_rate   \n",
       "2                  max_delta_step=0.8                 max_delta_step   \n",
       "3                      max_depth=None                      max_depth   \n",
       "4             metric='binary_logloss'                         metric   \n",
       "5                   n_estimators=None                   n_estimators   \n",
       "6                  num_iterations=450                 num_iterations   \n",
       "7                        num_leaves=3                     num_leaves   \n",
       "8                  objective='binary'                      objective   \n",
       "9                     random_state=42                   random_state   \n",
       "10                 scale_pos_weight=2               scale_pos_weight   \n",
       "11                     subsample=None                      subsample   \n",
       "\n",
       "                var2  \n",
       "0                0.4  \n",
       "1               0.02  \n",
       "2                0.8  \n",
       "3               None  \n",
       "4   'binary_logloss'  \n",
       "5               None  \n",
       "6                450  \n",
       "7                  3  \n",
       "8           'binary'  \n",
       "9                 42  \n",
       "10                 2  \n",
       "11              None  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[colsample_bytree, 0.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[learning_rate, 0.02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[max_delta_step, 0.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[               max_depth, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[metric, 'binary_logloss']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[n_estimators, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[               num_iterations, 450]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[num_leaves, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[objective, 'binary']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[               random_state, 42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[scale_pos_weight, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[subsample, None]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     var\n",
       "0                [colsample_bytree, 0.4]\n",
       "1                  [learning_rate, 0.02]\n",
       "2                  [max_delta_step, 0.8]\n",
       "3       [               max_depth, None]\n",
       "4             [metric, 'binary_logloss']\n",
       "5                   [n_estimators, None]\n",
       "6   [               num_iterations, 450]\n",
       "7                        [num_leaves, 3]\n",
       "8                  [objective, 'binary']\n",
       "9      [               random_state, 42]\n",
       "10                 [scale_pos_weight, 2]\n",
       "11                     [subsample, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['var'] = df['var'].str.split(\"=\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var1'] = df['var'].str[0]\n",
    "df['var2'] = df['var'].str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[colsample_bytree, 0.4]</td>\n",
       "      <td>colsample_bytree</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[learning_rate, 0.02]</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[max_delta_step, 0.8]</td>\n",
       "      <td>max_delta_step</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[               max_depth, None]</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[metric, 'binary_logloss']</td>\n",
       "      <td>metric</td>\n",
       "      <td>'binary_logloss'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[n_estimators, None]</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[               num_iterations, 450]</td>\n",
       "      <td>num_iterations</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[num_leaves, 3]</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[objective, 'binary']</td>\n",
       "      <td>objective</td>\n",
       "      <td>'binary'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[               random_state, 42]</td>\n",
       "      <td>random_state</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[scale_pos_weight, 2]</td>\n",
       "      <td>scale_pos_weight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[subsample, None]</td>\n",
       "      <td>subsample</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     var                           var1  \\\n",
       "0                [colsample_bytree, 0.4]               colsample_bytree   \n",
       "1                  [learning_rate, 0.02]                  learning_rate   \n",
       "2                  [max_delta_step, 0.8]                 max_delta_step   \n",
       "3       [               max_depth, None]                      max_depth   \n",
       "4             [metric, 'binary_logloss']                         metric   \n",
       "5                   [n_estimators, None]                   n_estimators   \n",
       "6   [               num_iterations, 450]                 num_iterations   \n",
       "7                        [num_leaves, 3]                     num_leaves   \n",
       "8                  [objective, 'binary']                      objective   \n",
       "9      [               random_state, 42]                   random_state   \n",
       "10                 [scale_pos_weight, 2]               scale_pos_weight   \n",
       "11                     [subsample, None]                      subsample   \n",
       "\n",
       "                var2  \n",
       "0                0.4  \n",
       "1               0.02  \n",
       "2                0.8  \n",
       "3               None  \n",
       "4   'binary_logloss'  \n",
       "5               None  \n",
       "6                450  \n",
       "7                  3  \n",
       "8           'binary'  \n",
       "9                 42  \n",
       "10                 2  \n",
       "11              None  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_column'] = df['codes'].str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_column'] = [l[0] if len(l) > 0 else np.nan for l in df['codes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = \"colsample_bytree=0.4, learning_rate=0.02, max_delta_step=0.8, \\\n",
    "               max_depth=None, metric='binary_logloss', n_estimators=None, \\\n",
    "               num_iterations=450, num_leaves=3, objective='binary', \\\n",
    "               random_state=42, scale_pos_weight=2, subsample=None, \\\n",
    "'boosting_type': 'gbdt', 'colsample_bytree': 0.4, 'learning_rate': 0.02, 'max_delta_step': 0.8, \\\n",
    "                'max_depth': None, 'metric': 'binary_logloss', 'n_estimators': None, \\\n",
    "                'num_iterations': 450, 'num_leaves': 3, 'objective': 'binary', \\\n",
    "                'scale_pos_weight': 2, 'subsample': None, \\\n",
    "Best Score: 0.7913043478260869, Best Index: 84963, \\\n",
    "train accuracy: 0.9826, val accuracy= 0.8621, test accuracy= 0.7568, \\\n",
    "precision : 0.6667, recall : 0.7143, f1score : 0.6897, roc : 0.7484, \\\n",
    "tn= 18, fp=5, fn=4, tp=10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(b.split(\", \"), columns=['var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var1'] = df['var'].str.replace(\":\", \"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var2'] = df['var1'].str.split(\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['param'] = df['var2'].str[0]\n",
    "df['value'] = df['var2'].str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['param', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colsample_bytree</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_delta_step</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_depth</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metric</td>\n",
       "      <td>'binary_logloss'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_iterations</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_leaves</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>objective</td>\n",
       "      <td>'binary'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>random_state</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>scale_pos_weight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subsample</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'boosting_type'</td>\n",
       "      <td>'gbdt'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'colsample_bytree'</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'learning_rate'</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'max_delta_step'</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'max_depth'</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'metric'</td>\n",
       "      <td>'binary_logloss'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'n_estimators'</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'num_iterations'</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>'num_leaves'</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'objective'</td>\n",
       "      <td>'binary'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'scale_pos_weight'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'subsample'</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.7913043478260869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Best Index</td>\n",
       "      <td>84963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train accuracy</td>\n",
       "      <td>0.9826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>val accuracy</td>\n",
       "      <td>0.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test accuracy</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>f1score</td>\n",
       "      <td>0.6897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>roc</td>\n",
       "      <td>0.7484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tn</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fp</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fn</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tp</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 param                value\n",
       "0                     colsample_bytree                  0.4\n",
       "1                        learning_rate                 0.02\n",
       "2                       max_delta_step                  0.8\n",
       "3                            max_depth                 None\n",
       "4                               metric     'binary_logloss'\n",
       "5                         n_estimators                 None\n",
       "6                       num_iterations                  450\n",
       "7                           num_leaves                    3\n",
       "8                            objective             'binary'\n",
       "9                         random_state                   42\n",
       "10                    scale_pos_weight                    2\n",
       "11                           subsample                 None\n",
       "12                     'boosting_type'               'gbdt'\n",
       "13                  'colsample_bytree'                  0.4\n",
       "14                     'learning_rate'                 0.02\n",
       "15                    'max_delta_step'                  0.8\n",
       "16                         'max_depth'                 None\n",
       "17                            'metric'     'binary_logloss'\n",
       "18                      'n_estimators'                 None\n",
       "19                    'num_iterations'                  450\n",
       "20                        'num_leaves'                    3\n",
       "21                         'objective'             'binary'\n",
       "22                  'scale_pos_weight'                    2\n",
       "23                         'subsample'                 None\n",
       "24                          Best Score   0.7913043478260869\n",
       "25                          Best Index                84963\n",
       "26                      train accuracy               0.9826\n",
       "27                        val accuracy               0.8621\n",
       "28                       test accuracy               0.7568\n",
       "29                          precision                0.6667\n",
       "30                             recall                0.7143\n",
       "31                            f1score                0.6897\n",
       "32                                roc                0.7484\n",
       "33                                  tn                   18\n",
       "34                                  fp                    5\n",
       "35                                  fn                    4\n",
       "36                                  tp                   10"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
