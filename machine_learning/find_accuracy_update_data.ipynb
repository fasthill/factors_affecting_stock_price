{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlS4gyYqJVpn"
   },
   "source": [
    "# 예측이 가능한 종목 추리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQBDVUjBbIsL"
   },
   "source": [
    "## 가장 좋은 결과를 낼 수 있는 feature항목 추출\n",
    "## 모든 feature를 사용한 결과와, 선택 추출된 feature만 사용한 결과 정확도에 차이가 남\n",
    "#### logistic 회귀 이용하여 coef_ 항목에서 영향력이 높은 feature를 선택. 최적의 갯수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILi_LPl9JVpw"
   },
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EwImyTS9S3QQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀후에 .coef_ 항목에서 기준(criteria, 계수)보다 높은 영향력을 미치는 feature column 선택\n",
    "def select_features(df, coef, criteria):\n",
    "    sel_num = np.where(np.abs(coef) > criteria )[1]\n",
    "    sel_col = df.columns[sel_num]\n",
    "    return sel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data, target):\n",
    "    train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "\n",
    "    lr = LogisticRegression(C=20, max_iter=4000) # max_iter default 100, \n",
    "#     lr = LogisticRegression(C=1, solver='newton_cg', max_iter=1000) # max_iter default 100, \n",
    "    lr.fit(train_scaled, train_target)\n",
    "\n",
    "    train_score = lr.score(train_scaled, train_target)\n",
    "    test_score = lr.score(test_scaled, test_target)\n",
    "#     print(f'train score: {train_score:.4f} \\n test score; {test_score:.4f}')\n",
    "    return train_score, test_score, lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_result(data, target):\n",
    "# min을 하나씩 제거하면서 최고의 결과를 가져오는 feature갯수(항목) 선택\n",
    "\n",
    "    train_score_list= []\n",
    "    test_score_list = []\n",
    "#     data_columns = []\n",
    "#     data_coef = []\n",
    "    test_s = 0\n",
    "    train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "    for _ in range(len(data.columns)-1):\n",
    "        criteria = np.abs(coef).min()\n",
    "        sel_col = select_features(data, coef, criteria)\n",
    "        data = df[sel_col]\n",
    "        train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "\n",
    "        if test_score > test_s:\n",
    "            test_s = test_score\n",
    "            data_columns = sel_col\n",
    "            data_coef = coef\n",
    "\n",
    "        train_score_list.append(train_score)\n",
    "        test_score_list.append(test_score)\n",
    "    \n",
    "    return train_score_list, test_score_list, data_columns, data_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(inp_num, a_layer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='sigmoid', input_shape=(inp_num,)))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.1))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix to list 변환\n",
    "def matrix_to_list(matrix):\n",
    "    m_list = []\n",
    "    for cm in confu_matrix:\n",
    "        name = cm[0]\n",
    "        tn = cm[1][0,0]\n",
    "        fp = cm[1][0,1]\n",
    "        fn = cm[1][1,0]\n",
    "        tp = cm[1][1,1]\n",
    "        m_list.append([name, tn, fp, fn, tp])\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "# code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AA63B76160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AA64D0C310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# 분석용 데이터 입력\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "logi_accuracy = []\n",
    "sgd_accuracy = []\n",
    "deep_accuracy = []\n",
    "confu_matrix = []\n",
    "for key, val in code.items():\n",
    "    f_name= 'df_{}_{}.pkl'.format(val[1], 'sel')\n",
    "    fname = directory_for_ml + f_name\n",
    "    df = pd.read_pickle(fname)\n",
    "    \n",
    "    data = df.iloc[:, :-5]\n",
    "    target = df.iloc[:, -4]\n",
    "    \n",
    "    # logisticregression 결과 모으기\n",
    "    train_score_list, test_score_list, data_columns, data_coef = find_best_result(data, target)\n",
    "    logi_accuracy.append([val[1], max(train_score_list), max(test_score_list)])\n",
    "    \n",
    "    # SGDregressor 결과 모으기\n",
    "    data_new = data[data_columns] # 선택된 주요 column (feature) 만으로 정확도 계산하기\n",
    "    train_input, test_input, train_target, test_target \\\n",
    "        = train_test_split(data_new, target, random_state=42, test_size=0.2, stratify=target)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    sgd_value = []\n",
    "    for iter in range(5, 50, 1):\n",
    "        sc = SGDClassifier(loss='log', max_iter=iter, random_state=42)\n",
    "        scores = cross_validate(sc, X=train_scaled, y=train_target, n_jobs=-1)\n",
    "        sgd_value.append(scores['test_score'].mean())\n",
    "        \n",
    "    sgd_accuracy.append([val[1], max(sgd_value)])\n",
    "    \n",
    "    # 인공신경망\n",
    "    try :\n",
    "        model = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model = model_fn(len(data_new.columns))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    # checkpoint_cb = ModelCheckpoint(filepath='best_model_{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5', \\\n",
    "#                                                 monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "    checkpoint_cb = ModelCheckpoint(filepath='best_model.h5', save_best_only=True)\n",
    "# earlystopping_cb = EarlyStopping(patience=100, monitor='val_accuracy', mode='max', restore_best_weights=True)\n",
    "    earlystopping_cb = EarlyStopping(patience=100, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(train_scaled, train_target, epochs=2000, verbose=0,\n",
    "                        callbacks=[checkpoint_cb, earlystopping_cb],\n",
    "                        validation_data=(test_scaled, test_target))\n",
    "    \n",
    "    y_predict = model.predict(np.array(test_scaled), verbose=0)\n",
    "    y_predict_list = [1 if i > 0.5 else 0 for i in y_predict[:, 0]]\n",
    "    \n",
    "# 정밀도 : 양성으로 예측된 것(TP+FP) 중 얼마나 많은 샘플이 진짜 양성(TP)인지 측정\n",
    "#     precision_score(test_target, y_predict_list)  # 정밀도, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     recall_score(test_target, y_predict_list)  # 재현율, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     f1_score(test_target, y_predict_list)\n",
    "#     roc_auc_score(test_target, y_predict_list)  \n",
    "    score = model.evaluate(test_scaled, test_target, verbose=0)\n",
    "    deep_accuracy.append([val[1], \n",
    "                          score[0], score[1],\n",
    "                          precision_score(test_target, y_predict_list),\n",
    "                          recall_score(test_target, y_predict_list),\n",
    "                          f1_score(test_target, y_predict_list),\n",
    "                          roc_auc_score(test_target, y_predict_list)  \n",
    "                         ]) \n",
    "    \n",
    "    confu_matrix.append([val[1], confusion_matrix(test_target, y_predict_list)])\n",
    "    \n",
    "    df_logi = pd.DataFrame(logi_accuracy, columns=['name', 'train_max', 'test_max']).set_index('name')\n",
    "    df_sgd = pd.DataFrame(sgd_accuracy, columns=['name', 'sgd_accuracy']).set_index('name')\n",
    "    df_deep = pd.DataFrame(deep_accuracy, \n",
    "                       columns=['name', 'val_loss', 'val_accuracy', 'precision', 'recall', 'f1_score', ' roc_auc_score']).set_index('name')\n",
    "    df_confu_matrix = pd.DataFrame(matrix_to_list(confu_matrix), columns = ['name', 'tn', 'fp', 'fn', 'tp']).set_index('name')\n",
    "\n",
    "    dfs = [df_logi, df_sgd, df_deep, df_confu_matrix ]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right, how='left', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.775858</td>\n",
       "      <td>0.528714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgenergy</th>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.648571</td>\n",
       "      <td>0.545101</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skhinix</th>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.477002</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssbio</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.675699</td>\n",
       "      <td>0.639811</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sdi</th>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.731984</td>\n",
       "      <td>0.604626</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgchemical</th>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.727800</td>\n",
       "      <td>0.460389</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.786713</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secpre</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.273694</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyunmotor</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.543970</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naver</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714170</td>\n",
       "      <td>0.380238</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.806034</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kia</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.648589</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.657738</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kakao</th>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.766145</td>\n",
       "      <td>0.496595</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.796992</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscoholding</th>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.688974</td>\n",
       "      <td>0.587578</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbbank</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.606807</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sscnt</th>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.743692</td>\n",
       "      <td>0.475179</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.788603</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celltrion</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.618366</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobis</th>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.682020</td>\n",
       "      <td>0.585929</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shgroup</th>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.693390</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgelec</th>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.497073</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscochemical</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.665263</td>\n",
       "      <td>0.676066</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skinnovation</th>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.742381</td>\n",
       "      <td>0.575332</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.726721</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ktng</th>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.689225</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_max  test_max  sgd_accuracy  val_loss  val_accuracy  \\\n",
       "name                                                                       \n",
       "sec             0.883178  0.814815      0.775858  0.528714      0.777778   \n",
       "lgenergy        0.776536  0.733333      0.648571  0.545101      0.777778   \n",
       "skhinix         0.878049  0.788462      0.814634  0.477002      0.769231   \n",
       "ssbio           0.814570  0.684211      0.675699  0.639811      0.605263   \n",
       "sdi             0.829897  0.693878      0.731984  0.604626      0.734694   \n",
       "lgchemical      0.837696  0.791667      0.727800  0.460389      0.791667   \n",
       "secpre          1.000000  0.894737      0.819048  0.273694      0.842105   \n",
       "hyunmotor       0.789474  0.791667      0.705263  0.543970      0.791667   \n",
       "naver           0.854167  0.857143      0.714170  0.380238      0.816327   \n",
       "kia             0.783333  0.755556      0.672222  0.648589      0.666667   \n",
       "kakao           0.861702  0.808511      0.766145  0.496595      0.808511   \n",
       "poscoholding    0.821429  0.720000      0.688974  0.587578      0.700000   \n",
       "kbbank          0.800000  0.690476      0.672727  0.606807      0.690476   \n",
       "sscnt           0.883721  0.787879      0.743692  0.475179      0.787879   \n",
       "celltrion       0.783333  0.700000      0.625000  0.618366      0.733333   \n",
       "mobis           0.872340  0.805556      0.682020  0.585929      0.777778   \n",
       "shgroup         0.782895  0.684211      0.606452  0.693390      0.473684   \n",
       "lgelec          0.868750  0.731707      0.731250  0.497073      0.804878   \n",
       "poscochemical   0.843750  0.640000      0.665263  0.676066      0.640000   \n",
       "skinnovation    0.848315  0.688889      0.742381  0.575332      0.733333   \n",
       "ktng            0.753247  0.641026      0.669677  0.689225      0.538462   \n",
       "\n",
       "               precision    recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                                          \n",
       "sec             0.800000  0.666667  0.727273        0.766667  26   4   8  16  \n",
       "lgenergy        0.750000  0.875000  0.807692        0.770833  14   7   3  21  \n",
       "skhinix         0.727273  0.727273  0.727273        0.763636  24   6   6  16  \n",
       "ssbio           0.615385  0.444444  0.516129        0.597222  15   5  10   8  \n",
       "sdi             0.750000  0.720000  0.734694        0.735000  18   6   7  18  \n",
       "lgchemical      0.800000  0.727273  0.761905        0.786713  22   4   6  16  \n",
       "secpre          0.800000  0.666667  0.727273        0.794872  12   1   2   4  \n",
       "hyunmotor       0.823529  0.666667  0.736842        0.777778  24   3   7  14  \n",
       "naver           0.789474  0.750000  0.769231        0.806034  25   4   5  15  \n",
       "kia             0.687500  0.523810  0.594595        0.657738  19   5  10  11  \n",
       "kakao           0.777778  0.736842  0.756757        0.796992  24   4   5  14  \n",
       "poscoholding    0.666667  0.695652  0.680851        0.699678  19   8   7  16  \n",
       "kbbank          0.666667  0.700000  0.682927        0.690909  15   7   6  14  \n",
       "sscnt           0.764706  0.812500  0.787879        0.788603  13   4   3  13  \n",
       "celltrion       0.705882  0.800000  0.750000        0.733333  10   5   3  12  \n",
       "mobis           0.733333  0.733333  0.733333        0.771429  17   4   4  11  \n",
       "shgroup         0.476190  0.526316  0.500000        0.473684   8  11   9  10  \n",
       "lgelec          0.789474  0.789474  0.789474        0.803828  18   4   4  15  \n",
       "poscochemical   0.625000  0.769231  0.689655        0.634615   6   6   3  10  \n",
       "skinnovation    0.684211  0.684211  0.684211        0.726721  20   6   6  13  \n",
       "ktng            0.545455  0.600000  0.571429        0.536842   9  10   8  12  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 0.7\n",
    "sgd_accuracy = 0.7\n",
    "val_accuracy = 0.7\n",
    "precision = 0.7\n",
    "fi_score = 0.7\n",
    "ratio_min = 0.4\n",
    "ratio_max = 0.6\n",
    "\n",
    "ratio = ((df_merged['fn'] + df_merged['tp']) / (df_merged['tn'] + df_merged['fp'] + df_merged['fn'] + df_merged['tp']))\n",
    "df_sel = (df_merged['test_max'] >= test_max) & \\\n",
    "        (df_merged['sgd_accuracy'] >= sgd_accuracy) & \\\n",
    "        (df_merged['val_accuracy'] >= val_accuracy) & \\\n",
    "        (df_merged['precision'] >= precision) & \\\n",
    "        (df_merged['f1_score'] >= fi_score) & \\\n",
    "        (ratio_min < ratio ) & (ratio < ratio_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>0.883178</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.775858</td>\n",
       "      <td>0.528714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skhinix</th>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.477002</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgchemical</th>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.727800</td>\n",
       "      <td>0.460389</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.786713</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyunmotor</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.543970</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naver</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714170</td>\n",
       "      <td>0.380238</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.806034</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kakao</th>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.766145</td>\n",
       "      <td>0.496595</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.796992</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sscnt</th>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.743692</td>\n",
       "      <td>0.475179</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.788603</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgelec</th>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.497073</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_max  test_max  sgd_accuracy  val_loss  val_accuracy  \\\n",
       "name                                                                    \n",
       "sec          0.883178  0.814815      0.775858  0.528714      0.777778   \n",
       "skhinix      0.878049  0.788462      0.814634  0.477002      0.769231   \n",
       "lgchemical   0.837696  0.791667      0.727800  0.460389      0.791667   \n",
       "hyunmotor    0.789474  0.791667      0.705263  0.543970      0.791667   \n",
       "naver        0.854167  0.857143      0.714170  0.380238      0.816327   \n",
       "kakao        0.861702  0.808511      0.766145  0.496595      0.808511   \n",
       "sscnt        0.883721  0.787879      0.743692  0.475179      0.787879   \n",
       "lgelec       0.868750  0.731707      0.731250  0.497073      0.804878   \n",
       "\n",
       "            precision    recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                                       \n",
       "sec          0.800000  0.666667  0.727273        0.766667  26   4   8  16  \n",
       "skhinix      0.727273  0.727273  0.727273        0.763636  24   6   6  16  \n",
       "lgchemical   0.800000  0.727273  0.761905        0.786713  22   4   6  16  \n",
       "hyunmotor    0.823529  0.666667  0.736842        0.777778  24   3   7  14  \n",
       "naver        0.789474  0.750000  0.769231        0.806034  25   4   5  15  \n",
       "kakao        0.777778  0.736842  0.756757        0.796992  24   4   5  14  \n",
       "sscnt        0.764706  0.812500  0.787879        0.788603  13   4   3  13  \n",
       "lgelec       0.789474  0.789474  0.789474        0.803828  18   4   4  15  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 정밀도, f1-score, \n",
    "2. confusion matrix ((1,1), (2,2), 두개가 큰 비중이면 good, (1,2)은 틀린것을 맞다라고 구분, (2,1)은 맞는 것을 틀린 것이다 라고 결정하는 항목) 따라서\n",
    "    (2,2) -> (1,2) -> (1,1)로 확인하고. <br>\n",
    "    (1,2)가 크면 모델 제외 (정밀도(precision = TP / (TP + FP) )가 높아야 함. 낮으면 손해를 보게 됨.), <br>\n",
    "    재현율(Recall = TP / (TP + FN) ) 은 손해를 끼치지는 않음.\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/fasthill/My-gist/main/data/picture/confusion_matrix.png\" width=\"800\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수수료: 주식거래수수료 0.015%. 유관기관수수료 0.0036%, 증권거래세 0.08, 농어촌 특별세 0.15%\n",
    "수수료 : (0.015+0.0036 ) * 2 (사고팔때), 증권거래세 : 0.08 + 0.15 (팔때)\n",
    "전체 지출 금액율: 0.2672%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-1 로지스틱 회귀.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
