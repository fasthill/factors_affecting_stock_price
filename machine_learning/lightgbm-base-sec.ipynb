{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_list = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'value{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target,\n",
    "                 test_scaled1, test_scaled2, test_scaled3, test_target1, test_target2, test_target3):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbmgs.best_score_ \n",
    "    result_dict['best_index'] = lgbmgs.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled1)\n",
    "    result_dict['acc_test1'] = model.score(test_scaled1, test_target1)\n",
    "    result_dict['precision1'] = precision_score(test_target1, y_predict)\n",
    "    result_dict['recall1'] = recall_score(test_target1, y_predict)\n",
    "    result_dict['f1score1'] = f1_score(test_target1, y_predict)\n",
    "    result_dict['roc1'] = roc_auc_score(test_target1, y_predict)\n",
    "    cm = confusion_matrix(test_target1, y_predict)\n",
    "    result_dict['tn1'] = cm[0,0]\n",
    "    result_dict['fp1'] = cm[0,1]\n",
    "    result_dict['fn1'] = cm[1,0]\n",
    "    result_dict['tp1'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled2)\n",
    "    result_dict['acc_test2'] = model.score(test_scaled2, test_target2)\n",
    "    result_dict['precision2'] = precision_score(test_target2, y_predict)\n",
    "    result_dict['recall2'] = recall_score(test_target2, y_predict)\n",
    "    result_dict['f1score2'] = f1_score(test_target2, y_predict)\n",
    "    result_dict['roc2'] = roc_auc_score(test_target2, y_predict)\n",
    "    cm = confusion_matrix(test_target2, y_predict)\n",
    "    result_dict['tn2'] = cm[0,0]\n",
    "    result_dict['fp2'] = cm[0,1]\n",
    "    result_dict['fn2'] = cm[1,0]\n",
    "    result_dict['tp2'] = cm[1,1]\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled3)\n",
    "    result_dict['acc_test3'] = model.score(test_scaled3, test_target3)\n",
    "    result_dict['precision3'] = precision_score(test_target3, y_predict)\n",
    "    result_dict['recall3'] = recall_score(test_target3, y_predict)\n",
    "    result_dict['f1score3'] = f1_score(test_target3, y_predict)\n",
    "    result_dict['roc3'] = roc_auc_score(test_target3, y_predict)\n",
    "    cm = confusion_matrix(test_target3, y_predict)\n",
    "    result_dict['tn3'] = cm[0,0]\n",
    "    result_dict['fp3'] = cm[0,1]\n",
    "    result_dict['fn3'] = cm[1,0]\n",
    "    result_dict['tp3'] = cm[1,1]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1',\n",
    "       'pension_1', 'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1',\n",
    "       'corporateetc_1', 'foreigneretc_1', 'dji_cr', 'dji_f_cr', 'ixic_cr',\n",
    "       'ixic_f_cr', 'spx_cr', 'spx_f_cr', 'bond_kor_10_cr', 'bond_kor_2_cr',\n",
    "       'dxy_cr', 'bond_usa_10_cr', 'bond_usa_2_cr', 'bond_usa_3m_cr',\n",
    "       'kosdaq_cr', 'kospi_cr', 'krw_cr', 'sox_cr', 'vix_cr', 'wti_cr',\n",
    "       'open_1', 'high_1', 'low_1', 'close_1', 'vol_1', 'retail_2',\n",
    "       'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2',\n",
    "       'pension_2', 'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2',\n",
    "       'corporateetc_2', 'foreigneretc_2', 'dji_cr_2', 'dji_f_cr_2',\n",
    "       'ixic_cr_2', 'ixic_f_cr_2', 'spx_cr_2', 'spx_f_cr_2',\n",
    "       'bond_kor_10_cr_2', 'bond_kor_2_cr_2', 'dxy_cr_2', 'bond_usa_10_cr_2',\n",
    "       'bond_usa_2_cr_2', 'bond_usa_3m_cr_2', 'kosdaq_cr_2', 'kospi_cr_2',\n",
    "       'krw_cr_2', 'sox_cr_2', 'vix_cr_2', 'wti_cr_2', 'open_2', 'high_2',\n",
    "       'low_2', 'close_2', 'vol_2', 'weekday', 'cr_00', 'cr_05', 'cr_10',\n",
    "       'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_name = 'sec'\n",
    "fname = f'df_{com_name}_sel.pkl'\n",
    "directory_for_ml = '../data/data_for_ml/expand_date/'\n",
    "\n",
    "# fname = f'df_shgroup_sel.pkl'\n",
    "# stock_name = 'shgroup'\n",
    "directory_for_ml = '../data/data_for_ml/expand_date/'\n",
    "f_name = directory_for_ml + fname\n",
    "df = pd.read_pickle(f_name) \n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   \n",
    "\n",
    "df = df[new_col]\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -4]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -4]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -4]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -4]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -4]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_base = {'boosting_type' : ['gbdt'], # ['gbdt', dart', 'goss'], # dart : 신경망의 드롭아웃을 적용시킨 방법, \n",
    "              'num_leaves' :  [4, 5, 6, 7], # 두번째로 중요, num_leaves는 작은 데이터면 작은 숫자로\n",
    "              'learning_rate' :  [0.003, 0.004, 0.005, 0.006],\n",
    "#               'max_delta_step' :  [0.4, 0.5, 0.6],\n",
    "              'n_estimators' :  [150, 200, 300, 400],\n",
    "              'colsample_bytree' :  [0.7], # = feature fraction, column sampling. 위의 subsample과 같이 튜닝.\n",
    "              'subsample' :  [0.7],# 세번째로 중요. = bagging fraction, row sampling. 아래 colsample_bytree과 같이 튜닝.\n",
    "              'max_depth' :  [-1], # 가장 먼저 튜닝 필요 -1이 default (무한깊이) 일반적으로 default가 가장 좋음.\n",
    "              'objective': ['binary'],\n",
    "              'metric': ['binary_logloss'],\n",
    "              'scale_pos_weight': [1.5, 2, 2.5, 3.0], # posiive  증가, class imbalance 경감, scale_pos_weight > 0.0, default=1.0. \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_o = param_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbmgs ******\n",
      "Fitting 7 folds for each of 256 candidates, totalling 1792 fits\n",
      "**** End of Process ****\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(com_name):\n",
    "    os.makedirs(com_name)\n",
    "    \n",
    "iter = 4\n",
    "while True:\n",
    "    iter = iter + 1\n",
    "\n",
    "    lgbm = None\n",
    "    lgbmgs = None\n",
    "\n",
    "    lgbm = lightgbm.LGBMClassifier(random_state=42)\n",
    "\n",
    "    lgbmgs = GridSearchCV(estimator = lgbm,\n",
    "                          param_grid = params_o,\n",
    "                          cv = 7, # StratifiedKFold us default for binary or multiclass\n",
    "                          scoring = 'precision', \n",
    "#                           scoring = 'accuracy', \n",
    "#                           scoring = ['accuracy', 'precision'], # refit 사용해야 함. 고로 사용하지 않음.\n",
    "                          error_score='raise',\n",
    "                          verbose = 1,\n",
    "                          n_jobs=-1, # 자동 검색 적용\n",
    "                         )\n",
    "                          \n",
    "    print(\"*** after lgbmgs ******\")\n",
    "    lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "#     lgbmgs.fit(train_scaled, train_target, eval_metric = 'logloss', eval_set = (val_scaled, val_target)) \n",
    "    # eval_set가 있어야 \"early_stopping_rounds\"를 사용할 수 있음.\n",
    "\n",
    "# save model\n",
    "    stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "    dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "    joblib.dump(lgbmgs, f'./{com_name}/lgbm_v{iter}_{dt}.pkl') # gridsearchcv 저장\n",
    "    joblib.dump(scaler, f'./{com_name}/scaler_v{iter}_{dt}.pkl') # scaler 저장\n",
    "    \n",
    "    df_estimator = make_df_from_estimator(lgbmgs.best_estimator_.get_params(), iter)\n",
    "    result_dict = calc_results(lgbmgs.best_estimator_, \n",
    "                               train_scaled, val_scaled, test_scaled,  \n",
    "                               train_target, val_target, test_target,\n",
    "                               test_scaled1, test_scaled2, test_scaled3,  \n",
    "                               test_target1, test_target2, test_target3\n",
    "                              )\n",
    "    \n",
    "    df_result = make_df_from_estimator(result_dict, iter)\n",
    "    df_concat = pd.concat([df_estimator, df_result])\n",
    "\n",
    "    df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "#  4가지 조건이 만족되면 break하고 완료\n",
    "    val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "    acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "    precision = df_concat.loc['precision'].iloc[0]\n",
    "    f1score = df_concat.loc['f1score'].iloc[0]\n",
    "    \n",
    "    if (val_test >= 0.75 ) & (acc_test > 0.75) & (precision >= 0.8) & (f1score >= 0.6) :\n",
    "        df_base.to_csv(f'./{com_name}/lgbm_ver{iter}_df_{dt}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_ver{iter}_df_{dt}.pkl')\n",
    "        break\n",
    "    if iter >= 1 : \n",
    "        df_base.to_csv(f'./{com_name}/lgbm_ver{iter}_df_{dt}.csv')\n",
    "        df_base.to_pickle(f'./{com_name}/lgbm_ver{iter}_df_{dt}.pkl')\n",
    "        break\n",
    "    print(\"******* No.{}  Process is Done! ********\".format(iter))\n",
    "    params_o = make_new_parameter(params_o, df_concat)\n",
    "    save_to_pickle(f'./{com_name}/params_ver{iter}_{dt}.pkl', params_o)\n",
    "    \n",
    "print(\"**** End of Process ****\")\n",
    "# save model, save df, stoppping 기준 수립\n",
    "# 일단위로 정확도 측정, 정확도, 정밀도?\n",
    "\n",
    "# eval_set, early_stopping_rounds 내용 확인 필. \">\" 에러 확인.\n",
    "# 집어 넣으면 에러 발생하니, 원인을 찾아야 함. 하면 좋은 이유는?\n",
    "\n",
    "# scoring = ['accuracy', 'precision'] 두가지 param 선언이 안되나?\n",
    "# Precision is ill-defined and being set to 0.0 due to no predicted samples.  왜 나오나 확인해야 함.\n",
    "# .predict로 하면 positive로 예측하는 경우가 발생하지 않음. \n",
    "\n",
    "\n",
    "# feature_importance 확인하고 중요한 feature만 갖고 분석해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value5_x</th>\n",
       "      <th>value5_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.77381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>140.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.796512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.629934</td>\n",
       "      <td>0.629934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test1</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc1</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test2</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall2</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc2</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test3</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc3</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         value5_x        value5_y\n",
       "parameter                                        \n",
       "objective                  binary          binary\n",
       "random_state                   42              42\n",
       "reg_alpha                     0.0             0.0\n",
       "reg_lambda                    0.0             0.0\n",
       "silent                       warn            warn\n",
       "subsample                     0.7             0.7\n",
       "subsample_for_bin          200000          200000\n",
       "subsample_freq                  0               0\n",
       "metric             binary_logloss  binary_logloss\n",
       "scale_pos_weight              1.5             1.5\n",
       "best_score                  0.625         0.77381\n",
       "best_index                  140.0            84.0\n",
       "acc_train                0.813953        0.796512\n",
       "acc_val                  0.744186        0.767442\n",
       "acc_test                 0.759259        0.759259\n",
       "precision                0.714286        0.714286\n",
       "recall                     0.3125          0.3125\n",
       "f1score                  0.434783        0.434783\n",
       "roc                      0.629934        0.629934\n",
       "tn                           36.0            36.0\n",
       "fp                            2.0             2.0\n",
       "fn                           11.0            11.0\n",
       "tp                            5.0             5.0\n",
       "acc_test1                0.722222        0.722222\n",
       "precision1               0.666667        0.666667\n",
       "recall1                  0.333333        0.333333\n",
       "f1score1                 0.444444        0.444444\n",
       "roc1                        0.625           0.625\n",
       "tn1                          11.0            11.0\n",
       "fp1                           1.0             1.0\n",
       "fn1                           4.0             4.0\n",
       "tp1                           2.0             2.0\n",
       "acc_test2                0.777778        0.777778\n",
       "precision2                    1.0             1.0\n",
       "recall2                  0.428571        0.428571\n",
       "f1score2                      0.6             0.6\n",
       "roc2                     0.714286        0.714286\n",
       "tn2                          11.0            11.0\n",
       "fp2                           0.0             0.0\n",
       "fn2                           4.0             4.0\n",
       "tp2                           3.0             3.0\n",
       "acc_test3                0.777778        0.777778\n",
       "precision3                    0.0             0.0\n",
       "recall3                       0.0             0.0\n",
       "f1score3                      0.0             0.0\n",
       "roc3                     0.466667        0.466667\n",
       "tn3                          14.0            14.0\n",
       "fp3                           1.0             1.0\n",
       "fn3                           3.0             3.0\n",
       "tp3                           0.0             0.0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(colsample_bytree=0.5, learning_rate=0.004,\n",
      "               metric='binary_logloss', n_estimators=200, num_leaves=6,\n",
      "               objective='binary', random_state=42, scale_pos_weight=2.5,\n",
      "               subsample=0.5)\n"
     ]
    }
   ],
   "source": [
    "print(lgbmgs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----after test : 1 ------\n",
      "accu_all: 0.6111, precision: 0.0000, recall: 0.0000, f1_score: 0.0000\n",
      "tn: 11, fp: 1, fn: 6, tp: 0\n",
      "--------------------------------\n",
      "----after test : 2 ------\n",
      "accu_all: 0.7222, precision: 1.0000, recall: 0.2857, f1_score: 0.4444\n",
      "tn: 11, fp: 0, fn: 5, tp: 2\n",
      "--------------------------------\n",
      "----after test : 3 ------\n",
      "accu_all: 0.8333, precision: 0.0000, recall: 0.0000, f1_score: 0.0000\n",
      "tn: 15, fp: 0, fn: 3, tp: 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#     num_t = 3\n",
    "for num_t in range(1, 4, 1):\n",
    "    test_scaled = globals()[f'test_scaled{num_t}']\n",
    "    test_target = globals()[f'test_target{num_t}']\n",
    "    model = lgbmgs.best_estimator_\n",
    "    accu_all = model.score(test_scaled, test_target)\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    precision = precision_score(test_target, y_predict)\n",
    "    recall = recall_score(test_target, y_predict)\n",
    "    f1s = f1_score(test_target, y_predict)\n",
    "\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    tn = cm[0,0]\n",
    "    fp = cm[0,1]\n",
    "    fn = cm[1,0]\n",
    "    tp = cm[1,1]\n",
    "    print(f\"----after test : {num_t} ------\")\n",
    "    print(f\"accu_all: {accu_all:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1_score: {f1s:.4f}\")\n",
    "    print(f\"tn: {tn}, fp: {fp}, fn: {fn}, tp: {tp}\")\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ixic_f_cr</th>\n",
       "      <td>2169.041734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox_cr</th>\n",
       "      <td>1427.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_cr</th>\n",
       "      <td>699.888465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sox_cr_2</th>\n",
       "      <td>674.407957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank_1</th>\n",
       "      <td>623.178323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity_2</th>\n",
       "      <td>602.887969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vix_cr_2</th>\n",
       "      <td>543.902978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporateetc_1</th>\n",
       "      <td>419.139531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxy_cr_2</th>\n",
       "      <td>392.885578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low_1</th>\n",
       "      <td>371.468644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ixic_cr_2</th>\n",
       "      <td>319.822622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2</th>\n",
       "      <td>304.031809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_2</th>\n",
       "      <td>303.713592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_10_cr</th>\n",
       "      <td>293.889340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corporateetc_2</th>\n",
       "      <td>229.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr</th>\n",
       "      <td>221.417799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxy_cr</th>\n",
       "      <td>216.150880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>privequity_1</th>\n",
       "      <td>191.585672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank_2</th>\n",
       "      <td>177.474581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>165.440849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr_2</th>\n",
       "      <td>161.600631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance_2</th>\n",
       "      <td>147.908399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreigneretc_2</th>\n",
       "      <td>140.661031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invtrust_2</th>\n",
       "      <td>138.449999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr</th>\n",
       "      <td>130.924698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_cr_2</th>\n",
       "      <td>127.241138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_10_cr_2</th>\n",
       "      <td>101.443330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution_2</th>\n",
       "      <td>95.732230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_3m_cr_2</th>\n",
       "      <td>92.662409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail_1</th>\n",
       "      <td>87.779610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_usa_2_cr_2</th>\n",
       "      <td>83.294108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bond_kor_2_cr</th>\n",
       "      <td>74.564001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close_2</th>\n",
       "      <td>66.416481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_cr</th>\n",
       "      <td>59.105329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pension_1</th>\n",
       "      <td>54.729630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dji_f_cr_2</th>\n",
       "      <td>50.212930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spx_f_cr_2</th>\n",
       "      <td>44.955810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_1</th>\n",
       "      <td>39.748939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kosdaq_cr_2</th>\n",
       "      <td>37.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kospi_cr_2</th>\n",
       "      <td>32.743710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance\n",
       "ixic_f_cr         2169.041734\n",
       "sox_cr            1427.509500\n",
       "ixic_cr            699.888465\n",
       "sox_cr_2           674.407957\n",
       "bank_1             623.178323\n",
       "privequity_2       602.887969\n",
       "vix_cr_2           543.902978\n",
       "corporateetc_1     419.139531\n",
       "dxy_cr_2           392.885578\n",
       "low_1              371.468644\n",
       "ixic_cr_2          319.822622\n",
       "vol_2              304.031809\n",
       "high_2             303.713592\n",
       "bond_usa_10_cr     293.889340\n",
       "corporateetc_2     229.407000\n",
       "kosdaq_cr          221.417799\n",
       "dxy_cr             216.150880\n",
       "privequity_1       191.585672\n",
       "bank_2             177.474581\n",
       "weekday            165.440849\n",
       "dji_cr_2           161.600631\n",
       "insurance_2        147.908399\n",
       "foreigneretc_2     140.661031\n",
       "invtrust_2         138.449999\n",
       "kospi_cr           130.924698\n",
       "spx_cr_2           127.241138\n",
       "bond_kor_10_cr_2   101.443330\n",
       "institution_2       95.732230\n",
       "bond_usa_3m_cr_2    92.662409\n",
       "retail_1            87.779610\n",
       "bond_usa_2_cr_2     83.294108\n",
       "bond_kor_2_cr       74.564001\n",
       "close_2             66.416481\n",
       "dji_cr              59.105329\n",
       "pension_1           54.729630\n",
       "dji_f_cr_2          50.212930\n",
       "spx_f_cr_2          44.955810\n",
       "high_1              39.748939\n",
       "kosdaq_cr_2         37.092200\n",
       "kospi_cr_2          32.743710"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:30]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sox_cr',\n",
       " 'ixic_f_cr',\n",
       " 'weekday',\n",
       " 'vix_cr_2',\n",
       " 'sox_cr_2',\n",
       " 'ixic_cr',\n",
       " 'privequity_2',\n",
       " 'ixic_cr_2',\n",
       " 'high_2',\n",
       " 'corporateetc_1',\n",
       " 'low_1',\n",
       " 'kosdaq_cr',\n",
       " 'dxy_cr_2',\n",
       " 'dxy_cr',\n",
       " 'bond_usa_10_cr',\n",
       " 'kospi_cr',\n",
       " 'foreigneretc_2',\n",
       " 'insurance_2',\n",
       " 'retail_1',\n",
       " 'foreigner_1',\n",
       " 'kosdaq_cr_2',\n",
       " 'dji_cr_2',\n",
       " 'bond_usa_2_cr',\n",
       " 'kospi_cr_2',\n",
       " 'bond_usa_3m_cr_2',\n",
       " 'vol_2',\n",
       " 'pension_1',\n",
       " 'privequity_1',\n",
       " 'vix_cr',\n",
       " 'institution_2',\n",
       " 'cr_00',\n",
       " 'cr_05',\n",
       " 'cr_10',\n",
       " 'cr_15',\n",
       " 'cr_20']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='split')\n",
    "# 큰 특징을 가지는 feature는 tree상위레벨에서 적게 사용됨."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
