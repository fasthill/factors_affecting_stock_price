{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlS4gyYqJVpn"
   },
   "source": [
    "# 예측이 가능한 종목 추리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQBDVUjBbIsL"
   },
   "source": [
    "## 가장 좋은 결과를 낼 수 있는 feature항목 추출\n",
    "## 모든 feature를 사용한 결과와, 선택 추출된 feature만 사용한 결과 정확도에 차이가 남\n",
    "#### logistic 회귀 이용하여 coef_ 항목에서 영향력이 높은 feature를 선택. 최적의 갯수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILi_LPl9JVpw"
   },
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EwImyTS9S3QQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱회귀후에 .coef_ 항목에서 기준(criteria, 계수)보다 높은 영향력을 미치는 feature column 선택\n",
    "def select_features(df, coef, criteria):\n",
    "    sel_num = np.where(np.abs(coef) > criteria )[1]\n",
    "    sel_col = df.columns[sel_num]\n",
    "    return sel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data, target):\n",
    "    train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "\n",
    "    lr = LogisticRegression(C=20, max_iter=4000) # max_iter default 100, \n",
    "#     lr = LogisticRegression(C=1, solver='newton_cg', max_iter=1000) # max_iter default 100, \n",
    "    lr.fit(train_scaled, train_target)\n",
    "\n",
    "    train_score = lr.score(train_scaled, train_target)\n",
    "    test_score = lr.score(test_scaled, test_target)\n",
    "#     print(f'train score: {train_score:.4f} \\n test score; {test_score:.4f}')\n",
    "    return train_score, test_score, lr.coef_, lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_result(data, target):\n",
    "# min을 하나씩 제거하면서 최고의 결과를 가져오는 feature갯수(항목) 선택\n",
    "\n",
    "    train_score_list= []\n",
    "    test_score_list = []\n",
    "#     data_columns = []\n",
    "#     data_coef = []\n",
    "    test_s = 0\n",
    "    train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "    for _ in range(len(data.columns)-1):\n",
    "        criteria = np.abs(coef).min()\n",
    "        sel_col = select_features(data, coef, criteria)\n",
    "        data = df[sel_col]\n",
    "        train_score, test_score, coef, intercept = get_scores(data, target)\n",
    "\n",
    "        if test_score > test_s:\n",
    "            test_s = test_score\n",
    "            data_columns = sel_col\n",
    "            data_coef = coef\n",
    "\n",
    "        train_score_list.append(train_score)\n",
    "        test_score_list.append(test_score)\n",
    "    \n",
    "    return train_score_list, test_score_list, data_columns, data_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(inp_num, a_layer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='sigmoid', input_shape=(inp_num,)))\n",
    "#     model.add(Dropout(0.1))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "#     model.add(Dropout(0.1))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix to list 변환\n",
    "def matrix_to_list(matrix):\n",
    "    m_list = []\n",
    "    for cm in confu_matrix:\n",
    "        name = cm[0]\n",
    "        tn = cm[1][0,0]\n",
    "        fp = cm[1][0,1]\n",
    "        fn = cm[1][1,0]\n",
    "        tp = cm[1][1,1]\n",
    "        m_list.append([name, tn, fp, fn, tp])\n",
    "    return m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "\n",
    "# code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D3AE9CB0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D3AEABC160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# 분석용 데이터 입력\n",
    "directory_for_ml = '../data/data_for_ml/'\n",
    "logi_accuracy = []\n",
    "sgd_accuracy = []\n",
    "deep_accuracy = []\n",
    "confu_matrix = []\n",
    "for key, val in code.items():\n",
    "    f_name= 'df_{}_{}.pkl'.format(val[1], 'sel')\n",
    "    fname = directory_for_ml + f_name\n",
    "    df = pd.read_pickle(fname)\n",
    "    \n",
    "    data = df.iloc[:, :-5]\n",
    "    target = df.iloc[:, -4]\n",
    "    \n",
    "    # logisticregression 결과 모으기\n",
    "    train_score_list, test_score_list, data_columns, data_coef = find_best_result(data, target)\n",
    "    logi_accuracy.append([val[1], max(train_score_list), max(test_score_list)])\n",
    "    \n",
    "    # SGDregressor 결과 모으기\n",
    "    data_new = data[data_columns] # 선택된 주요 column (feature) 만으로 정확도 계산하기\n",
    "    train_input, test_input, train_target, test_target \\\n",
    "        = train_test_split(data_new, target, random_state=42, test_size=0.2, stratify=target)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    sgd_value = []\n",
    "    for iter in range(5, 50, 1):\n",
    "        sc = SGDClassifier(loss='log', max_iter=iter, random_state=42)\n",
    "        scores = cross_validate(sc, X=train_scaled, y=train_target, n_jobs=-1)\n",
    "        sgd_value.append(scores['test_score'].mean())\n",
    "        \n",
    "    sgd_accuracy.append([val[1], max(sgd_value)])\n",
    "    \n",
    "    # 인공신경망\n",
    "    try :\n",
    "        model = None\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model = model_fn(len(data_new.columns))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "    # checkpoint_cb = ModelCheckpoint(filepath='best_model_{epoch:02d}-{val_loss:.2f}-{val_accuracy:.2f}.h5', \\\n",
    "#                                                 monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "    checkpoint_cb = ModelCheckpoint(filepath='best_model.h5', save_best_only=True)\n",
    "# earlystopping_cb = EarlyStopping(patience=100, monitor='val_accuracy', mode='max', restore_best_weights=True)\n",
    "    earlystopping_cb = EarlyStopping(patience=100, monitor='val_loss', mode='min', restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(train_scaled, train_target, epochs=2000, verbose=0,\n",
    "                        callbacks=[checkpoint_cb, earlystopping_cb],\n",
    "                        validation_data=(test_scaled, test_target))\n",
    "    \n",
    "    y_predict = model.predict(np.array(test_scaled), verbose=0)\n",
    "    y_predict_list = [1 if i > 0.5 else 0 for i in y_predict[:, 0]]\n",
    "    \n",
    "# 정밀도 : 양성으로 예측된 것(TP+FP) 중 얼마나 많은 샘플이 진짜 양성(TP)인지 측정\n",
    "#     precision_score(test_target, y_predict_list)  # 정밀도, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     recall_score(test_target, y_predict_list)  # 재현율, 입력값의 순서 중요힘. (실제값, 예측값)\n",
    "#     f1_score(test_target, y_predict_list)\n",
    "#     roc_auc_score(test_target, y_predict_list)  \n",
    "    score = model.evaluate(test_scaled, test_target, verbose=0)\n",
    "    deep_accuracy.append([val[1], \n",
    "                          score[0], score[1],\n",
    "                          precision_score(test_target, y_predict_list),\n",
    "                          recall_score(test_target, y_predict_list),\n",
    "                          f1_score(test_target, y_predict_list),\n",
    "                          roc_auc_score(test_target, y_predict_list)  \n",
    "                         ]) \n",
    "    \n",
    "    confu_matrix.append([val[1], confusion_matrix(test_target, y_predict_list)])\n",
    "    \n",
    "    df_logi = pd.DataFrame(logi_accuracy, columns=['name', 'train_max', 'test_max']).set_index('name')\n",
    "    df_sgd = pd.DataFrame(sgd_accuracy, columns=['name', 'sgd_accuracy']).set_index('name')\n",
    "    df_deep = pd.DataFrame(deep_accuracy, \n",
    "                       columns=['name', 'val_loss', 'val_accuracy', 'precision', 'recall', 'f1_score', ' roc_auc_score']).set_index('name')\n",
    "    df_confu_matrix = pd.DataFrame(matrix_to_list(confu_matrix), columns = ['name', 'tn', 'fp', 'fn', 'tp']).set_index('name')\n",
    "\n",
    "    dfs = [df_logi, df_sgd, df_deep, df_confu_matrix ]\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right, how='left', left_index=True, right_index=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>0.877863</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.754986</td>\n",
       "      <td>0.337531</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgenergy</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.676809</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skhinix</th>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.750462</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ssbio</th>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.595930</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sdi</th>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.739692</td>\n",
       "      <td>0.689484</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgchemical</th>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.510138</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secpre</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.497478</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyunmotor</th>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.660860</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naver</th>\n",
       "      <td>0.940678</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.796739</td>\n",
       "      <td>0.419404</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kia</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.741558</td>\n",
       "      <td>0.626463</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kakao</th>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.759420</td>\n",
       "      <td>0.570038</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscoholding</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.512579</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.745798</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbbank</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.675789</td>\n",
       "      <td>0.533591</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sscnt</th>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732026</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celltrion</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.660209</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobis</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.702924</td>\n",
       "      <td>0.561479</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shgroup</th>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.668019</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgelec</th>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.607975</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poscochemical</th>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.655648</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skinnovation</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.426624</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ktng</th>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.587895</td>\n",
       "      <td>0.647734</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_max  test_max  sgd_accuracy  val_loss  val_accuracy  \\\n",
       "name                                                                       \n",
       "sec             0.877863  0.909091      0.754986  0.337531      0.909091   \n",
       "lgenergy        0.800000  0.645161      0.625000  0.676809      0.677419   \n",
       "skhinix         0.898438  0.843750      0.750462  0.329563      0.875000   \n",
       "ssbio           0.827273  0.714286      0.700000  0.595930      0.714286   \n",
       "sdi             0.858268  0.656250      0.739692  0.689484      0.593750   \n",
       "lgchemical      0.891667  0.833333      0.733333  0.510138      0.700000   \n",
       "secpre          1.000000  0.800000      0.896429  0.497478      0.700000   \n",
       "hyunmotor       0.816667  0.700000      0.716667  0.660860      0.633333   \n",
       "naver           0.940678  0.833333      0.796739  0.419404      0.800000   \n",
       "kia             0.833333  0.740741      0.741558  0.626463      0.740741   \n",
       "kakao           0.913793  0.758621      0.759420  0.570038      0.689655   \n",
       "poscoholding    0.833333  0.774194      0.683333  0.512579      0.741935   \n",
       "kbbank          0.812500  0.760000      0.675789  0.533591      0.760000   \n",
       "sscnt           0.930233  0.772727      0.732026  0.510051      0.727273   \n",
       "celltrion       0.812500  0.800000      0.550000  0.660209      0.750000   \n",
       "mobis           0.923077  0.782609      0.702924  0.561479      0.826087   \n",
       "shgroup         0.883721  0.681818      0.650980  0.668019      0.636364   \n",
       "lgelec          0.898990  0.720000      0.707895  0.607975      0.720000   \n",
       "poscochemical   0.866667  0.736842      0.640000  0.655648      0.736842   \n",
       "skinnovation    0.814815  0.750000      0.666667  0.426624      0.750000   \n",
       "ktng            0.783505  0.760000      0.587895  0.647734      0.600000   \n",
       "\n",
       "               precision    recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                                          \n",
       "sec             0.882353  0.937500  0.909091        0.909926  15   2   1  15  \n",
       "lgenergy        0.684211  0.764706  0.722222        0.668067   8   6   4  13  \n",
       "skhinix         0.857143  0.857143  0.857143        0.873016  16   2   2  12  \n",
       "ssbio           0.727273  0.615385  0.666667        0.707692  12   3   5   8  \n",
       "sdi             0.578947  0.687500  0.628571        0.593750   8   8   5  11  \n",
       "lgchemical      0.625000  0.769231  0.689655        0.708145  11   6   3  10  \n",
       "secpre          0.666667  0.500000  0.571429        0.666667   5   1   2   2  \n",
       "hyunmotor       0.636364  0.500000  0.560000        0.625000  12   4   7   7  \n",
       "naver           0.818182  0.692308  0.750000        0.787330  15   2   4   9  \n",
       "kia             0.666667  0.923077  0.774194        0.747253   8   6   1  12  \n",
       "kakao           0.636364  0.583333  0.608696        0.674020  13   4   5   7  \n",
       "poscoholding    0.687500  0.785714  0.733333        0.745798  12   5   3  11  \n",
       "kbbank          0.750000  0.750000  0.750000        0.759615  10   3   3   9  \n",
       "sscnt           0.777778  0.636364  0.700000        0.727273   9   2   4   7  \n",
       "celltrion       0.777778  0.700000  0.736842        0.750000   8   2   3   7  \n",
       "mobis           0.800000  0.800000  0.800000        0.823077  11   2   2   8  \n",
       "shgroup         0.666667  0.545455  0.600000        0.636364   8   3   5   6  \n",
       "lgelec          0.666667  0.923077  0.774194        0.711538   6   6   1  12  \n",
       "poscochemical   0.692308  0.900000  0.782609        0.727778   5   4   1   9  \n",
       "skinnovation    0.692308  0.750000  0.720000        0.750000  12   4   3   9  \n",
       "ktng            0.600000  0.500000  0.545455        0.596154   9   4   6   6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_max = 0.7\n",
    "sgd_accuracy = 0.7\n",
    "val_accuracy = 0.7\n",
    "precision = 0.7\n",
    "fi_score = 0.7\n",
    "ratio_min = 0.4\n",
    "ratio_max = 0.6\n",
    "\n",
    "ratio = ((df_merged['fn'] + df_merged['tp']) / (df_merged['tn'] + df_merged['fp'] + df_merged['fn'] + df_merged['tp']))\n",
    "df_sel = (df_merged['test_max'] >= test_max) & \\\n",
    "        (df_merged['sgd_accuracy'] >= sgd_accuracy) & \\\n",
    "        (df_merged['val_accuracy'] >= val_accuracy) & \\\n",
    "        (df_merged['precision'] >= precision) & \\\n",
    "        (df_merged['f1_score'] >= fi_score) & \\\n",
    "        (ratio_min < ratio ) & (ratio < ratio_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_max</th>\n",
       "      <th>test_max</th>\n",
       "      <th>sgd_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>0.877863</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.754986</td>\n",
       "      <td>0.337531</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909926</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skhinix</th>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.750462</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naver</th>\n",
       "      <td>0.940678</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.796739</td>\n",
       "      <td>0.419404</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sscnt</th>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.732026</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobis</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.702924</td>\n",
       "      <td>0.561479</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_max  test_max  sgd_accuracy  val_loss  val_accuracy  precision  \\\n",
       "name                                                                            \n",
       "sec       0.877863  0.909091      0.754986  0.337531      0.909091   0.882353   \n",
       "skhinix   0.898438  0.843750      0.750462  0.329563      0.875000   0.857143   \n",
       "naver     0.940678  0.833333      0.796739  0.419404      0.800000   0.818182   \n",
       "sscnt     0.930233  0.772727      0.732026  0.510051      0.727273   0.777778   \n",
       "mobis     0.923077  0.782609      0.702924  0.561479      0.826087   0.800000   \n",
       "\n",
       "           recall  f1_score   roc_auc_score  tn  fp  fn  tp  \n",
       "name                                                         \n",
       "sec      0.937500  0.909091        0.909926  15   2   1  15  \n",
       "skhinix  0.857143  0.857143        0.873016  16   2   2  12  \n",
       "naver    0.692308  0.750000        0.787330  15   2   4   9  \n",
       "sscnt    0.636364  0.700000        0.727273   9   2   4   7  \n",
       "mobis    0.800000  0.800000        0.823077  11   2   2   8  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_sel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 정밀도, f1-score, \n",
    "2. confusion matrix ((1,1), (2,2), 두개가 큰 비중이면 good, (1,2)은 틀린것을 맞다라고 구분, (2,1)은 맞는 것을 틀린 것이다 라고 결정하는 항목) 따라서\n",
    "    (2,2) -> (1,2) -> (1,1)로 확인하고. <br>\n",
    "    (1,2)가 크면 모델 제외 (정밀도(precision = TP / (TP + FP) )가 높아야 함. 낮으면 손해를 보게 됨.), <br>\n",
    "    재현율(Recall = TP / (TP + FN) ) 은 손해를 끼치지는 않음.\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/fasthill/My-gist/main/data/picture/confusion_matrix.png\" width=\"800\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수수료: 주식거래수수료 0.015%. 유관기관수수료 0.0036%, 증권거래세 0.08, 농어촌 특별세 0.15%\n",
    "수수료 : (0.015+0.0036 ) * 2 (사고팔때), 증권거래세 : 0.08 + 0.15 (팔때)\n",
    "전체 지출 금액율: 0.2672%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-1 로지스틱 회귀.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
