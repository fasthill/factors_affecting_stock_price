{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fasthill/ML-DL-study-alone/blob/main/5-1%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uA_6TRHEMHV"
   },
   "source": [
    "## Analyse from LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26KAIfzEEMHc"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rIXeXBVTfZrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# write list, dictionary to pickle\n",
    "def save_to_pickle(path, filename):\n",
    "    open_file = open(path, \"wb\")\n",
    "    pickle.dump(filename, open_file)\n",
    "    open_file.close()\n",
    "\n",
    "# read list, dictionary from pickle\n",
    "def load_from_pickle(path):\n",
    "    open_file = open(path, \"rb\")\n",
    "    loaded_file = pickle.load(open_file)\n",
    "    open_file.close()\n",
    "    return loaded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# write list, dictionary to csv\n",
    "# path = './xxx/', my_dict = filename\n",
    "\n",
    "def save_dict_to_csv(path, my_dict):\n",
    "    fields=my_dict.keys()\n",
    "    values = my_dict.values()\n",
    "    pd.DataFrame([fields, values], index=['parameter','value']).T.to_csv(path)\n",
    "#     df = pd.DataFrame.from_dict(my_dict, orient='index') \n",
    "#     df.to_csv (path, index=False, header=True)  \n",
    "    \n",
    "def save_list_to_csv(path, my_list):\n",
    "    df = pd.DataFrame(my_list, columns=['columns'])\n",
    "    df.to_csv (path, index=False, header=True) \n",
    "    \n",
    "# def load_dict_from_csv(path):\n",
    "#     df = pd.read_csv(path, header=None)\n",
    "#     my_dict = df.to_dict()\n",
    "#     return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_p(test_target, y_predict_list): \n",
    "    ps = precision_score(test_target, y_predict_list)\n",
    "    rs = recall_score(test_target, y_predict_list)\n",
    "    fs = f1_score(test_target, y_predict_list)\n",
    "    roc = roc_auc_score(test_target, y_predict_list)\n",
    "    collect_list = [ps, rs, fs, roc]\n",
    "    return collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_estimator(estimator, num):\n",
    "    df_t = pd.DataFrame.from_dict(estimator, orient='index')\n",
    "    df_t.columns = [f'iter_{num}']\n",
    "    df_t.index.name = 'parameter'\n",
    "    return df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(lgbm, model, train_scaled, val_scaled, test_scaled, train_target, val_target, test_target,\n",
    "                 test_scaled1, test_scaled2, test_scaled3, test_target1, test_target2, test_target3):\n",
    "# model = lgbmgs.best_estimator_  # 최적의 파라미터로 모델 생성\n",
    "    y_predict = model.predict(test_scaled)\n",
    "    result_dict= {}\n",
    "    result_dict['best_score'] = lgbm.best_score_ \n",
    "    result_dict['best_index'] = lgbm.best_index_\n",
    "    result_dict['acc_train'] = model.score(train_scaled, train_target)\n",
    "    result_dict['acc_val'] = model.score(val_scaled, val_target)\n",
    "    result_dict['acc_test'] = model.score(test_scaled, test_target)\n",
    "    result_dict['precision'] = precision_score(test_target, y_predict)\n",
    "    result_dict['recall'] = recall_score(test_target, y_predict)\n",
    "    result_dict['f1score'] = f1_score(test_target, y_predict)\n",
    "    result_dict['roc'] = roc_auc_score(test_target, y_predict)\n",
    "    cm = confusion_matrix(test_target, y_predict)\n",
    "    result_dict['tn'] = cm[0,0]\n",
    "    result_dict['fp'] = cm[0,1]\n",
    "    result_dict['fn'] = cm[1,0]\n",
    "    result_dict['tp'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled1)\n",
    "    result_dict['acc_test1'] = model.score(test_scaled1, test_target1)\n",
    "    result_dict['precision1'] = precision_score(test_target1, y_predict)\n",
    "    result_dict['recall1'] = recall_score(test_target1, y_predict)\n",
    "    result_dict['f1score1'] = f1_score(test_target1, y_predict)\n",
    "    result_dict['roc1'] = roc_auc_score(test_target1, y_predict)\n",
    "    cm = confusion_matrix(test_target1, y_predict)\n",
    "    result_dict['tn1'] = cm[0,0]\n",
    "    result_dict['fp1'] = cm[0,1]\n",
    "    result_dict['fn1'] = cm[1,0]\n",
    "    result_dict['tp1'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled2)\n",
    "    result_dict['acc_test2'] = model.score(test_scaled2, test_target2)\n",
    "    result_dict['precision2'] = precision_score(test_target2, y_predict)\n",
    "    result_dict['recall2'] = recall_score(test_target2, y_predict)\n",
    "    result_dict['f1score2'] = f1_score(test_target2, y_predict)\n",
    "    result_dict['roc2'] = roc_auc_score(test_target2, y_predict)\n",
    "    cm = confusion_matrix(test_target2, y_predict)\n",
    "    result_dict['tn2'] = cm[0,0]\n",
    "    result_dict['fp2'] = cm[0,1]\n",
    "    result_dict['fn2'] = cm[1,0]\n",
    "    result_dict['tp2'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    #------------------------------------\n",
    "    y_predict = model.predict(test_scaled3)\n",
    "    result_dict['acc_test3'] = model.score(test_scaled3, test_target3)\n",
    "    result_dict['precision3'] = precision_score(test_target3, y_predict)\n",
    "    result_dict['recall3'] = recall_score(test_target3, y_predict)\n",
    "    result_dict['f1score3'] = f1_score(test_target3, y_predict)\n",
    "    result_dict['roc3'] = roc_auc_score(test_target3, y_predict)\n",
    "    cm = confusion_matrix(test_target3, y_predict)\n",
    "    result_dict['tn3'] = cm[0,0]\n",
    "    result_dict['fp3'] = cm[0,1]\n",
    "    result_dict['fn3'] = cm[1,0]\n",
    "    result_dict['tp3'] = cm[1,1]\n",
    "#     result_dict['precision_neg'] = cm[0,0] / (cm[0,0] + cm[1,0])\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_results(com_name, model, scaler, columns, df_base):\n",
    "    joblib.dump(model, f'{directory_for_model}{com_name}/best_model.pkl') # estimaor 저장\n",
    "    joblib.dump(scaler, f'{directory_for_model}{com_name}/best_scaler.pkl') # scaler 저장\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_model_p.pkl', model)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_scaler_p.pkl', scaler)\n",
    "    save_to_pickle(f'{directory_for_model}{com_name}/best_columns.pkl', new_col)\n",
    "    save_list_to_csv(f'{directory_for_model}{com_name}/best_columns.csv', new_col)\n",
    "    df_base.to_pickle(f'{directory_for_model}{com_name}/best_result.pkl')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dict(*dicts):\n",
    "    dsum = {}\n",
    "    d_k = []\n",
    "    d_v = []\n",
    "    for dic in dicts:\n",
    "        d_k.extend(list(dic.keys()))  # sum keys list\n",
    "        d_v.extend(list(dic.values()))  # sum values list\n",
    "    for i in range(len(d_k)):\n",
    "        dsum[d_k[i]] = d_v[i]\n",
    "    return dsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_combine_sorted(df_base_l, df_params_l):\n",
    "    o_num = list(df_base_l.index).index('best_score')\n",
    "    df1 = df_base.iloc[:o_num, :]\n",
    "    df2 = df_base.iloc[o_num:, :]\n",
    "    df3 = pd.concat([df1, df_params_l], axis=0)\n",
    "    df3.sort_index(axis=0, inplace=True)\n",
    "    df_sorted = pd.concat([df3, df2], axis=0)\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..')) # 현재 폴더로 이동\n",
    "if module_path+\"\\\\data\\\\base_data\\\\common_data\" not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\data\\\\base_data\\\\common_data\") #  공통으로 사용하는 각종 리스트, 코드 등 \n",
    "    \n",
    "import common_data as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = cd.code_all # 전체 회사 코드\n",
    "code = {'028260': ['삼성물산', 'sscnt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "#             'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', \n",
    "            'privequity_1',  'insurance_1', 'corporateetc_1', # bank_1, 'financeetc_1 제외\n",
    "            'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "#             'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', \n",
    "            'privequity_2', 'insurance_2', 'corporateetc_2', # bank_2, 'financeetc_2 제외\n",
    "            'foreigneretc_2']\n",
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']\n",
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']\n",
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]\n",
    "col_futures = ['ixic_f_cr', 'ixic_f_cr_2', 'spx_f_cr', 'spx_f_cr_2', 'dji_f_cr', 'dji_f_cr_2',\n",
    "           'wti_cr','wti_cr_2', 'dxy_cr', 'dxy_cr_2', 'bond_usa_10_cr', 'bond_usa_10_cr_2' ]\n",
    "column_o = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr\n",
    "\n",
    "col_except_futures = [item for item in column_o if item not in col_futures]\n",
    "\n",
    "new_col = col_except_futures.copy()\n",
    "\n",
    "# bank, financeetc는 결측치가 많아서 사용하지 않음.\n",
    "# df.drop(['bank_1', 'bank_2', 'financeetc_1', 'financeetc_2'], axis=1, inplace=True)   \n",
    "\n",
    "# col_futures : futures는 당일 종료가 되지 않는 data이므로 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최초의 empty df 생성\n",
    "df_base = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "df_params = pd.DataFrame(pd.Series([],dtype=pd.StringDtype(), name='parameter')).set_index('parameter')\n",
    "iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 신규 분석 데이터는 아래 것으로 사용\n",
    "\n",
    "com_name = list(code.values())[0][1]\n",
    "\n",
    "directory_for_ml = '../data/data_for_ml/predict/'\n",
    "fname = f'df_{com_name}_combine.pkl'\n",
    "f_name = directory_for_ml + fname\n",
    "df_o = pd.read_pickle(f_name) \n",
    "df_o = df_o.iloc[:-1] # /predict/를 사용할 경우 마지막 prediction data 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업시 여기서 부터 진행 (feature importance로 선정된 새로운 column으로)\n",
    "\n",
    "df = df_o[new_col]  # 새롭게 선정된 column으로 진행\n",
    "\n",
    "# train, val,: 8, test: 2\n",
    "split_ratio = 0.8\n",
    "split_n = int(len(df)*split_ratio)\n",
    "\n",
    "test_interval = int((len(df) - split_n)/3)\n",
    "data = df.iloc[:split_n, :-5]\n",
    "target = df.iloc[:split_n, -5]\n",
    "test_input = df.iloc[split_n:, :-5]\n",
    "test_target = df.iloc[split_n:, -5]\n",
    "test_input1 = df.iloc[split_n:split_n+test_interval, :-5]\n",
    "test_input2 = df.iloc[split_n+test_interval: split_n+test_interval*2, :-5]\n",
    "test_input3 = df.iloc[split_n+test_interval*2:, :-5]\n",
    "test_target1 = df.iloc[split_n:split_n+test_interval, -5]\n",
    "test_target2 = df.iloc[split_n+test_interval: split_n+test_interval*2, -5]\n",
    "test_target3 = df.iloc[split_n+test_interval*2:, -5]\n",
    "\n",
    "train_input, val_input, train_target, val_target = \\\n",
    "     train_test_split(data, target, random_state=42, test_size=0.2, stratify=target)\n",
    "\n",
    "scaler = None\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "train_scaled = scaler.transform(train_input)\n",
    "val_scaled = scaler.transform(val_input)\n",
    "test_scaled = scaler.transform(test_input)\n",
    "test_scaled1 = scaler.transform(test_input1)\n",
    "test_scaled2 = scaler.transform(test_input2)\n",
    "test_scaled3 = scaler.transform(test_input3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'boosting_type' : ['gbdt', 'dart', ],# ['gbdt', 'dart', 'goss'],\n",
    "    'learning_rate': (0.0001, 0.004, 'log-uniform'),\n",
    "    'num_leaves': (3, 15),      \n",
    "    'max_depth': (0, 50), #[-1], #(0, 50),\n",
    "    'min_child_samples': (5, 40),\n",
    "#     'min_child_weight': (1.0, 3.0), # 값을 변동시 같은 값이 최적값으로 선정되더라고 precision이 틀림. 반드시 값을 바꾸면서 진행해야 함.\n",
    "#     'min_split_loss': (0, 5), \n",
    "    'max_bin': (100, 1000), # 사용시 0.75%로 올라감 default: 255\n",
    "#     'max_cat_threshold' : (1, 100),\n",
    "    'subsample': (0.005, 1.0, 'uniform'), # == bagging_fraction\n",
    "#     'subsample_freq': (1, 10), # mobis에서 적용시 값이 많이 올라감. default:0\n",
    "    'colsample_bytree': (0.005, 1.0, 'uniform'),\n",
    "    'subsample_for_bin': (100000, 500000),\n",
    "    'scale_pos_weight' : (0.2, 2.0, 'uniform'),\n",
    "#     'scale_pos_weight': np.arange(0.2, 2, 0.1) ,\n",
    "    'n_estimators': (700, 5000),\n",
    "    'reg_alpha' : (0.0, 4.0, 'uniform'), # =='lambda_l1': [0, 5], # default 0\n",
    "    'reg_lambda' : (0.0, 4.0, 'uniform'), # == lambda_l2': [0, 5], #default 0    \n",
    "#     'reg_alpha' : np.arange(0, 4, 0.1),\n",
    "#     'reg_lambda' : np.arange(0, 4, 0.1),\n",
    "    'force_col_wise': ['true'], \n",
    "    'importance_type': ['split'], # ['gain'], default: split\n",
    "    'boost_from_average' : [True, False],\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "}\n",
    "\n",
    "params_space = search_space.copy() # for Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'cv' : 3,\n",
    "#     'cv' : None,\n",
    "#     'scoring' : None,\n",
    "#     'scoring' : 'f1',\n",
    "#     'scoring' : 'roc_auc',\n",
    "    'scoring' : 'precision',\n",
    "#     'scoring' : 'average_precision',\n",
    "#     'scoring' : 'accuracy',\n",
    "    'num_col' : len(new_col),\n",
    "    'iterations' : 50,  # default : 50, number of parameter settings.\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_for_model = '../data/data_for_ml/model/model/0. test/'\n",
    "directory_for_model = '../data/data_for_ml/model/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** after lgbm BS ******\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n    self._Booster = train(\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\engine.py\", line 271, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n    _safe_call(_LIB.LGBM_BoosterCreate(\n  File \"C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\nlightgbm.basic.LightGBMError: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 25\u001b[0m\n\u001b[0;32m     13\u001b[0m lgbmBS \u001b[38;5;241m=\u001b[39m BayesSearchCV( estimator \u001b[38;5;241m=\u001b[39m lightgbm\u001b[38;5;241m.\u001b[39mLGBMClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m     14\u001b[0m                        search_spaces \u001b[38;5;241m=\u001b[39m params_space,\n\u001b[0;32m     15\u001b[0m                        scoring \u001b[38;5;241m=\u001b[39m param_grid[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscoring\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m                        verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, refit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m \n\u001b[0;32m     22\u001b[0m                       )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** after lgbm BS ******\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mlgbmBS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# save model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m stamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39misoformat() \u001b[38;5;66;03m# 파일명 끝에 생성날짜 시간 추가\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\skopt\\searchcv.py:408\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[0;32m    406\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m--> 408\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# Feed the point and objective value back into optimizer\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Optimizer minimizes objective, hence provide negative score\u001b[39;00m\n\u001b[0;32m    411\u001b[0m local_results \u001b[38;5;241m=\u001b[39m all_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(params):]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Check failed: (num_data) > (0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\dataset.cpp, line 33 .\n"
     ]
    }
   ],
   "source": [
    "# directory가 없으면 만드는 과정\n",
    "if not os.path.exists(directory_for_model+com_name):\n",
    "    os.makedirs(directory_for_model+com_name)\n",
    "\n",
    "iter = iter + 1\n",
    "\n",
    "lgbm = None\n",
    "lgbmBS = None\n",
    "gsbs = 'bs'\n",
    "\n",
    "lgbmBS = BayesSearchCV( estimator = lightgbm.LGBMClassifier(verbose=0, random_state=42),\n",
    "                       search_spaces = params_space,\n",
    "                       scoring = param_grid['scoring'],\n",
    "                       cv = StratifiedKFold( n_splits=param_grid['cv'],\n",
    "                                             shuffle=True,\n",
    "                                             random_state=42 ),\n",
    "                       n_jobs = -1, # 자동 검색 적용\n",
    "                       n_iter = param_grid['iterations'],   \n",
    "                       verbose = 0, refit = True, random_state = 42 \n",
    "                      )\n",
    "\n",
    "print(\"*** after lgbm BS ******\")\n",
    "lgbmBS.fit(train_scaled, train_target, eval_metric = 'logloss') \n",
    "\n",
    "# save model\n",
    "stamp = datetime.datetime.today().isoformat() # 파일명 끝에 생성날짜 시간 추가\n",
    "dt = re.sub(r'[-:T]', '', stamp[5:16])\n",
    "dt = f'{dt[:4]}_{dt[4:]}'\n",
    "\n",
    "df_estimator = make_df_from_estimator(lgbmBS.best_estimator_.get_params(), iter)\n",
    "df_estimator.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "\n",
    "# metrics accuracy,,,, 3단계 precision 등까지. dictionary\n",
    "result_dict = calc_results(lgbmBS, lgbmBS.best_estimator_, \n",
    "                           train_scaled, val_scaled, test_scaled,  \n",
    "                           train_target, val_target, test_target,\n",
    "                           test_scaled1, test_scaled2, test_scaled3,  \n",
    "                           test_target1, test_target2, test_target3\n",
    "                          )\n",
    "\n",
    "df_grid = make_df_from_estimator(param_grid, iter) # gridcv parameter\n",
    "df_grid.sort_index(inplace=True) # alphabet 순으로 보기 편하게\n",
    "df_result = make_df_from_estimator(result_dict, iter)  # dict 를 df로\n",
    "df_concat = pd.concat([df_grid, df_estimator, df_result])\n",
    "\n",
    "df_base = pd.merge(df_base,df_concat, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "val_test = df_concat.loc['acc_val'].iloc[0]\n",
    "acc_test = df_concat.loc['acc_test'].iloc[0]\n",
    "precision = df_concat.loc['precision'].iloc[0]\n",
    "f1score = df_concat.loc['f1score'].iloc[0]\n",
    "\n",
    "params_search = add_dict(param_grid, search_space)\n",
    "df_params_search = make_df_from_estimator(params_search, iter)\n",
    "df_params = pd.merge(df_params,df_params_search, how='outer', left_index=True, right_index=True)\n",
    "  \n",
    "print(\"******* No.{} BS Process is Done! ********\".format(iter))\n",
    "    \n",
    "print(\"**** End of BayesSearchCV Process ****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_1</th>\n",
       "      <th>iter_2</th>\n",
       "      <th>iter_3</th>\n",
       "      <th>iter_4</th>\n",
       "      <th>iter_5</th>\n",
       "      <th>iter_6</th>\n",
       "      <th>iter_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boost_from_average</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "      <td>[gbdt, dart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting_type</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>dart</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.5, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.61635</td>\n",
       "      <td>0.679511</td>\n",
       "      <td>0.799024</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.799024</td>\n",
       "      <td>0.127292</td>\n",
       "      <td>0.109335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "      <td>[true]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force_col_wise</th>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "      <td>[split]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importance_type</th>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iterations</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "      <td>(0.0001, 0.004, log-uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>597</td>\n",
       "      <td>684</td>\n",
       "      <td>780</td>\n",
       "      <td>974</td>\n",
       "      <td>780</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bin</th>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "      <td>(100, 1000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "      <td>binary_logloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "      <td>[binary_logloss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "      <td>(5, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_samples</th>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.001, 10.0)</td>\n",
       "      <td>(0.001, 5.0)</td>\n",
       "      <td>(0.001, 3.0)</td>\n",
       "      <td>(1.0, 3.0)</td>\n",
       "      <td>(1.0, 3.0)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.001</td>\n",
       "      <td>9.242889</td>\n",
       "      <td>1.708637</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.683191</td>\n",
       "      <td>1.811087</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "      <td>(700, 5000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_estimators</th>\n",
       "      <td>3686</td>\n",
       "      <td>3529</td>\n",
       "      <td>4301</td>\n",
       "      <td>3282</td>\n",
       "      <td>4301</td>\n",
       "      <td>2976</td>\n",
       "      <td>3725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_col</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_leaves</th>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 20)</td>\n",
       "      <td>(3, 15)</td>\n",
       "      <td>(3, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "      <td>[binary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "      <td>binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_state</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>1.266717</td>\n",
       "      <td>1.874062</td>\n",
       "      <td>3.858802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.858802</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.038204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "      <td>(0.0, 4.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.260842</td>\n",
       "      <td>1.784465</td>\n",
       "      <td>3.677294</td>\n",
       "      <td>1.784465</td>\n",
       "      <td>0.924225</td>\n",
       "      <td>1.781386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "      <td>(0.2, 2.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <td>0.79333</td>\n",
       "      <td>0.78926</td>\n",
       "      <td>0.765358</td>\n",
       "      <td>0.771035</td>\n",
       "      <td>0.765358</td>\n",
       "      <td>1.347188</td>\n",
       "      <td>0.850053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "      <td>precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silent</th>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "      <td>warn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.398242</td>\n",
       "      <td>0.063145</td>\n",
       "      <td>0.073301</td>\n",
       "      <td>0.063145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "      <td>(0.005, 1.0, uniform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>432982</td>\n",
       "      <td>306651</td>\n",
       "      <td>390404</td>\n",
       "      <td>500000</td>\n",
       "      <td>390404</td>\n",
       "      <td>297000</td>\n",
       "      <td>192030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "      <td>(100000, 500000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.609169</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.585441</td>\n",
       "      <td>0.560185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          iter_1   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                         0.61635   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.001175   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      597   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     28   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_samples                             21   \n",
       "min_child_weight                             NaN   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                3686   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                    20   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                               1.266717   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                                   4.0   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                         0.79333   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                                  0.005   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                         432982   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.539877   \n",
       "best_index                                  43.0   \n",
       "acc_train                               0.949749   \n",
       "acc_val                                     0.54   \n",
       "acc_test                                0.619048   \n",
       "precision                                    0.6   \n",
       "recall                                  0.428571   \n",
       "\n",
       "                                          iter_2   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                        0.679511   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.000897   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      684   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     21   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_samples                             27   \n",
       "min_child_weight                   (0.001, 10.0)   \n",
       "min_child_weight                        9.242889   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                3529   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                    13   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                               1.874062   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                              3.260842   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                         0.78926   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                               0.398242   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                         306651   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.609169   \n",
       "best_index                                   6.0   \n",
       "acc_train                               0.773869   \n",
       "acc_val                                     0.62   \n",
       "acc_test                                0.619048   \n",
       "precision                               0.642857   \n",
       "recall                                  0.321429   \n",
       "\n",
       "                                          iter_3   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               dart   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                        0.799024   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.000142   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      780   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     44   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_samples                             19   \n",
       "min_child_weight                    (0.001, 5.0)   \n",
       "min_child_weight                        1.708637   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                4301   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                    13   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                               3.858802   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                              1.784465   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.765358   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                               0.063145   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                         390404   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.558405   \n",
       "best_index                                   3.0   \n",
       "acc_train                               0.723618   \n",
       "acc_val                                     0.56   \n",
       "acc_test                                0.634921   \n",
       "precision                               0.692308   \n",
       "recall                                  0.321429   \n",
       "\n",
       "                                          iter_4   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               gbdt   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                          0.5107   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.000281   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      974   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                      9   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_samples                             40   \n",
       "min_child_weight                    (0.001, 3.0)   \n",
       "min_child_weight                           0.001   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                3282   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                     7   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                                    0.0   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                              3.677294   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.771035   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                               0.073301   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                         500000   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.568627   \n",
       "best_index                                  18.0   \n",
       "acc_train                               0.693467   \n",
       "acc_val                                      0.6   \n",
       "acc_test                                0.603175   \n",
       "precision                               0.636364   \n",
       "recall                                      0.25   \n",
       "\n",
       "                                          iter_5   \n",
       "parameter                                          \n",
       "boost_from_average                 [True, False]  \\\n",
       "boost_from_average                          True   \n",
       "boosting_type                       [gbdt, dart]   \n",
       "boosting_type                               dart   \n",
       "class_weight                                None   \n",
       "colsample_bytree             (0.5, 1.0, uniform)   \n",
       "colsample_bytree                        0.799024   \n",
       "cv                                             3   \n",
       "cv                                             3   \n",
       "force_col_wise                            [true]   \n",
       "force_col_wise                              true   \n",
       "importance_type                          [split]   \n",
       "importance_type                            split   \n",
       "iterations                                    50   \n",
       "iterations                                    50   \n",
       "learning_rate                           0.000142   \n",
       "learning_rate       (0.0001, 0.004, log-uniform)   \n",
       "max_bin                                      780   \n",
       "max_bin                              (100, 1000)   \n",
       "max_depth                                     44   \n",
       "max_depth                                (0, 50)   \n",
       "metric                            binary_logloss   \n",
       "metric                          [binary_logloss]   \n",
       "min_child_samples                        (5, 40)   \n",
       "min_child_samples                             19   \n",
       "min_child_weight                      (1.0, 3.0)   \n",
       "min_child_weight                        1.683191   \n",
       "min_split_gain                               0.0   \n",
       "n_estimators                         (700, 5000)   \n",
       "n_estimators                                4301   \n",
       "n_jobs                                        -1   \n",
       "num_col                                       98   \n",
       "num_col                                       98   \n",
       "num_leaves                                    13   \n",
       "num_leaves                               (3, 20)   \n",
       "objective                               [binary]   \n",
       "objective                                 binary   \n",
       "random_state                                  42   \n",
       "reg_alpha                               3.858802   \n",
       "reg_alpha                    (0.0, 4.0, uniform)   \n",
       "reg_lambda                   (0.0, 4.0, uniform)   \n",
       "reg_lambda                              1.784465   \n",
       "scale_pos_weight             (0.2, 2.0, uniform)   \n",
       "scale_pos_weight                        0.765358   \n",
       "scoring                                precision   \n",
       "scoring                                precision   \n",
       "silent                                      warn   \n",
       "subsample                               0.063145   \n",
       "subsample                  (0.005, 1.0, uniform)   \n",
       "subsample_for_bin                         390404   \n",
       "subsample_for_bin               (100000, 500000)   \n",
       "subsample_freq                                 0   \n",
       "verbose                                        0   \n",
       "best_score                              0.558405   \n",
       "best_index                                   3.0   \n",
       "acc_train                               0.723618   \n",
       "acc_val                                     0.56   \n",
       "acc_test                                0.634921   \n",
       "precision                               0.692308   \n",
       "recall                                  0.321429   \n",
       "\n",
       "                                          iter_6                        iter_7  \n",
       "parameter                                                                       \n",
       "boost_from_average                 [True, False]                 [True, False]  \n",
       "boost_from_average                          True                         False  \n",
       "boosting_type                       [gbdt, dart]                  [gbdt, dart]  \n",
       "boosting_type                               gbdt                          gbdt  \n",
       "class_weight                                None                          None  \n",
       "colsample_bytree           (0.005, 1.0, uniform)         (0.005, 1.0, uniform)  \n",
       "colsample_bytree                        0.127292                      0.109335  \n",
       "cv                                             3                             3  \n",
       "cv                                             3                             3  \n",
       "force_col_wise                            [true]                        [true]  \n",
       "force_col_wise                              true                          true  \n",
       "importance_type                          [split]                       [split]  \n",
       "importance_type                            split                         split  \n",
       "iterations                                    50                            50  \n",
       "iterations                                    50                            50  \n",
       "learning_rate                           0.000499                      0.000533  \n",
       "learning_rate       (0.0001, 0.004, log-uniform)  (0.0001, 0.004, log-uniform)  \n",
       "max_bin                                      239                           240  \n",
       "max_bin                              (100, 1000)                   (100, 1000)  \n",
       "max_depth                                     20                            38  \n",
       "max_depth                                (0, 50)                       (0, 50)  \n",
       "metric                            binary_logloss                binary_logloss  \n",
       "metric                          [binary_logloss]              [binary_logloss]  \n",
       "min_child_samples                        (5, 40)                       (5, 40)  \n",
       "min_child_samples                             26                            39  \n",
       "min_child_weight                      (1.0, 3.0)                           NaN  \n",
       "min_child_weight                        1.811087                         0.001  \n",
       "min_split_gain                               0.0                           0.0  \n",
       "n_estimators                         (700, 5000)                   (700, 5000)  \n",
       "n_estimators                                2976                          3725  \n",
       "n_jobs                                        -1                            -1  \n",
       "num_col                                       98                            98  \n",
       "num_col                                       98                            98  \n",
       "num_leaves                                     3                             8  \n",
       "num_leaves                               (3, 15)                       (3, 15)  \n",
       "objective                               [binary]                      [binary]  \n",
       "objective                                 binary                        binary  \n",
       "random_state                                  42                            42  \n",
       "reg_alpha                                    4.0                      2.038204  \n",
       "reg_alpha                    (0.0, 4.0, uniform)           (0.0, 4.0, uniform)  \n",
       "reg_lambda                   (0.0, 4.0, uniform)           (0.0, 4.0, uniform)  \n",
       "reg_lambda                              0.924225                      1.781386  \n",
       "scale_pos_weight             (0.2, 2.0, uniform)           (0.2, 2.0, uniform)  \n",
       "scale_pos_weight                        1.347188                      0.850053  \n",
       "scoring                                precision                     precision  \n",
       "scoring                                precision                     precision  \n",
       "silent                                      warn                          warn  \n",
       "subsample                                    1.0                       0.99692  \n",
       "subsample                  (0.005, 1.0, uniform)         (0.005, 1.0, uniform)  \n",
       "subsample_for_bin                         297000                        192030  \n",
       "subsample_for_bin               (100000, 500000)              (100000, 500000)  \n",
       "subsample_freq                                 0                             0  \n",
       "verbose                                        0                             0  \n",
       "best_score                              0.585441                      0.560185  \n",
       "best_index                                  47.0                           2.0  \n",
       "acc_train                               0.743719                      0.773869  \n",
       "acc_val                                     0.56                          0.62  \n",
       "acc_test                                0.634921                      0.619048  \n",
       "precision                               0.580645                      0.666667  \n",
       "recall                                  0.642857                      0.285714  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one = df_combine_sorted(df_base, df_params)\n",
    "df_one.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter_1</th>\n",
       "      <th>iter_2</th>\n",
       "      <th>iter_3</th>\n",
       "      <th>iter_4</th>\n",
       "      <th>iter_5</th>\n",
       "      <th>iter_6</th>\n",
       "      <th>iter_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>verbose</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.539877</td>\n",
       "      <td>0.609169</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.585441</td>\n",
       "      <td>0.560185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_index</th>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.949749</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.773869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_val</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.603571</td>\n",
       "      <td>0.567857</td>\n",
       "      <td>0.603571</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.585714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test1</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1score1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              iter_1    iter_2    iter_3    iter_4    iter_5    iter_6   \n",
       "parameter                                                                \n",
       "verbose            0         0         0         0         0         0  \\\n",
       "best_score  0.539877  0.609169  0.558405  0.568627  0.558405  0.585441   \n",
       "best_index      43.0       6.0       3.0      18.0       3.0      47.0   \n",
       "acc_train   0.949749  0.773869  0.723618  0.693467  0.723618  0.743719   \n",
       "acc_val         0.54      0.62      0.56       0.6      0.56      0.56   \n",
       "acc_test    0.619048  0.619048  0.634921  0.603175  0.634921  0.634921   \n",
       "precision        0.6  0.642857  0.692308  0.636364  0.692308  0.580645   \n",
       "recall      0.428571  0.321429  0.321429      0.25  0.321429  0.642857   \n",
       "f1score          0.5  0.428571  0.439024  0.358974  0.439024  0.610169   \n",
       "roc              0.6  0.589286  0.603571  0.567857  0.603571  0.635714   \n",
       "tn              27.0      30.0      31.0      31.0      31.0      22.0   \n",
       "fp               8.0       5.0       4.0       4.0       4.0      13.0   \n",
       "fn              16.0      19.0      19.0      21.0      19.0      10.0   \n",
       "tp              12.0       9.0       9.0       7.0       9.0      18.0   \n",
       "acc_test1   0.714286  0.619048  0.619048  0.571429  0.619048  0.619048   \n",
       "precision1  0.666667       0.5       0.5  0.333333       0.5       0.5   \n",
       "recall1          0.5      0.25     0.375     0.125     0.375       0.5   \n",
       "f1score1    0.571429  0.333333  0.428571  0.181818  0.428571       0.5   \n",
       "\n",
       "              iter_7  \n",
       "parameter             \n",
       "verbose            0  \n",
       "best_score  0.560185  \n",
       "best_index       2.0  \n",
       "acc_train   0.773869  \n",
       "acc_val         0.62  \n",
       "acc_test    0.619048  \n",
       "precision   0.666667  \n",
       "recall      0.285714  \n",
       "f1score          0.4  \n",
       "roc         0.585714  \n",
       "tn              31.0  \n",
       "fp               4.0  \n",
       "fn              20.0  \n",
       "tp               8.0  \n",
       "acc_test1   0.619048  \n",
       "precision1       0.5  \n",
       "recall1         0.25  \n",
       "f1score1    0.333333  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.iloc[52:70, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space, parameters and results save\n",
    "df_one.to_csv(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.csv')\n",
    "df_one.to_pickle(f'{directory_for_model}{com_name}/params_results_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 아래 내용은 위의 df_one을 대체함.\n",
    "# parameter and results save\n",
    "df_base.to_csv(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.csv')\n",
    "df_base.to_pickle(f'{directory_for_model}{com_name}/lgbm_{gsbs}_df_{dt}.pkl')\n",
    "\n",
    "# search_space, parameters save\n",
    "df_params.to_csv(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.csv')\n",
    "df_params.to_pickle(f'{directory_for_model}{com_name}/params_{gsbs}_df_{dt}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# save model\\n# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\\njoblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\\nsave_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\\njoblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\\nsave_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\\nsave_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# save model\n",
    "# 필요시 저장. 가장 좋은 결과만 저장하고자할 때는 밑의 save_best_results만 진행하면 됨.\n",
    "joblib.dump(lgbmBS.best_estimator_, f'{directory_for_model}{com_name}/estimator_{gsbs}_{dt}_v{iter}.pkl') # bayessearchcv 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/model_{gsbs}_{dt}_v{iter}_p.pkl', lgbmBS.best_estimator_)\n",
    "joblib.dump(scaler, f'{directory_for_model}{com_name}/scaler_{gsbs}_{dt}_v{iter}.pkl') # scaler 저장\n",
    "save_to_pickle(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.pkl', new_col)\n",
    "save_list_to_csv(f'{directory_for_model}{com_name}/columns_{gsbs}_{dt}_{len(new_col)}_{round(precision*100):2d}%_{round(f1score*100):2d}%_ver{iter}.csv', new_col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 최종 가장 좋은 결과 저장\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m save_best_results(com_name, \u001b[43mlgbmBS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m, scaler, new_col, df_base)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# 최종 가장 좋은 결과 저장\n",
    "save_best_results(com_name, lgbmBS.best_estimator_, scaler, new_col, df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lgbmBS.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbmBS.best_estimator_\n",
    "feature_df = pd.DataFrame(model.booster_.feature_importance(importance_type='gain'), \n",
    "                      index=data.columns, columns=['importance']).sort_values(by='importance', \n",
    "                                                                              ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.tail(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = list(feature_df.index[:35]) +  ['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "5-1 결정 트리.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
