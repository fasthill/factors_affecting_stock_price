{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f051084f",
   "metadata": {},
   "source": [
    "### feature합치기\n",
    "#### investors, historical(매일 거래량 등) and 분류항목 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b930a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f7032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index column : date\n",
    "def find_previous_date(df_inv, df_his, date_current): # 현재일에서 바로 직전 1~3거래일을 찾음.\n",
    "    i = 0\n",
    "    date2 = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        date2 = date_current - datetime.timedelta(days = i)\n",
    "\n",
    "        if (df_inv.loc[date2]['retail'] != 0) & (df_his.loc[date2]['vol'] != '') :  \n",
    "            # investors와 historical 두 개 데이터에 같이 없어야 함\n",
    "            break\n",
    "        if i >= 30:  # 현재일 대비 최대 30일전까지 거래가 있을 경우 계산 (현실적으로 최대 10일 이상 폐장되는 경우 없음)\n",
    "            break\n",
    "            \n",
    "    return date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf12fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래일과 거래일 바로 이전일의 변화율을 계산함.\n",
    "def find_ratio(df_o, date_current):\n",
    "    df_o_trans = df_o.transpose()\n",
    "    df_o_trans.columns = ['before', 'after']\n",
    "    df_o_trans[date_current] = (df_o_trans['after'] - df_o_trans['before']) / df_o_trans['before']\n",
    "    return df_o_trans.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f6c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변화율(historical, investors), weekday를 계산하고 합하여 return함\n",
    "def combine_data(df_o, df_inv, df_his):\n",
    "    # df_inv : df_investor, df_his: df_historical\n",
    "    investor_rate = pd.DataFrame()\n",
    "    historical_rate = pd.DataFrame()\n",
    "    date_weekday = pd.DataFrame()\n",
    "    \n",
    "    # 최초의 0이 아닌(최초 거래가 이루어진 일자) 날짜로 부터 일주일 후부터 기준.\n",
    "    # 최초 2일전까지의 날짜를 확보하기 위함. 현재일의 전날과 전전날의 이틀간 데이터 변화율 계산\n",
    "    for k, i in enumerate(df_inv.iloc[:, 1]):  \n",
    "        if i != 0: \n",
    "            skip_num = k + 10 # 8: 전일, 9: 전전일, 10: -3일까지 확보 \n",
    "            break\n",
    "\n",
    "    for date_current in df_o.index[skip_num:]: \n",
    "        # 최초 2일전까지의 날짜를 확보하기 위함. 현재일의 전날과 전전날의 이틀간 데이터 변화율 계산\n",
    "        # 거래 전일(-1일) 날짜 구하기\n",
    "        date_previous_c = find_previous_date(df_inv, df_his, date_current)\n",
    "        # 거래 전날 요일 구하기\n",
    "        date_temp = {'date': date_current, 'weekday' : date_previous_c.weekday()}\n",
    "        df_temp = pd.DataFrame(date_temp, index=[0]).set_index('date')\n",
    "        date_weekday = pd.concat([date_weekday, df_temp], axis=0)\n",
    "        date_previous_1 = find_previous_date(df_inv, df_his, date_previous_c)\n",
    "        # 거래 전날, 전전날을 확인하고 변화정도 계산하기(find_ratio)\n",
    "        df_inv_comp_1 = df_inv.loc[[date_previous_1, date_previous_c]]\n",
    "        df_his_comp_1 = df_his.loc[[date_previous_1, date_previous_c]]\n",
    "    \n",
    "    \n",
    "        # 거래 전전일(-2일) 날짜 구하기\n",
    "        date_previous_2 = find_previous_date(df_inv, df_his, date_previous_1)\n",
    "        # 거래 전전날(-2일째) 요일 구하기  -- 2일전 요일은 의미 없을 것 같아서 추가하지 않음.\n",
    "#         date_temp_2 = {'date': date_current, 'weekday' : date_previous_2.weekday()}\n",
    "#         df_temp_2 = pd.DataFrame(date_temp_2, index=[0]).set_index('date')\n",
    "#         date_weekday = pd.concat([date_weekday, df_temp_2], axis=0)\n",
    "        # 거래 전날(-1일), 전전날(-3일)을 확인하고 변화정도 계산하기(find_ratio)\n",
    "        df_inv_comp_2 = df_inv.loc[[date_previous_2, date_previous_c]]\n",
    "        df_his_comp_2 = df_his.loc[[date_previous_2, date_previous_c]]\n",
    "        \n",
    "        \n",
    "        # 전날 -전전날 ratio, 전날 - 전전전날 ratio, column확대\n",
    "        df_inv_concat_2 = pd.concat([find_ratio(df_inv_comp_1, date_current).iloc[[-1]],\n",
    "                                 find_ratio(df_inv_comp_2, date_current).iloc[[-1]]], axis=1)\n",
    "        df_his_concat_2 = pd.concat([find_ratio(df_his_comp_1, date_current).iloc[[-1]],\n",
    "                                 find_ratio(df_his_comp_2, date_current).iloc[[-1]]], axis=1)\n",
    "        \n",
    "        investor_rate = pd.concat([investor_rate,  df_inv_concat_2], axis=0)\n",
    "        historical_rate = pd.concat([historical_rate, df_his_concat_2], axis=0)\n",
    "\n",
    "    total = pd.concat([investor_rate, historical_rate, date_weekday, df_o ], axis=1)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f53561",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'],\n",
    "                 '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "# code = {'005930': ['삼성전자', 'sec']}\n",
    "\n",
    "code = {'005930' : ['삼성전자', 'sec'], '373220' : ['LG에너지솔루션', 'lgenergy'], \n",
    "        '000660' : ['SK하이닉스', 'skhinix'], '207940' : ['삼성바이오로직스', 'ssbio'],\n",
    "        '006400' : ['삼성SDI', 'sdi'], '051910' : ['LG화학', 'lgchemical'],\n",
    "        '005935' : ['삼성전자우', 'secpre'], '005380' : ['현대차', 'hyunmotor'],\n",
    "        '035420' : ['NAVER', 'naver'], '000270' : ['기아','kia'],\n",
    "        '035720' : ['카카오', 'kakao'], '005490' : ['POSCO홀딩스', 'poscoholding'],\n",
    "        '105560' : ['KB금융', 'kbbank'], '028260' : ['삼성물산', 'sscnt'],\n",
    "        '068270' : ['셀트리온', 'celltrion'], '012330' : ['현대모비스', 'mobis'],\n",
    "        '055550' : ['신한지주', 'shgroup'], '066570' : ['LG전자', 'lgelec'],\n",
    "        '003670' : ['포스코케미칼', 'poscochemical'], '096770' : ['SK이노베이션', 'skinnovation'],\n",
    "        '033780' : ['KT&G', 'ktng']}\n",
    "# code = {'035420' : ['NAVER', 'naver']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587a0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_column = [ 'date', 'open', 'high', 'low', 'close', 'close_cr', 'vol']\n",
    "hist_column_m = [ 'date', 'open', 'high', 'low', 'close', 'vol'] # close_cr 제외하고 사용. divided by zero 회피용\n",
    "inv_column = ['date', 'retail', 'foreigner', 'institution', 'financial', 'invtrust', 'pension', 'privequity',\n",
    "              'bank', 'insurance', 'financeetc', 'corporateetc', 'foreigneretc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8615f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# investor.pkl, historical.pkl. 읽기\n",
    "\n",
    "# ****************************************************************************************************\n",
    "## 주요: 오늘날짜로 데이터를 분석하고자 하면 pkl directory 내의 .pkl 데이터가 오늘 날짜로 모두 update시켜 놓아야 함.\n",
    "##   C:\\jupyter연습\\factors_affecting_stock_price' 디렉토리에 있는\n",
    "#    'get_company_daily_price_since_last_update_to_pickle.ipynb' 과 (historical.pkl과 investors.pkl update 프로그램)\n",
    "#     'get_common_data_since_last_update_to_pickle (미국, 한국 주요 지표 등 update용)\n",
    "# ****************************************************************************************************\n",
    "directory_for_ml_ex = '../data/data_for_ml/expand_date/'\n",
    "directory_for_ml_ex_update = '../data/data_for_ml/expand_date/update/'\n",
    "pkl_directory = '../data/company_pkl/'\n",
    "\n",
    "# 전체 column을 선정하여, 분석시에 선별하여 사용하도록 함.\n",
    "\n",
    "\n",
    "\n",
    "for key, val in code.items():\n",
    "#     pkl_name= '{}{}_4class.pkl'.format(directory_for_ml, val[1])\n",
    "#     df_class_temp = pd.read_pickle(pkl_name)\n",
    "#     df_class_temp['date'] = pd.to_datetime(df_class_temp['date']) #change to timestamp\n",
    "#     df_class_temp['date'] = df_class_temp['date'].dt.date  # change to datetime\n",
    " \n",
    "    pkl_name= '{}_historical.pkl'.format(val[1])\n",
    "    df_historical_temp = pd.read_pickle(pkl_directory + pkl_name)\n",
    "    df_historical_temp = df_historical_temp[hist_column_m]\n",
    "    # close_cr 행을 없앰(변동이 없는 경우가 빌생하여 divided zero error 발생), close_cr은 target column에서 재 계산하여사용\n",
    "    df_historical_temp['date'] = df_historical_temp['date'].dt.date # change to datetime\n",
    "    \n",
    "    pkl_name= '{}_investors.pkl'.format(val[1])\n",
    "    df_investors_temp = pd.read_pickle(pkl_directory + pkl_name)\n",
    "    df_investors_temp['date'] = df_investors_temp['date'].dt.date # change to datetime\n",
    "    \n",
    "    # ******** 시작 일자, 마지막 일자  지정 ***********\n",
    "    start_date = datetime.date(2022, 1, 1) # 2022년 01월 01일 자료 있음. 추후 이전날짜 추가시 수정 필요\n",
    "    end_date = df_investors_temp['date'].iloc[-1]  # 투자자별 자료가 있는 마지막 날짜\n",
    "    \n",
    "    date_range_ts = pd.date_range(start=start_date, end=end_date)\n",
    "    df_base = pd.DataFrame(pd.Series(date_range_ts, name='date'))\n",
    "    df_base['date'] = df_base['date'].dt.date\n",
    "    \n",
    "# get combined data (eg. df_sec_combined, df_ktng_combined...)\n",
    "#     df_combined_temp = combine_data(df_class_temp.set_index('date'), df_investors_temp.set_index('date'),\n",
    "#                                     df_historical_temp.set_index('date'))\n",
    "\n",
    "    df_combined_temp = combine_data(df_base.set_index('date'), \n",
    "                                    df_investors_temp.set_index('date'), df_historical_temp.set_index('date'))\n",
    "    \n",
    "    # column nama change according to the newly added columns\n",
    "    column_name_change = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "          'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', 'foreigneretc_1', \n",
    "          'retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2', \n",
    "          'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', 'foreigneretc_2', \n",
    "          'open_1', 'high_1', 'low_1', 'close_1', 'vol_1', \n",
    "          'open_2', 'high_2', 'low_2', 'close_2', 'vol_2', 'weekday' ]\n",
    "    \n",
    "    df_combined_temp.columns = column_name_change\n",
    "    \n",
    "    min_rate = 0.0 # +로 끝난 상황을 알기 위함\n",
    "    df_combined_temp['cr_00'] = df_combined_temp['close_1'].map(lambda x : 0 if x <= min_rate else ( 1 if x > min_rate  else  \"\" ))\n",
    "    min_rate = 0.005 # 수수료등 비용 0.2672% 이상 확인하기 위함, 0.5% 상승 마감\n",
    "    df_combined_temp['cr_05'] = df_combined_temp['close_1'].map(lambda x : 0 if x <= min_rate else ( 1 if x > min_rate  else  \"\" ))\n",
    "    min_rate = 0.010 # 1.0% 상승 마감\n",
    "    df_combined_temp['cr_10'] = df_combined_temp['close_1'].map(lambda x : 0 if x <= min_rate else ( 1 if x > min_rate  else  \"\" ))\n",
    "    min_rate = 0.015 # 1.5% 상승 마감\n",
    "    df_combined_temp['cr_15'] = df_combined_temp['close_1'].map(lambda x : 0 if x <= min_rate else ( 1 if x > min_rate  else  \"\" ))\n",
    "    min_rate = 0.020 # 2.0% 상승 마감\n",
    "    df_combined_temp['cr_20'] = df_combined_temp['close_1'].map(lambda x : 0 if x <= min_rate else ( 1 if x > min_rate  else  \"\" ))\n",
    "    \n",
    "    column_selected = column_name_change\n",
    "    column_selected.extend(['cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20'])  # 아래 class column 이 변경에 따라 수정해야 함\n",
    "    \n",
    "    globals()['df_{}_{}'.format(val[1], 'combined')] = df_combined_temp.copy()\n",
    "    globals()['df_{}_{}'.format(val[1], 'sel')] = df_combined_temp[column_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf45e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 전체 column을 선정하여, 분석시에 선별하여 사용하도록 함.\\ncolumn_selected = ['retail', 'foreigner', 'institution', 'financial', 'invtrust', 'pension', 'privequity',\\n              'bank', 'insurance', 'financeetc', 'corporateetc', 'foreigneretc',\\n              'open', 'high', 'low', 'close', 'vol','weekday']\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 전체 column을 선정하여, 분석시에 선별하여 사용하도록 함.\n",
    "column_selected = ['retail', 'foreigner', 'institution', 'financial', 'invtrust', 'pension', 'privequity',\n",
    "              'bank', 'insurance', 'financeetc', 'corporateetc', 'foreigneretc',\n",
    "              'open', 'high', 'low', 'close', 'vol','weekday']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da712d0",
   "metadata": {},
   "source": [
    "## 주요 지표 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f903c8",
   "metadata": {},
   "source": [
    "### Read and Combine data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "186962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_pkl = [\"bok_rate.pkl\", \"cpi.pkl\", \"dji.pkl\", \"dji_future.pkl\", \"dxy_future.pkl\", \n",
    "#               \"fear_greed.pkl\", \"fed_rate.pkl\", \"gold.pkl\", \"ixic_future.pkl\", \"kor_10yr_bond.pkl\",\n",
    "#               \"kor_2yr_bond.pkl\", \"kosdaq.pkl\", \"kospi.pkl\", \"krw_rate.pkl\", \"nas.pkl\",\n",
    "#               \"snp_future.pkl\", \"sox.pkl\", \"spx.pkl\", \"us_10yr_bond.pkl\", \"us_2yr_bond.pkl\",\n",
    "#               \"us_3mon_bond.pkl\", \"vix.pkl\", \"wti_future.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187ec9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매일 변화가 있는 항목 추출; 금리변동과 같이 주기적을 발생하는 항목들(cpi, bok_rate, fed_rate 등)은 제외\n",
    "common_pkl = [ \"dji.pkl\", \"dji_future.pkl\", \"dxy_future.pkl\", \n",
    "               \"ixic_future.pkl\", \"kor_10yr_bond.pkl\",\n",
    "              \"kor_2yr_bond.pkl\", \"kosdaq.pkl\", \"kospi.pkl\", \"krw_rate.pkl\", \"nas.pkl\",\n",
    "              \"snp_future.pkl\", \"sox.pkl\", \"spx.pkl\", \"us_10yr_bond.pkl\", \"us_2yr_bond.pkl\",\n",
    "              \"us_3mon_bond.pkl\", \"vix.pkl\", \"wti_future.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0581e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_col_name = {'dji.pkl':'dji', 'dji_future.pkl':'dji_f', 'dxy_future.pkl':'dxy', \n",
    "                   'ixic_future.pkl':'ixic_f', 'kor_10yr_bond.pkl':'bond_kor_10',\n",
    "                   'kor_2yr_bond.pkl':'bond_kor_2', 'kosdaq.pkl':'kosdaq', 'kospi.pkl':'kospi',\n",
    "                   'krw_rate.pkl':'krw', 'nas.pkl':'ixic', 'snp_future.pkl':'spx_f',\n",
    "                   'sox.pkl':'sox', 'spx.pkl':'spx', 'us_10yr_bond.pkl':'bond_usa_10',\n",
    "                   'us_2yr_bond.pkl':'bond_usa_2', 'us_3mon_bond.pkl':'bond_usa_3m',\n",
    "                   'vix.pkl':'vix', 'wti_future.pkl':'wti' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe4e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.datetime.today().date()\n",
    "start_date = '20220101'  # 2022년 01월 01일 자료 있음. 추후 이전날짜 추가시 수정 필요\n",
    "date_range_ts = pd.date_range(start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab23266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_common_directory = '../data/common_pkl/'\n",
    "# df_base = pd.DataFrame(pd.Series(date_range_ts, name='date')).set_index('date')\n",
    "# # for index_name in major_index:\n",
    "# for index_name in common_pkl:\n",
    "#     key_name = index_name[:-4]\n",
    "# #     globals()['df_{}'.format(key_name)] = pd.read_pickle(pkl_common_directory + index_name)\n",
    "# #     df_base = df_base.merge(globals()['df_{}'.format(key_name)].set_index('date').iloc[:, [-1]], \\\n",
    "# #                             how='left', left_index=True, right_index=True)\n",
    "#     df_temp = pd.read_pickle(pkl_common_directory + index_name)\n",
    "#     df_temp['date'] = df_temp['date'] + datetime.timedelta(days = 1) # 하루전 데이터와 일치시키기 위하여 하루 shift\n",
    "#     df_base = df_base.merge(df_temp.set_index('date').iloc[:, [-1]], \\\n",
    "#                             how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eac7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_common_directory = '../data/common_pkl/'\n",
    "df_base = pd.DataFrame(pd.Series(date_range_ts, name='date')).set_index('date')\n",
    "# for index_name in major_index:\n",
    "for index_name in common_pkl:\n",
    "    key_name = index_name[:-4]\n",
    "    col_name = common_col_name[index_name]\n",
    "    df_temp = pd.read_pickle(pkl_common_directory + index_name)\n",
    "    df_temp['temp'] = df_temp[col_name].shift(2)  # 2일전 데이터와 비교하기 위하여 shift\n",
    "    df_temp[f'{col_name}_cr_2'] = (df_temp[col_name] - df_temp['temp'])/df_temp['temp']*100\n",
    "    df_temp['date'] = df_temp['date'] + datetime.timedelta(days = 1) # 하루전 데이터와 일치시키기 위하여 하루 shift\n",
    "    df_base = df_base.merge(df_temp.set_index('date').iloc[:, [-3, -1]], \\\n",
    "                            how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2328fa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_sec_sel = df_sec_combined[column_selected]\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_sec_sel = df_sec_combined[column_selected]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d5ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in code.items():\n",
    "    globals()['df_{}_sel'.format(val[1])] \\\n",
    "    = globals()['df_{}_sel'.format(val[1])].merge(df_base, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a099ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_sec_sel = df_sec_sel.merge(df_base, how='left', left_index=True, right_index=True)\\ndf_hyunmotor_sel = df_hyunmotor_sel.merge(df_base, how='left', left_index=True, right_index=True)\\ndf_naver_sel = df_naver_sel.merge(df_base, how='left', left_index=True, right_index=True)\\ndf_ktng_sel = df_ktng_sel.merge(df_base, how='left', left_index=True, right_index=True)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_sec_sel = df_sec_sel.merge(df_base, how='left', left_index=True, right_index=True)\n",
    "df_hyunmotor_sel = df_hyunmotor_sel.merge(df_base, how='left', left_index=True, right_index=True)\n",
    "df_naver_sel = df_naver_sel.merge(df_base, how='left', left_index=True, right_index=True)\n",
    "df_ktng_sel = df_ktng_sel.merge(df_base, how='left', left_index=True, right_index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9581d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 column을 선정하여, 분석시에 선별하여 사용하도록 함.\n",
    "# weekday, 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20' column을 마지막으로 이동 \n",
    "new_columns = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', \n",
    "               'privequity_1', 'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', 'foreigneretc_1', \n",
    "               'dji_cr', 'dji_f_cr', 'ixic_cr', 'ixic_f_cr', 'spx_cr', 'spx_f_cr', 'bond_kor_10_cr',\n",
    "               'bond_kor_2_cr', 'dxy_cr', 'bond_usa_10_cr','bond_usa_2_cr', 'bond_usa_3m_cr',\n",
    "               'kosdaq_cr', 'kospi_cr', 'krw_cr', 'sox_cr', 'vix_cr', 'wti_cr',                \n",
    "               'open_1', 'high_1', 'low_1', 'close_1', 'vol_1',      \n",
    "               'retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "               'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', 'foreigneretc_2',\n",
    "               'dji_cr_2', 'dji_f_cr_2', 'ixic_cr_2', 'ixic_f_cr_2', 'spx_cr_2', 'spx_f_cr_2',\n",
    "               'bond_kor_10_cr_2', 'bond_kor_2_cr_2', 'dxy_cr_2', 'bond_usa_10_cr_2','bond_usa_2_cr_2', \n",
    "               'bond_usa_3m_cr_2', 'kosdaq_cr_2', 'kospi_cr_2', 'krw_cr_2', 'sox_cr_2', 'vix_cr_2', 'wti_cr_2', \n",
    "#                 'open', 'high', 'low', 'close', 'vol', 'weekday',  # close column 제거함 (class column 계산항목으로 사용됨)\n",
    "                'open_2', 'high_2', 'low_2', 'close_2', 'vol_2', 'weekday', \n",
    "                'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02da1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 순서 변경 : weekday, 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20' column을 마지막으로 이동 \n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_sel'.format(val[1])] = globals()['df_{}_sel'.format(val[1])][new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4f1fa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# drop inf, -inf : replace inf to 1 or -1 . 데이터를 살리고\\n# 변동률이 무한대가 되는 것을 방지하기 위해서, 나중에 발생하는 에러를 방지\\ndf_sec_sel.replace([np.inf, -np.inf], [1, -1], inplace=True)\\n\\n.impute 사용하는 것을 고려할 필요 있음.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# drop inf, -inf : replace inf to 1 or -1 . 데이터를 살리고\n",
    "# 변동률이 무한대가 되는 것을 방지하기 위해서, 나중에 발생하는 에러를 방지\n",
    "df_sec_sel.replace([np.inf, -np.inf], [1, -1], inplace=True)\n",
    "\n",
    ".impute 사용하는 것을 고려할 필요 있음.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e91c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop inf, -inf : replace inf to 1 or -1 . 데이터를 살리고\n",
    "# 변동률이 무한대가 되는 것을 방지하기 위해서, 나중에 발생하는 에러를 방지\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_sel'.format(val[1])].replace([np.inf, -np.inf], [1, -1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec3975e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete rows which include NaN : dji, spx, nasdaq 지수가 nan인 rows 제거\n",
    "# df_sec_sel.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a6d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows which include NaN : dji, spx, nasdaq 지수가 nan인 rows 제거\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_sel'.format(val[1])].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f3061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string column을 numeric으로 전환\n",
    "def string_to_num(df):\n",
    "    df.replace('%', '', regex=True, inplace=True)\n",
    "    return df.apply(pd.to_numeric)\n",
    "'''\n",
    "df_sec_sel = string_to_num(df_sec_sel)\n",
    "'''\n",
    "\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_sel'.format(val[1])] = string_to_num(globals()['df_{}_sel'.format(val[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e8d5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 데이터 저장\n",
    "'''\n",
    "directory_for_ml_ex_update = '../data/data_for_ml/expand_date/update/'\n",
    "df_sec_sel.to_pickle(directory_for_ml_ex_update + 'df_sec_sel.pkl')\n",
    "df_sec_sel.to_csv(directory_for_ml_ex_update + 'df_sec_sel.csv')\n",
    "'''\n",
    "\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_sel'.format(val[1])].to_pickle(directory_for_ml_ex + 'df_{}_sel.pkl'.format(val[1]))\n",
    "    globals()['df_{}_sel'.format(val[1])].to_csv(directory_for_ml_ex + 'df_{}_sel.csv'.format(val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c5e5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
