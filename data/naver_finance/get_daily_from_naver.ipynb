{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "matched-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import datetime, time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3f2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cfscrape # 403 forbidden, cloudflare error을 해결하기 위한 모듈\n",
    "import cloudscraper\n",
    "scraper = cloudscraper.create_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08943027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install cfscrape # 403 forbidden, cloudflare error을 해결하기 위한 모듈\n",
    "# import cfscrape\n",
    "# scraper = cfscrape.create_scraper()\n",
    "# # 이후 403 error이 발생한 곳에는 requests 대신 scraper 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selective-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Referer': 'https://kr.investing.com/',\n",
    "           'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbcbb53-e0e0-496d-adb7-a57c3341ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df_o, df, dup_col, sort_col):\n",
    "    df_o = pd.concat([df_o, df], ignore_index=True)\n",
    "    df_o.drop_duplicates(subset=[dup_col], keep='last', inplace=True) # dup_col 중첩제거 기준 컬럼 이름: \"time\", \"date\" 등\n",
    "#     df_o.drop_duplicates(subset=[dup_col], keep='first', inplace=True)\n",
    "    df_o.sort_values(by=[df_o.columns[sort_col]], inplace=True) # sort_col 정렬 기준 컬럼 번호\n",
    "    df_o.index = np.arange(0, len(df_o))  # 일련 번호 오름차순으로 재 설정\n",
    "    return df_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98171c7f-8e92-4ea7-a933-c4855c8bb1a8",
   "metadata": {},
   "source": [
    "## 시간별 시세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c80d5a0-f562-4f37-9363-ee1056d572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정일의 시간별 시세 취득을 위한 페이지별 table 데이터 취득. page는 날짜별로 약 40쪽. 09:00:00부터 1분간격으로 15:58:00 까지.\n",
    "def get_piece_time_price(url_t):\n",
    "    res = scraper.get(url_t, headers=headers)\n",
    "    class_name = 'type2'\n",
    "    df = pd.read_html(io.StringIO(str(res.text)), attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "    \n",
    "    df = df.dropna(axis=0) # delete rows with nan values\n",
    "    df.columns = ['time', 'price', 'change', 'sell', 'buy', 'volume', 'change_volumn'] # rename column in english from korean\n",
    "\n",
    "    # convert character values to integer value : 보합= 0, 하락= -, 상승= +\n",
    "    df['change'] = df['change'].apply(lambda x: int(x[2:]) if x[:2] == '보합' \n",
    "                                      else (-int(x[4:].replace(',','')) if x[:2] == '하락' \n",
    "                                            else int(x[4:].replace(',',''))))  # convert characters to int\n",
    "    \n",
    "    df = df[['time', 'price', 'change', 'volume']]  # delete unnecessary columns\n",
    "\n",
    "    # define variable types\n",
    "    df['time'] = df['time'].apply(lambda x : datetime.datetime.strptime(x, \"%H:%M\").time())  # convert characters to datetime objet\n",
    "    df['price'] = df['price'].astype(int)\n",
    "    df['volume'] = df['volume'].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699280b8-7e5c-450f-864a-b27d9329a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정일의 시간대별 가격 40쪽을 한개의 df로 묶는 기능\n",
    "def get_time_price(url_base_t, code_com, collect_date):\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # make first data frame\n",
    "    collect_date_time = collect_date + '160000' # 장종료후 16시 00분 00초에 시간별 시세 추출\n",
    "    page = str(page_num)\n",
    "    \n",
    "    url = url_base_t + '?code=' + code_com + '&thistime=' + collect_date_time + '&page=' + page\n",
    "    df_base = get_piece_time_price(url)\n",
    "    \n",
    "    page_num = page_num + 1\n",
    "    \n",
    "    while True:\n",
    "        page = str(page_num)\n",
    "        \n",
    "        url = url_base_t + '?code=' + code_com + '&thistime=' + collect_date_time + '&page=' + page\n",
    "        df_p = get_piece_time_price(url)\n",
    "    \n",
    "        df_base = concat_df(df_base, df_p, 'time', 0)  # df concat후 'time' column을 기준으로 중복제거 후 0 column을 기준으로 정렬시킴.\n",
    "        # print('page_num', page_num)\n",
    "        \n",
    "        if df_p['time'].iloc[-1] == datetime.time(9, 00):\n",
    "            break\n",
    "    \n",
    "        page_num = page_num + 1\n",
    "    \n",
    "    df_base['date'] = datetime.datetime.strptime(collect_date, '%Y%m%d') # insert column with collecting date\n",
    "    df_base = df_base[['date', 'time', 'price', 'change', 'volume']]  \n",
    "\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b751c7-63fc-4f11-ac67-1ee03bee6d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# naver_dir = 'data/naver_finance/time_data'\n",
    "naver_dir = 'time_data'\n",
    "\n",
    "url_base = 'https://finance.naver.com/item/sise_time.naver'  # sise_date\n",
    "\n",
    "code_dic = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'], \n",
    "        '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "# code_list = list(code_dic.items())\n",
    "# code_company_name = code_list[0]\n",
    "# code = code_company_name[0] # 취득을 원하는 회사 주식 코드\n",
    "code_dic = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'], }\n",
    "code_dic = {'035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "\n",
    "c_date = ['20240619', '20240620', '20240621', '20240624', '20240625', '20240626'] # 취득이 필요한 날짜 리스트\n",
    "# 오늘날짜부터 1주일전까지만 가능함. c_date 시작일자는 20200101 부터 있음.\n",
    "# \n",
    "# c_date = ['20240626', '20240620'] \n",
    "# c_date = ['20240619'] \n",
    "for i, (code, company_name) in enumerate(code_dic.items()):\n",
    "    for collect_date in c_date:\n",
    "        df_collect = get_time_price(url_base, code, collect_date)\n",
    "        # add logic to save date for each date for each company\n",
    "        f_name = f'{naver_dir}/{company_name[1]}_{collect_date}.csv'\n",
    "        df_collect.to_csv(f_name)\n",
    "        df_collect.to_pickle(f_name.replace('csv','pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae7fc7-ceb8-4886-af2c-f856d2403168",
   "metadata": {},
   "source": [
    "## 일별시세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebbbd01b-12d7-4956-9bec-301933b1b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자별 주식 데이터를 페이지별로 10개씩 취득\n",
    "def get_piece_date_price(url_d):\n",
    "    res = scraper.get(url_d, headers=headers)\n",
    "    class_name = 'type2'\n",
    "    df = pd.read_html(io.StringIO(str(res.text)), attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "    \n",
    "    df = df.dropna(axis=0) # delete nan rows\n",
    "\n",
    "    df.columns = ['date', 'close', 'close_change', 'open', 'high', 'low', 'volume'] # rename column\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.datetime.strptime(x, '%Y.%m.%d')) # convert character to datetime object\n",
    "    \n",
    "    # convert character values to integer value : 보합= 0, 하락= -, 상승= +\n",
    "    df['close_change'] = df['close_change'].apply(lambda x: int(x[2:]) if x[:2] == '보합' \n",
    "                                  else (-int(x[4:].replace(',','')) if x[:2] == '하락' \n",
    "                                        else int(x[4:].replace(',',''))))  # convert characters to int\n",
    "    # define variable types\n",
    "    df['open'] = df['open'].astype(int)\n",
    "    df['high'] = df['high'].astype(int)\n",
    "    df['low'] = df['low'].astype(int)\n",
    "    df['close'] = df['close'].astype(int)\n",
    "    df['volume'] = df['volume'].astype(int)\n",
    "    \n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'close_change', 'volume']]  # rearrange columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "309638e3-7ee2-4b51-b67c-c12e9f20f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개씩의 일자별 데이터를 원하는 일자부터 현재일자까지 합하어 취득\n",
    "def get_date_price(url_base_d, code_com):\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # make first data frame\n",
    "    page = str(page_num)\n",
    "    url_date = url_base_d + '?code=' + code_com + '&page=' + page\n",
    "    df_base = get_piece_date_price(url_date)\n",
    "    \n",
    "    page_num = page_num + 1\n",
    "    \n",
    "    while True:\n",
    "        page = str(page_num)\n",
    "        \n",
    "        url_date = url_base_d + '?code=' + code_com + '&page=' + page\n",
    "        df_p = get_piece_date_price(url_date)\n",
    "    \n",
    "        df_base = concat_df(df_base, df_p, 'date', 0)  # df concat후 'time' column을 기준으로 중복제거 후 0 column을 기준으로 정렬시킴.\n",
    "\n",
    "        startdate_str = '2020/1/2 00:00:00' # 데이터 수집 시작 일자, startdate_str\n",
    "        startdate = datetime.datetime.strptime(startdate_str, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "        if (startdate == df_base['date']).any(): # 시작일자와 일치하는 row가 있으면 더 이상 진행하지 않음.\n",
    "            break\n",
    "\n",
    "        page_num = page_num + 1\n",
    "\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8624b98e-d394-4d8d-aeeb-545d7fcdd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver_dir = 'data/naver_finance/date_data'\n",
    "naver_dir = 'date_data'\n",
    "\n",
    "url_base = 'https://finance.naver.com/item/sise_day.naver'  # sise_day\n",
    "\n",
    "code_dic = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'], \n",
    "        '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "\n",
    "# code_dic = {'005930': ['삼성전자', 'sec'],}\n",
    "\n",
    "for i, (code, company_name) in enumerate(code_dic.items()):\n",
    "    df_collect = get_date_price(url_base, code)\n",
    "    f_name = f'{naver_dir}/{company_name[1]}.csv'\n",
    "    df_collect.to_csv(f_name)\n",
    "    df_collect.to_pickle(f_name.replace('csv','pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6669a8ad-efec-4a67-be11-700c6c08bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_change</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>85500</td>\n",
       "      <td>86100</td>\n",
       "      <td>85000</td>\n",
       "      <td>85500</td>\n",
       "      <td>300</td>\n",
       "      <td>178185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>86300</td>\n",
       "      <td>86900</td>\n",
       "      <td>86000</td>\n",
       "      <td>86700</td>\n",
       "      <td>1200</td>\n",
       "      <td>285464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>85900</td>\n",
       "      <td>86700</td>\n",
       "      <td>85500</td>\n",
       "      <td>85900</td>\n",
       "      <td>-800</td>\n",
       "      <td>159538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>86000</td>\n",
       "      <td>86900</td>\n",
       "      <td>85900</td>\n",
       "      <td>86500</td>\n",
       "      <td>600</td>\n",
       "      <td>185079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>86100</td>\n",
       "      <td>86800</td>\n",
       "      <td>86000</td>\n",
       "      <td>86500</td>\n",
       "      <td>0</td>\n",
       "      <td>126821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>86500</td>\n",
       "      <td>87300</td>\n",
       "      <td>85900</td>\n",
       "      <td>85900</td>\n",
       "      <td>-600</td>\n",
       "      <td>349698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>85300</td>\n",
       "      <td>86800</td>\n",
       "      <td>85300</td>\n",
       "      <td>86800</td>\n",
       "      <td>900</td>\n",
       "      <td>490156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>86500</td>\n",
       "      <td>86800</td>\n",
       "      <td>86000</td>\n",
       "      <td>86800</td>\n",
       "      <td>0</td>\n",
       "      <td>104525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>86700</td>\n",
       "      <td>87000</td>\n",
       "      <td>86100</td>\n",
       "      <td>86500</td>\n",
       "      <td>-300</td>\n",
       "      <td>213667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2024-06-19</td>\n",
       "      <td>87200</td>\n",
       "      <td>87300</td>\n",
       "      <td>86000</td>\n",
       "      <td>86400</td>\n",
       "      <td>-100</td>\n",
       "      <td>153855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>86000</td>\n",
       "      <td>86900</td>\n",
       "      <td>86000</td>\n",
       "      <td>86700</td>\n",
       "      <td>300</td>\n",
       "      <td>165516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>86800</td>\n",
       "      <td>87000</td>\n",
       "      <td>86100</td>\n",
       "      <td>86300</td>\n",
       "      <td>-400</td>\n",
       "      <td>206548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>86500</td>\n",
       "      <td>86500</td>\n",
       "      <td>85700</td>\n",
       "      <td>85900</td>\n",
       "      <td>-400</td>\n",
       "      <td>171990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>86600</td>\n",
       "      <td>86600</td>\n",
       "      <td>85700</td>\n",
       "      <td>85800</td>\n",
       "      <td>-100</td>\n",
       "      <td>222460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>85500</td>\n",
       "      <td>86500</td>\n",
       "      <td>85000</td>\n",
       "      <td>86500</td>\n",
       "      <td>700</td>\n",
       "      <td>220987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   open   high    low  close  close_change  volume\n",
       "1095 2024-06-05  85500  86100  85000  85500           300  178185\n",
       "1096 2024-06-07  86300  86900  86000  86700          1200  285464\n",
       "1097 2024-06-10  85900  86700  85500  85900          -800  159538\n",
       "1098 2024-06-11  86000  86900  85900  86500           600  185079\n",
       "1099 2024-06-12  86100  86800  86000  86500             0  126821\n",
       "1100 2024-06-13  86500  87300  85900  85900          -600  349698\n",
       "1101 2024-06-14  85300  86800  85300  86800           900  490156\n",
       "1102 2024-06-17  86500  86800  86000  86800             0  104525\n",
       "1103 2024-06-18  86700  87000  86100  86500          -300  213667\n",
       "1104 2024-06-19  87200  87300  86000  86400          -100  153855\n",
       "1105 2024-06-20  86000  86900  86000  86700           300  165516\n",
       "1106 2024-06-21  86800  87000  86100  86300          -400  206548\n",
       "1107 2024-06-24  86500  86500  85700  85900          -400  171990\n",
       "1108 2024-06-25  86600  86600  85700  85800          -100  222460\n",
       "1109 2024-06-26  85500  86500  85000  86500           700  220987"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collect.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d4419-038b-4f9f-bb67-14562fd58e62",
   "metadata": {},
   "source": [
    "## 여기까지"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
