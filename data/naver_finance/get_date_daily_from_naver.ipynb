{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import datetime, time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3f2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cfscrape # 403 forbidden, cloudflare error을 해결하기 위한 모듈\n",
    "import cloudscraper\n",
    "scraper = cloudscraper.create_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08943027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install cfscrape # 403 forbidden, cloudflare error을 해결하기 위한 모듈\n",
    "# import cfscrape\n",
    "# scraper = cfscrape.create_scraper()\n",
    "# # 이후 403 error이 발생한 곳에는 requests 대신 scraper 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "selective-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Referer': 'https://kr.investing.com/',\n",
    "           'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "           AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5d6156-f7ff-4aee-a063-7240845f438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../data/constant')\n",
    "from constants import COMPANY_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afbcbb53-e0e0-496d-adb7-a57c3341ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df_o, df, dup_col, sort_col):\n",
    "    df_o = pd.concat([df_o, df], ignore_index=True)\n",
    "    df_o.drop_duplicates(subset=[dup_col], keep='last', inplace=True) # dup_col 중첩제거 기준 컬럼 이름: \"time\", \"date\" 등\n",
    "#     df_o.drop_duplicates(subset=[dup_col], keep='first', inplace=True)\n",
    "    df_o.sort_values(by=[df_o.columns[sort_col]], inplace=True) # sort_col 정렬 기준 컬럼 번호\n",
    "    df_o.index = np.arange(0, len(df_o))  # 일련 번호 오름차순으로 재 설정\n",
    "    return df_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae7fc7-ceb8-4886-af2c-f856d2403168",
   "metadata": {},
   "source": [
    "## 일별시세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbbd01b-12d7-4956-9bec-301933b1b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자별 주식 데이터를 페이지별로 10개씩 취득\n",
    "def get_piece_date_price(url_d):\n",
    "    res = scraper.get(url_d, headers=headers)\n",
    "    class_name = 'type2'\n",
    "    df = pd.read_html(io.StringIO(str(res.text)), attrs={\"class\": class_name}, flavor=[\"lxml\", \"bs4\"])[0]\n",
    "    \n",
    "    df = df.dropna(axis=0) # delete nan rows\n",
    "\n",
    "    df.columns = ['date', 'close', 'close_change', 'open', 'high', 'low', 'volume'] # rename column\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.datetime.strptime(x, '%Y.%m.%d')) # convert character to datetime object\n",
    "    \n",
    "    # convert character values to integer value : 보합= 0, 하락= -, 상승= +\n",
    "    df['close_change'] = df['close_change'].apply(lambda x: int(x[2:]) if x[:2] == '보합' \n",
    "                                  else (-int(x[4:].replace(',','')) if x[:2] == '하락' \n",
    "                                        else int(x[4:].replace(',',''))))  # convert characters to int\n",
    "    # define variable types\n",
    "    df['open'] = df['open'].astype(int)\n",
    "    df['high'] = df['high'].astype(int)\n",
    "    df['low'] = df['low'].astype(int)\n",
    "    df['close'] = df['close'].astype(int)\n",
    "    df['volume'] = df['volume'].astype(int)\n",
    "    \n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'close_change', 'volume']]  # rearrange columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "309638e3-7ee2-4b51-b67c-c12e9f20f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개씩의 일자별 데이터를 원하는 일자부터 현재일자까지 합하어 취득\n",
    "def get_date_price(url_base_d, code_com):\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # make first data frame\n",
    "    page = str(page_num)\n",
    "    url_date = url_base_d + '?code=' + code_com + '&page=' + page\n",
    "    df_base = get_piece_date_price(url_date)\n",
    "    \n",
    "    page_num = page_num + 1\n",
    "\n",
    "    startdate_str = '2020/1/2 00:00:00' # 데이터 수집 시작 일자, startdate_str\n",
    "    startdate = datetime.datetime.strptime(startdate_str, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "    STOP_FLAG = True\n",
    "    while STOP_FLAG:\n",
    "        page = str(page_num)\n",
    "        \n",
    "        url_date = url_base_d + '?code=' + code_com + '&page=' + page\n",
    "        df_p = get_piece_date_price(url_date)\n",
    "        # print(\"page_num\", page_num, end=\", \")\n",
    "        # print(\"length\", len(df_p))\n",
    "        df_base = concat_df(df_base, df_p, 'date', 0)  # df concat후 'time' column을 기준으로 중복제거 후 0 column을 기준으로 정렬시킴.\n",
    "        # print(\"*****\", df_base.head(2))\n",
    "        # print(\"OOOOOO\", df_p.head(2))\n",
    "        for i in range(len(df_p)):\n",
    "            if len(df_p) < 10: # 10개 이하가 아니면 완료\n",
    "                # print(\"iiii:\", url_date, df_p['date'].iloc[0])\n",
    "                STOP_FLAG = False\n",
    "                break\n",
    "            if df_p['date'].iloc[i] == startdate: # 시작일자와 일치하는 row가 있으면 더 이상 진행하지 않음.\n",
    "                # print(\"jjjj:\", url_date, df_p['date'].iloc[0])\n",
    "                STOP_FLAG = False\n",
    "                break\n",
    "\n",
    "        page_num = page_num + 1\n",
    "\n",
    "    # print(\"ppp\", df_base.head(1), df_base.tail(1))\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8624b98e-d394-4d8d-aeeb-545d7fcdd9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, "
     ]
    }
   ],
   "source": [
    "# naver_dir = 'data/naver_finance/date_data'\n",
    "naver_dir = 'date_data'\n",
    "\n",
    "url_base = 'https://finance.naver.com/item/sise_day.naver'  # sise_day\n",
    "\n",
    "code_dic = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'], \n",
    "        '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "\n",
    "code_dic = COMPANY_CODE\n",
    "code_dic = {'005930': ['삼성전자', 'sec'],}\n",
    "\n",
    "for i, (code, company_name) in enumerate(code_dic.items()):\n",
    "    df_collect = get_date_price(url_base, code)\n",
    "    f_name = f'{naver_dir}/{company_name[1]}.csv'\n",
    "    df_collect.to_csv(f_name)\n",
    "    df_collect.to_pickle(f_name.replace('csv','pkl'))\n",
    "    print(i, end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6669a8ad-efec-4a67-be11-700c6c08bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_change</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>55800</td>\n",
       "      <td>56700</td>\n",
       "      <td>55400</td>\n",
       "      <td>56700</td>\n",
       "      <td>2000</td>\n",
       "      <td>19358433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>56700</td>\n",
       "      <td>57200</td>\n",
       "      <td>56000</td>\n",
       "      <td>56300</td>\n",
       "      <td>-400</td>\n",
       "      <td>15558208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>57000</td>\n",
       "      <td>57300</td>\n",
       "      <td>55500</td>\n",
       "      <td>56000</td>\n",
       "      <td>-300</td>\n",
       "      <td>14180520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>56100</td>\n",
       "      <td>56500</td>\n",
       "      <td>55600</td>\n",
       "      <td>56000</td>\n",
       "      <td>0</td>\n",
       "      <td>12095519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>56100</td>\n",
       "      <td>56400</td>\n",
       "      <td>55100</td>\n",
       "      <td>55500</td>\n",
       "      <td>-500</td>\n",
       "      <td>9839252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>55600</td>\n",
       "      <td>55700</td>\n",
       "      <td>54800</td>\n",
       "      <td>55000</td>\n",
       "      <td>-500</td>\n",
       "      <td>11868463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>54700</td>\n",
       "      <td>55400</td>\n",
       "      <td>54400</td>\n",
       "      <td>55400</td>\n",
       "      <td>400</td>\n",
       "      <td>9645034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>55700</td>\n",
       "      <td>56900</td>\n",
       "      <td>55500</td>\n",
       "      <td>56500</td>\n",
       "      <td>1100</td>\n",
       "      <td>12313056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>56200</td>\n",
       "      <td>56600</td>\n",
       "      <td>55700</td>\n",
       "      <td>55800</td>\n",
       "      <td>-700</td>\n",
       "      <td>8356767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>55500</td>\n",
       "      <td>56000</td>\n",
       "      <td>55000</td>\n",
       "      <td>55200</td>\n",
       "      <td>-600</td>\n",
       "      <td>12993228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close  close_change    volume\n",
       "0 2019-12-17  55800  56700  55400  56700          2000  19358433\n",
       "1 2019-12-18  56700  57200  56000  56300          -400  15558208\n",
       "2 2019-12-19  57000  57300  55500  56000          -300  14180520\n",
       "3 2019-12-20  56100  56500  55600  56000             0  12095519\n",
       "4 2019-12-23  56100  56400  55100  55500          -500   9839252\n",
       "5 2019-12-24  55600  55700  54800  55000          -500  11868463\n",
       "6 2019-12-26  54700  55400  54400  55400           400   9645034\n",
       "7 2019-12-27  55700  56900  55500  56500          1100  12313056\n",
       "8 2019-12-30  56200  56600  55700  55800          -700   8356767\n",
       "9 2020-01-02  55500  56000  55000  55200          -600  12993228"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collect.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d4419-038b-4f9f-bb67-14562fd58e62",
   "metadata": {},
   "source": [
    "## 여기까지"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
