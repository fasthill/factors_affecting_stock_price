{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459ff0ca",
   "metadata": {},
   "source": [
    "## combine company data and common data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b5a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef51f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('.')) \n",
    "sys.path.append(module_path+\"\\\\data\\\\constant\")\n",
    "\n",
    "from constants import COMPANY_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea60572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n[[datetime.date(2022, 1, 17) 'dji_cr']\\n [datetime.date(2022, 1, 17) 'dji_f_cr']\\n ...\\n [datetime.date(2023, 5, 23) 'kosdaq_cr']\\n [datetime.date(2023, 5, 23) 'kosdaq_cr_2']]\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def locate_nan(df):\n",
    "    idx, idy = np.where(pd.isnull(df))\n",
    "    result = np.column_stack([df.index[idx], df.columns[idy]])\n",
    "    return result\n",
    "\n",
    "# return format\n",
    "''' \n",
    "[[datetime.date(2022, 1, 17) 'dji_cr']\n",
    " [datetime.date(2022, 1, 17) 'dji_f_cr']\n",
    " ...\n",
    " [datetime.date(2023, 5, 23) 'kosdaq_cr']\n",
    " [datetime.date(2023, 5, 23) 'kosdaq_cr_2']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f9e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = COMPANY_CODE\n",
    "\n",
    "# code = {'005930': ['삼성전자', 'sec'], '005380': ['현대차', 'hyunmotor'],\n",
    "#                  '035420': ['NAVER', 'naver'], '033780': ['KT&G', 'ktng']}\n",
    "# code = {'005930': ['삼성전자', 'sec'], '000660': ['SK하이닉스', 'skhynix']}\n",
    "# code = {'302440': ['SK바이오사이언스', 'skbio']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ced9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_for_predict = './data/data_for_ml/predict/'\n",
    "pkl_common_directory = './data/common_pkl/'\n",
    "pkl_directory = './data/common_pkl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ac3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.read_pickle(directory_for_predict + '0_df_common.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82d5ae58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m code\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     df_company \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_for_predict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_company.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     df_company \u001b[38;5;241m=\u001b[39m df_company\u001b[38;5;241m.\u001b[39mmerge(df_common, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_combine\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_company\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\pickle.py:207\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\compat\\pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pickle.py:1205\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1203\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1205\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pickle.py:1530\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\compat\\pickle_compat.py:162\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    160\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[0;32m    161\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pickle.py:1572\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1570\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1571\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1572\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'"
     ]
    }
   ],
   "source": [
    "for key, val in code.items():\n",
    "    df_company = pd.read_pickle(directory_for_predict + f'df_{val[1]}_company.pkl')\n",
    "    df_company = df_company.merge(df_common, how='left', left_index=True, right_index=True)\n",
    "    globals()[f'df_{val[1]}_combine'] = df_company.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c798e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_hyunmotor_combine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_hyunmotor_combine\u001b[49m\u001b[38;5;241m.\u001b[39mtail()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_hyunmotor_combine' is not defined"
     ]
    }
   ],
   "source": [
    "df_hyunmotor_combine.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hyunmotor_combine.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ac2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_inv1 = ['retail_1', 'foreigner_1', 'institution_1', 'financial_1', 'invtrust_1', 'pension_1', 'privequity_1', \n",
    "            'bank_1', 'insurance_1', 'financeetc_1', 'corporateetc_1', 'foreigneretc_1']\n",
    "col_inv2 = ['retail_2', 'foreigner_2', 'institution_2', 'financial_2', 'invtrust_2', 'pension_2',\n",
    "            'privequity_2', 'bank_2', 'insurance_2', 'financeetc_2', 'corporateetc_2', 'foreigneretc_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_his1 = ['open_1', 'high_1', 'low_1', 'close_1', 'vol_1']\n",
    "col_his2 = ['open_2', 'high_2', 'low_2', 'close_2', 'vol_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_common1 = [\"dji_cr\", \"dji_f_cr\", \"dxy_cr\", \"ixic_f_cr\", \"bond_kor_10_cr\", \"bond_kor_2_cr\", \"kosdaq_cr\", \"kospi_cr\", \n",
    "         \"krw_cr\", \"ixic_cr\", \"spx_f_cr\", \"sox_cr\", \"spx_cr\", \"bond_usa_10_cr\", \"bond_usa_2_cr\", \"bond_usa_3m_cr\", \n",
    "         \"vix_cr\", \"wti_cr\", \"spsy_cr\", \"spny_cr\", \"spxhc_cr\", \"splrcd_cr\", \"splrci_cr\", \"splrcu_cr\", \"splrcs_cr\",\n",
    "         \"splrct_cr\", \"splrcl_cr\", \"splrcm_cr\", \"ixbk_cr\", \"ixfn_cr\", \"ixid_cr\", \"ixis_cr\", \"ixk_cr\", \"ixtr_cr\",\n",
    "         \"ixut_cr\", \"nbi_cr\", \"bkx_cr\"]\n",
    "col_common2 = [\"dji_cr_2\", \"dji_f_cr_2\", \"dxy_cr_2\", \"ixic_f_cr_2\", \"bond_kor_10_cr_2\", \"bond_kor_2_cr_2\", \"kosdaq_cr_2\", \"kospi_cr_2\",\n",
    "         \"krw_cr_2\", \"ixic_cr_2\", \"spx_f_cr_2\", \"sox_cr_2\", \"spx_cr_2\", \"bond_usa_10_cr_2\", \"bond_usa_2_cr_2\", \"bond_usa_3m_cr_2\",\n",
    "         \"vix_cr_2\", \"wti_cr_2\", \"spsy_cr_2\", \"spny_cr_2\", \"spxhc_cr_2\", \"splrcd_cr_2\", \"splrci_cr_2\", \"splrcu_cr_2\",\n",
    "         \"splrcs_cr_2\", \"splrct_cr_2\", \"splrcl_cr_2\", \"splrcm_cr_2\", \"ixbk_cr_2\", \"ixfn_cr_2\", \"ixid_cr_2\",\n",
    "         \"ixis_cr_2\", \"ixk_cr_2\", \"ixtr_cr_2\", \"ixut_cr_2\", \"nbi_cr_2\", \"bkx_cr_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a595935",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cr = ['weekday', 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_col = col_inv1 + col_common1 + col_his1 + col_inv2 + col_common2 + col_his2 + col_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6769da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write common data only\n",
    "# df_temp = df_common.copy()\n",
    "# df_temp = df_temp[col_common1+col_common2]\n",
    "# pkl_common_directory = './data/common_pkl/'\n",
    "# df_temp.to_pickle(pkl_common_directory + 'df_common.pkl')\n",
    "# df_temp.to_csv(pkl_common_directory + 'df_common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c8f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = col_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 순서 변경 : weekday, 'cr_00', 'cr_05', 'cr_10', 'cr_15', 'cr_20' column을 마지막으로 이동 \n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_combine'.format(val[1])] = globals()['df_{}_combine'.format(val[1])][new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# drop inf, -inf : replace inf to 1 or -1 . 데이터를 살리고\n",
    "# 변동률이 무한대가 되는 것을 방지하기 위해서, 나중에 발생하는 에러를 방지\n",
    "df_sec_sel.replace([np.inf, -np.inf], [1, -1], inplace=True)\n",
    "\n",
    ".impute 사용하는 것을 고려할 필요 있음.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e91c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop inf, -inf : replace inf to 1 or -1 . 데이터를 살리고\n",
    "# 변동률이 무한대가 되는 것을 방지하기 위해서, 나중에 발생하는 에러를 방지\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_combine'.format(val[1])].replace([np.inf, -np.inf], [1, -1], inplace=True)\n",
    "\n",
    "# **** 데이터 전처리 from sklearn.impute import SimpleImputer, SimpleImputer 사용하기로 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sec_combine.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7224df",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanlo = locate_nan(df_sec_combine)  # nan 위치 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nanlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows which include NaN : dji, spx, nasdaq 기타 common 지수중 한개라도 nan인 rows 제거\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_combine'.format(val[1])].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f3061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string column을 numeric으로 전환\n",
    "def string_to_num(df):\n",
    "    df.replace('%', '', regex=True, inplace=True)\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    return df\n",
    "\n",
    "for key, val in code.items():\n",
    "    globals()['df_{}_combine'.format(val[1])] = string_to_num(globals()['df_{}_combine'.format(val[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 데이터 저장\n",
    "\n",
    "for key, val in code.items():\n",
    "    globals()[f'df_{val[1]}_combine'].to_pickle(directory_for_predict + f'df_{val[1]}_combine.pkl')\n",
    "    globals()[f'df_{val[1]}_combine'].to_csv(directory_for_predict + f'df_{val[1]}_combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01825d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300e5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffeab80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7c9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80b897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
